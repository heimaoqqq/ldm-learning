# LDM Training Configuration
# åŸºäºCompVis/latent-diffusionçš„æ½œåœ¨æ‰©æ•£æ¨¡å‹è®­ç»ƒé…ç½®

# æ•°æ®é…ç½®
data:
  data_dir: "/kaggle/input/dataset/dataset"  # æ•°æ®é›†è·¯å¾„
  batch_size: 8                              # æ‰¹æ¬¡å¤§å°ï¼ˆä¿å®ˆè®¾ç½®ï¼Œé¿å…OOMï¼‰
  num_workers: 2                             # æ•°æ®åŠ è½½çº¿ç¨‹æ•°
  image_size: 256                            # å›¾åƒå°ºå¯¸ï¼ˆåŒ¹é…VAEè®­ç»ƒï¼‰

# U-Netæ¨¡å‹é…ç½®
unet:
  in_channels: 4                             # è¾“å…¥é€šé“æ•°ï¼ˆAutoencoderKLçš„æ½œå˜é‡ï¼‰
  out_channels: 4                            # è¾“å‡ºé€šé“æ•°ï¼ˆé¢„æµ‹çš„å™ªéŸ³ï¼‰
  model_channels: 320                        # åŸºç¡€é€šé“æ•°ï¼ˆå‚è€ƒStable Diffusionï¼‰
  num_res_blocks: 2                          # æ¯ä¸ªåˆ†è¾¨ç‡çº§åˆ«çš„æ®‹å·®å—æ•°
  attention_resolutions: [4, 2, 1]           # ä½¿ç”¨æ³¨æ„åŠ›çš„åˆ†è¾¨ç‡çº§åˆ«
  channel_mult: [1, 2, 4, 4]                # é€šé“å€æ•°
  num_classes: 31                            # ç±»åˆ«æ•°é‡ï¼ˆå¾®å¤šæ™®å‹’ä¿¡å·åˆ†ç±»ï¼‰
  dropout: 0.1                               # Dropoutæ¦‚ç‡
  num_heads: 8                               # æ³¨æ„åŠ›å¤´æ•°
  use_scale_shift_norm: true                 # ä½¿ç”¨ç¼©æ”¾åç§»å½’ä¸€åŒ–
  resblock_updown: true                      # æ®‹å·®å—ä¸­ä½¿ç”¨ä¸Šä¸‹é‡‡æ ·

# æ‰©æ•£è¿‡ç¨‹é…ç½®
diffusion:
  timesteps: 1000                            # æ‰©æ•£æ—¶é—´æ­¥æ•°
  beta_schedule: "cosine"                    # betaè°ƒåº¦ç±»å‹ï¼ˆcosine/linearï¼‰
  beta_start: 0.0001                         # betaèµ·å§‹å€¼
  beta_end: 0.02                             # betaç»“æŸå€¼

# è®­ç»ƒé…ç½®
training:
  epochs: 50                                 # è®­ç»ƒè½®æ¬¡
  learning_rate: 0.0001                     # ç›®æ ‡å­¦ä¹ ç‡
  weight_decay: 0.01                         # æƒé‡è¡°å‡
  scheduler: "cosine"                        # å­¦ä¹ ç‡è°ƒåº¦å™¨ï¼ˆcosine/step/noneï¼‰
  min_lr: 0.000001                           # æœ€å°å­¦ä¹ ç‡
  gradient_clip: 1.0                         # æ­£å¸¸æ¢¯åº¦è£å‰ªé˜ˆå€¼
  auto_update_scaling_factor: true           # è‡ªåŠ¨è®¡ç®—ç¼©æ”¾å› å­
  progressive_scaling_update: true           # ä½¿ç”¨æ¸è¿›å¼æ›´æ–°é¿å…æ¢¯åº¦éœ‡è¡
  
  # ğŸ”¥ æ–°å¢ï¼šé¢„çƒ­æœºåˆ¶é…ç½®
  warmup:
    enabled: true                            # å¯ç”¨é¢„çƒ­æœºåˆ¶
    
    # å­¦ä¹ ç‡é¢„çƒ­ï¼ˆé’ˆå¯¹ç¬¬ä¸€è½®ï¼‰
    lr_warmup:
      enabled: true                          # å¯ç”¨å­¦ä¹ ç‡é¢„çƒ­
      warmup_epochs: 2                      # å‡å°‘åˆ°2è½®é¢„çƒ­
      start_lr: 0.00002                     # æ›´ä¿å®ˆçš„èµ·å§‹å­¦ä¹ ç‡ï¼ˆç›®æ ‡LRçš„20%ï¼‰
      warmup_strategy: "linear"              # é¢„çƒ­ç­–ç•¥ï¼ˆlinear/cosineï¼‰
    
    # ç¼©æ”¾å› å­æ¸è¿›é¢„çƒ­
    scaling_warmup:
      enabled: true                          # å¯ç”¨ç¼©æ”¾å› å­é¢„çƒ­
      warmup_epochs: 3                      # å‡å°‘åˆ°3è½®è°ƒæ•´
      adjustment_steps: [0.7, 0.9, 1.0]     # æœ€ç§¯æè°ƒæ•´ï¼š70% â†’ 90% â†’ 100%
      tolerance: 0.1
    
    # æ¢¯åº¦è£å‰ªé¢„çƒ­ï¼ˆé’ˆå¯¹ç¬¬ä¸€è½®ï¼‰
    gradient_warmup:
      enabled: true                          # å¯ç”¨æ¢¯åº¦è£å‰ªé¢„çƒ­
      warmup_epochs: 1                      # åªåœ¨ç¬¬ä¸€è½®ä¸¥æ ¼è£å‰ª
      start_clip: 0.3                       # ç¬¬ä¸€è½®éå¸¸ä¸¥æ ¼çš„æ¢¯åº¦è£å‰ª
  
  # è¯¦ç»†æ•°å€¼ç›‘æ§é…ç½®ï¼ˆç”¨äºè°ƒè¯•å’ŒéªŒè¯ï¼‰
  detailed_monitoring:
    enabled: true                            # æ˜¯å¦å¯ç”¨è¯¦ç»†ç›‘æ§
    monitor_epochs: 5                        # åªç›‘æ§å‰5ä¸ªepochï¼ˆå‡å°‘è¾“å‡ºï¼‰
    monitor_batches: 3                       # æ¯ä¸ªepochç›‘æ§å‰3ä¸ªæ‰¹æ¬¡ï¼ˆå‡å°‘è¾“å‡ºï¼‰
    summary_interval: 300                    # æ¯300ä¸ªæ‰¹æ¬¡è¾“å‡ºä¸€æ¬¡æ‘˜è¦ï¼ˆå‡å°‘è¾“å‡ºï¼‰
    check_scaling_factor: true               # æ˜¯å¦æ£€æŸ¥ç¼©æ”¾å› å­æ•ˆæœ

# è¯„ä¼°å’Œé‡‡æ ·é…ç½®
evaluation:
  # FIDè¯„ä¼°é…ç½®
  fid_evaluation:
    enabled: true                              # æ˜¯å¦å¯ç”¨FIDè¯„ä¼°
    eval_every_epochs: 5                        # æ¯éš”5ä¸ªepochè¯„ä¼°ä¸€æ¬¡ï¼ˆå‡å°‘é¢‘ç‡ï¼‰
    num_real_samples: 500                      # å¤§å¹…å‡å°‘æ ·æœ¬æ•°é‡
    num_fake_samples: 500                      # å¤§å¹…å‡å°‘æ ·æœ¬æ•°é‡
    batch_size: 4                              # æå°æ‰¹æ¬¡å¤§å°
    inception_batch_size: 4                    # æå°Inceptionæ‰¹æ¬¡
    num_inference_steps: 50                    # å‡å°‘æ¨ç†æ­¥æ•°
    # ç´§æ€¥ä½å†…å­˜æ¨¡å¼: æ€»å…±400å¼ å›¾ç‰‡ï¼Œæ‰¹æ¬¡4+2
    
  # å¸¸è§„æ ·æœ¬ç”Ÿæˆé…ç½®
  sample_generation:
    sample_every_epochs: 10                     # æ¯éš”å‡ ä¸ªepochç”Ÿæˆæ ·æœ¬
    num_sample_images: 4                       # ç”Ÿæˆæ ·æœ¬å›¾åƒæ•°é‡
    inference_steps: 50                        # æ¨ç†æ­¥æ•°
    guidance_scale: 1.0                        # åˆ†ç±»å™¨è‡ªç”±å¼•å¯¼å¼ºåº¦
    save_individual: false                      # æ˜¯å¦ä¿å­˜å•ç‹¬çš„æ ·æœ¬å›¾åƒ

# è¾“å‡ºé…ç½®
output_dir: "./ldm_outputs"                  # è¾“å‡ºç›®å½•
save_every_epochs: 25                       # å‡å°‘ä¿å­˜é¢‘ç‡ï¼Œæ¯20ä¸ªepochä¿å­˜ä¸€æ¬¡

# å†…å­˜ä¼˜åŒ–é…ç½®
optimization:
  mixed_precision: false                     # æ··åˆç²¾åº¦è®­ç»ƒï¼ˆVAEå·²å¤„ç†dtypeé—®é¢˜ï¼‰
  gradient_accumulation: 2                   # ä½¿ç”¨æ¢¯åº¦ç´¯ç§¯å¢å¼ºç¨³å®šæ€§
  memory_efficient_attention: true           # å†…å­˜é«˜æ•ˆæ³¨æ„åŠ›
  
# æ•°æ®å½’ä¸€åŒ–é…ç½®
data_normalization:
  # å›¾åƒå½’ä¸€åŒ–èŒƒå›´ï¼ˆè¾“å…¥åˆ°VAEçš„å›¾åƒï¼‰
  image_range: [-1, 1]                       # VAEè®­ç»ƒæ—¶ä½¿ç”¨çš„å½’ä¸€åŒ–èŒƒå›´
  # æ½œå˜é‡èŒƒå›´ï¼ˆVAEè¾“å‡ºçš„æ½œå˜é‡ï¼‰
  latent_range: [-4, 4]                      # æ½œå˜é‡çš„å…¸å‹èŒƒå›´
  # FIDè¯„ä¼°æ—¶çš„å›¾åƒèŒƒå›´
  fid_image_range: [0, 1]                    # FIDè¯„ä¼°è¦æ±‚çš„å›¾åƒèŒƒå›´

# Kaggleç¯å¢ƒé…ç½®
kaggle:
  vae_checkpoint: "/kaggle/input/vae-model/vae_finetuned_epoch_23.pth"
  dataset_path: "/kaggle/input/dataset/dataset" 
