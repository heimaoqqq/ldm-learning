# LDM Training Configuration
# 基于CompVis/latent-diffusion的潜在扩散模型训练配置

# 数据配置
data:
  data_dir: "/kaggle/input/dataset/dataset"  # 数据集路径
  batch_size: 6                              # 批次大小（保守设置，避免OOM）
  num_workers: 2                             # 数据加载线程数
  image_size: 256                            # 图像尺寸（匹配VAE训练）

# U-Net模型配置
unet:
  in_channels: 4                             # 输入通道数（AutoencoderKL的潜变量）
  out_channels: 4                            # 输出通道数（预测的噪音）
  model_channels: 320                        # 基础通道数（参考Stable Diffusion）
  num_res_blocks: 2                          # 每个分辨率级别的残差块数
  attention_resolutions: [4, 2, 1]           # 使用注意力的分辨率级别
  channel_mult: [1, 2, 4, 4]                # 通道倍数
  num_classes: 31                            # 类别数量（微多普勒信号分类）
  dropout: 0.1                               # Dropout概率
  num_heads: 8                               # 注意力头数
  use_scale_shift_norm: true                 # 使用缩放偏移归一化
  resblock_updown: true                      # 残差块中使用上下采样

# 扩散过程配置
diffusion:
  timesteps: 1000                            # 扩散时间步数
  beta_schedule: "cosine"                    # beta调度类型（cosine/linear）
  beta_start: 0.0001                         # beta起始值
  beta_end: 0.02                             # beta结束值

# 训练配置
training:
  epochs: 50                                 # 训练轮次
  learning_rate: 0.0001                     # 初始学习率
  weight_decay: 0.01                         # 权重衰减
  scheduler: "cosine"                        # 学习率调度器（cosine/step/none）
  min_lr: 0.000001                          # 最小学习率
  gradient_clip: 1.0                         # 梯度裁剪阈值
  auto_update_scaling_factor: true           # 是否自动更新VAE缩放因子（重新训练VAE后推荐开启）

# 评估和采样配置
evaluation:
  # FID评估配置
  fid_evaluation:
    enabled: true                              # 是否启用FID评估
    eval_every_epochs: 1                       # 每隔几个epoch评估一次
    num_samples: 500                           # 用于FID评估的样本数量（减少以节省内存）
    batch_size: 16                             # FID评估时的批次大小（减少以节省内存）
    inception_batch_size: 16                   # Inception模型的批次大小（减少以节省内存）
    num_inference_steps: 50                    # 生成样本时的推理步数
    # 低内存模式建议: num_samples: 200, batch_size: 8, inception_batch_size: 8
    
  # 常规样本生成配置
  sample_generation:
    sample_every_epochs: 5                     # 每隔几个epoch生成样本
    num_sample_images: 4                       # 生成样本图像数量
    inference_steps: 50                        # 推理步数
    guidance_scale: 1.0                        # 分类器自由引导强度
    save_individual: true                      # 是否保存单独的样本图像

# 输出配置
output_dir: "./ldm_outputs"                  # 输出目录
save_every_epochs: 10                       # 每隔几个epoch保存检查点

# 内存优化配置
optimization:
  mixed_precision: false                     # 混合精度训练（VAE已处理dtype问题）
  gradient_accumulation: 1                   # 梯度累积步数
  memory_efficient_attention: true           # 内存高效注意力
  
# 数据归一化配置
data_normalization:
  # 图像归一化范围（输入到VAE的图像）
  image_range: [-1, 1]                       # VAE训练时使用的归一化范围
  # 潜变量范围（VAE输出的潜变量）
  latent_range: [-4, 4]                      # 潜变量的典型范围
  # FID评估时的图像范围
  fid_image_range: [0, 1]                    # FID评估要求的图像范围 
