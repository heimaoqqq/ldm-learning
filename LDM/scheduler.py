import torch
import torch.nn as nn
import numpy as np
import math
from typing import Optional, Tuple, Union

class DDPMScheduler:
    """
    DDPMæ‰©æ•£è°ƒåº¦å™¨ï¼Œå®ç°å‰å‘åŠ å™ªå’Œåå‘å»å™ªè¿‡ç¨‹
    æ”¯æŒçº¿æ€§å’Œä½™å¼¦å™ªå£°è°ƒåº¦
    """
    def __init__(
        self,
        num_train_timesteps: int = 1000,
        beta_start: float = 0.0001,
        beta_end: float = 0.02,
        beta_schedule: str = "linear",
        clip_denoised: bool = True,
        set_alpha_to_one: bool = True,
        steps_offset: int = 0,
    ):
        self.num_train_timesteps = num_train_timesteps
        self.beta_start = beta_start
        self.beta_end = beta_end
        self.beta_schedule = beta_schedule
        self.clip_denoised = clip_denoised
        
        # æ ¹æ®è°ƒåº¦ç±»å‹ç”Ÿæˆbetaåºåˆ—
        if beta_schedule == "linear":
            self.betas = torch.linspace(beta_start, beta_end, num_train_timesteps, dtype=torch.float32)
        elif beta_schedule == "cosine":
            self.betas = self._cosine_beta_schedule(num_train_timesteps)
        else:
            raise ValueError(f"Unsupported beta schedule: {beta_schedule}")
        
        # è®¡ç®—alphaç›¸å…³å‚æ•°
        self.alphas = 1.0 - self.betas
        self.alphas_cumprod = torch.cumprod(self.alphas, dim=0)
        self.alphas_cumprod_prev = torch.cat([torch.tensor([1.0]), self.alphas_cumprod[:-1]])
        
        # ç”¨äºé‡‡æ ·çš„å‚æ•°
        self.sqrt_alphas_cumprod = torch.sqrt(self.alphas_cumprod)
        self.sqrt_one_minus_alphas_cumprod = torch.sqrt(1.0 - self.alphas_cumprod)
        self.sqrt_recip_alphas_cumprod = torch.sqrt(1.0 / self.alphas_cumprod)
        self.sqrt_recipm1_alphas_cumprod = torch.sqrt(1.0 / self.alphas_cumprod - 1)
        
        # ç”¨äºåå‘è¿‡ç¨‹çš„å‚æ•°
        self.posterior_variance = (
            self.betas * (1.0 - self.alphas_cumprod_prev) / (1.0 - self.alphas_cumprod)
        )
        self.posterior_log_variance_clipped = torch.log(
            torch.cat([self.posterior_variance[1:2], self.posterior_variance[1:]])
        )
        
        self.posterior_mean_coef1 = (
            self.betas * torch.sqrt(self.alphas_cumprod_prev) / (1.0 - self.alphas_cumprod)
        )
        self.posterior_mean_coef2 = (
            (1.0 - self.alphas_cumprod_prev) * torch.sqrt(self.alphas) / (1.0 - self.alphas_cumprod)
        )
        
    def _cosine_beta_schedule(self, timesteps: int, s: float = 0.008) -> torch.Tensor:
        """
        ä½™å¼¦å™ªå£°è°ƒåº¦ï¼Œæ¥è‡ª "Improved Denoising Diffusion Probabilistic Models"
        """
        def alpha_bar(time_step):
            return math.cos((time_step + s) / (1 + s) * math.pi / 2) ** 2
        
        betas = []
        for i in range(timesteps):
            t1 = i / timesteps
            t2 = (i + 1) / timesteps
            betas.append(min(1 - alpha_bar(t2) / alpha_bar(t1), 0.999))
        return torch.tensor(betas, dtype=torch.float32)
    
    def add_noise(
        self,
        original_samples: torch.Tensor,
        noise: torch.Tensor,
        timesteps: torch.Tensor,
    ) -> torch.Tensor:
        """
        å‰å‘è¿‡ç¨‹ï¼šç»™åŸå§‹æ ·æœ¬æ·»åŠ å™ªå£°
        q(z_t | z_0) = N(z_t; sqrt(alpha_cumprod_t) * z_0, (1 - alpha_cumprod_t) * I)
        """
        # ç¡®ä¿å‚æ•°åœ¨æ­£ç¡®çš„è®¾å¤‡ä¸Š
        alphas_cumprod = self.sqrt_alphas_cumprod.to(device=original_samples.device, dtype=original_samples.dtype)
        sqrt_one_minus_alphas_cumprod = self.sqrt_one_minus_alphas_cumprod.to(
            device=original_samples.device, dtype=original_samples.dtype
        )
        
        sqrt_alpha_prod = alphas_cumprod[timesteps].flatten()
        sqrt_one_minus_alpha_prod = sqrt_one_minus_alphas_cumprod[timesteps].flatten()
        
        # è°ƒæ•´ç»´åº¦ä»¥åŒ¹é…è¾“å…¥å¼ é‡
        while len(sqrt_alpha_prod.shape) < len(original_samples.shape):
            sqrt_alpha_prod = sqrt_alpha_prod.unsqueeze(-1)
        while len(sqrt_one_minus_alpha_prod.shape) < len(original_samples.shape):
            sqrt_one_minus_alpha_prod = sqrt_one_minus_alpha_prod.unsqueeze(-1)
        
        noisy_samples = sqrt_alpha_prod * original_samples + sqrt_one_minus_alpha_prod * noise
        return noisy_samples
    
    def step(
        self,
        model_output: torch.Tensor,
        timestep: int,
        sample: torch.Tensor,
        eta: Optional[float] = None,  # ğŸ”§ æ·»åŠ etaå‚æ•°ä»¥ä¿æŒæ¥å£å…¼å®¹
        generator: Optional[torch.Generator] = None,
        return_dict: bool = True,
    ) -> Union[Tuple, "DDPMSchedulerOutput"]:
        """
        åå‘è¿‡ç¨‹ï¼šä»z_té¢„æµ‹z_{t-1}
        
        æ³¨æ„ï¼šDDPMè°ƒåº¦å™¨ä¸ä½¿ç”¨etaå‚æ•°ï¼Œä½†æ¥å—å®ƒä»¥ä¿æŒæ¥å£å…¼å®¹æ€§
        """
        # ğŸ”§ å¦‚æœä¼ å…¥äº†etaå‚æ•°ï¼Œå‘å‡ºæç¤ºä½†ä¸ä½¿ç”¨
        if eta is not None and eta != 0.0:
            print(f"ğŸ’¡ DDPMè°ƒåº¦å™¨ä¸ä½¿ç”¨etaå‚æ•° (ä¼ å…¥å€¼: {eta})ï¼Œå°†ä½¿ç”¨æ ‡å‡†DDPMé‡‡æ ·")
        
        t = timestep
        
        # 1. è®¡ç®—ç³»æ•°
        alpha_prod_t = self.alphas_cumprod[t]
        alpha_prod_t_prev = self.alphas_cumprod_prev[t] if t > 0 else torch.tensor(1.0)
        beta_prod_t = 1 - alpha_prod_t
        beta_prod_t_prev = 1 - alpha_prod_t_prev
        current_alpha_t = alpha_prod_t / alpha_prod_t_prev
        current_beta_t = 1 - current_alpha_t
        
        # 2. è®¡ç®—é¢„æµ‹çš„åŸå§‹æ ·æœ¬ z_0
        pred_original_sample = (sample - beta_prod_t ** (0.5) * model_output) / alpha_prod_t ** (0.5)
        
        # 3. è£å‰ªé¢„æµ‹æ ·æœ¬
        if self.clip_denoised:
            pred_original_sample = torch.clamp(pred_original_sample, -1, 1)
        
        # 4. è®¡ç®—åéªŒå‡å€¼å’Œæ–¹å·®
        pred_sample_direction = (1 - alpha_prod_t_prev) ** (0.5) * model_output
        pred_prev_sample = alpha_prod_t_prev ** (0.5) * pred_original_sample + pred_sample_direction
        
        # 5. æ·»åŠ å™ªå£° (é™¤äº†æœ€åä¸€æ­¥)
        if t > 0:
            device = model_output.device
            variance_noise = torch.randn(
                model_output.shape, generator=generator, device=device, dtype=model_output.dtype
            )
            # ä½¿ç”¨ç®€åŒ–çš„æ–¹å·®è®¡ç®—
            variance = (1 - alpha_prod_t_prev) / (1 - alpha_prod_t) * current_beta_t
            pred_prev_sample = pred_prev_sample + variance ** (0.5) * variance_noise
        
        if not return_dict:
            return (pred_prev_sample,)
        
        return DDPMSchedulerOutput(prev_sample=pred_prev_sample, pred_original_sample=pred_original_sample)
    
    def set_timesteps(self, num_inference_steps: int, device: Union[str, torch.device] = None):
        """
        è®¾ç½®æ¨ç†æ—¶çš„æ—¶é—´æ­¥
        """
        if num_inference_steps > self.num_train_timesteps:
            raise ValueError(
                f"num_inference_steps ({num_inference_steps}) > num_train_timesteps ({self.num_train_timesteps})"
            )
        
        self.num_inference_steps = num_inference_steps
        step_ratio = self.num_train_timesteps // self.num_inference_steps
        timesteps = (np.arange(0, num_inference_steps) * step_ratio).round()
        timesteps = list(reversed(timesteps.astype(np.int64)))
        self.timesteps = torch.from_numpy(np.array(timesteps))
        
        if device is not None:
            self.timesteps = self.timesteps.to(device)
    
    def __len__(self):
        return self.num_train_timesteps


class DDPMSchedulerOutput:
    """
    DDPMè°ƒåº¦å™¨çš„è¾“å‡ºç±»
    """
    def __init__(self, prev_sample: torch.Tensor, pred_original_sample: Optional[torch.Tensor] = None):
        self.prev_sample = prev_sample
        self.pred_original_sample = pred_original_sample


class DDIMScheduler(DDPMScheduler):
    """
    DDIMè°ƒåº¦å™¨ï¼Œç”¨äºå¿«é€Ÿé‡‡æ ·
    æ”¯æŒæ ‡å‡†DDIM (eta=0) å’Œæ”¹è¿›çš„è‡ªé€‚åº”eta
    """
    def __init__(self, eta: float = 0.0, adaptive_eta: bool = False, **kwargs):
        super().__init__(**kwargs)
        self.eta = eta
        self.adaptive_eta = adaptive_eta  # ğŸ†• æ˜¯å¦ä½¿ç”¨è‡ªé€‚åº”eta
    
    def step(
        self,
        model_output: torch.Tensor,
        timestep: int,
        sample: torch.Tensor,
        eta: Optional[float] = None,
        use_clipped_model_output: bool = False,
        generator: Optional[torch.Generator] = None,
        return_dict: bool = True,
    ):
        """
        DDIMé‡‡æ ·æ­¥éª¤
        æ”¯æŒæ ‡å‡†etaå’Œæ”¹è¿›çš„è‡ªé€‚åº”eta
        """
        if eta is None:
            eta = self.eta
        
        # å½“å‰å’Œå‰ä¸€æ—¶é—´æ­¥çš„ç´¢å¼•
        prev_timestep = timestep - self.num_train_timesteps // self.num_inference_steps
        
        # 1. è·å–alphaå€¼
        alpha_prod_t = self.alphas_cumprod[timestep]
        alpha_prod_t_prev = self.alphas_cumprod[prev_timestep] if prev_timestep >= 0 else torch.tensor(1.0)
        
        beta_prod_t = 1 - alpha_prod_t
        
        # 2. è®¡ç®—é¢„æµ‹çš„åŸå§‹æ ·æœ¬
        pred_original_sample = (sample - beta_prod_t ** (0.5) * model_output) / alpha_prod_t ** (0.5)
        
        # 3. è£å‰ªé¢„æµ‹æ ·æœ¬
        if self.clip_denoised:
            pred_original_sample = torch.clamp(pred_original_sample, -1, 1)
        
        # 4. ğŸ†• è®¡ç®—æ–¹å·® - æ”¯æŒè‡ªé€‚åº”eta
        if self.adaptive_eta and eta > 0:
            # ä½¿ç”¨è®ºæ–‡ä¸­çš„æ”¹è¿›å…¬å¼: Ïƒ_Ï„áµ¢(Î·) = Î·âˆš((1-Î±_Ï„áµ¢â‚‹â‚)/(1-Î±_Ï„áµ¢))âˆš(1-Î±_Ï„áµ¢/Î±_Ï„áµ¢â‚‹â‚)
            variance = self._get_adaptive_variance(timestep, prev_timestep, eta)
        else:
            # æ ‡å‡†DDIMæ–¹å·®
            variance = self._get_variance(timestep, prev_timestep)
        
        # 5. è®¡ç®—æ–¹å‘æŒ‡å‘å½“å‰æ ·æœ¬çš„"æ–¹å‘"
        # ç¡®ä¿å¼€æ–¹å‚æ•°éè´Ÿ
        term_for_sqrt = (1 - alpha_prod_t_prev - eta * variance).clamp(min=0.0)
        pred_sample_direction = term_for_sqrt.sqrt() * model_output
        
        # 6. è®¡ç®—å‰ä¸€æ ·æœ¬
        pred_prev_sample = alpha_prod_t_prev ** (0.5) * pred_original_sample + pred_sample_direction
        
        # 7. æ·»åŠ å™ªå£°
        if eta > 0:
            device = model_output.device
            noise = torch.randn(model_output.shape, generator=generator, device=device, dtype=model_output.dtype)
            # ç¡®ä¿å¼€æ–¹å‚æ•°éè´Ÿ
            variance_term_for_noise = (eta * variance).clamp(min=0.0)
            pred_prev_sample = pred_prev_sample + variance_term_for_noise.sqrt() * noise
        
        if not return_dict:
            return (pred_prev_sample,)
        
        return DDPMSchedulerOutput(prev_sample=pred_prev_sample, pred_original_sample=pred_original_sample)
    
    def _get_variance(self, timestep, prev_timestep):
        """æ ‡å‡†DDIMæ–¹å·®è®¡ç®—"""
        alpha_prod_t = self.alphas_cumprod[timestep]
        alpha_prod_t_prev = self.alphas_cumprod[prev_timestep] if prev_timestep >= 0 else torch.tensor(1.0)
        beta_prod_t = 1 - alpha_prod_t
        beta_prod_t_prev = 1 - alpha_prod_t_prev
        
        variance = (beta_prod_t_prev / beta_prod_t) * (1 - alpha_prod_t / alpha_prod_t_prev)
        return variance
    
    def _get_adaptive_variance(self, timestep, prev_timestep, eta):
        """
        ğŸ†• æ”¹è¿›çš„è‡ªé€‚åº”æ–¹å·®è®¡ç®—
        åŸºäºè®ºæ–‡å…¬å¼: Ïƒ_Ï„áµ¢(Î·) = Î·âˆš((1-Î±_Ï„áµ¢â‚‹â‚)/(1-Î±_Ï„áµ¢))âˆš(1-Î±_Ï„áµ¢/Î±_Ï„áµ¢â‚‹â‚)
        ä¼˜åŒ–ä¸º: Ïƒ_Ï„áµ¢(Î·) = Î·âˆš((1-Î±_Ï„áµ¢â‚‹â‚)(Î±_Ï„áµ¢â‚‹â‚-Î±_Ï„áµ¢)/(Î±_Ï„áµ¢â‚‹â‚(1-Î±_Ï„áµ¢)))
        """
        alpha_prod_t = self.alphas_cumprod[timestep]           # Î±_Ï„áµ¢
        alpha_prod_t_prev = self.alphas_cumprod[prev_timestep] if prev_timestep >= 0 else torch.tensor(1.0)  # Î±_Ï„áµ¢â‚‹â‚
        
        # ä½¿ç”¨ä¼˜åŒ–çš„å•ä¸ªå¹³æ–¹æ ¹å…¬å¼
        # Î·âˆš((1-Î±_Ï„áµ¢â‚‹â‚)(Î±_Ï„áµ¢â‚‹â‚-Î±_Ï„áµ¢)/(Î±_Ï„áµ¢â‚‹â‚(1-Î±_Ï„áµ¢)))
        numerator = (1 - alpha_prod_t_prev) * (alpha_prod_t_prev - alpha_prod_t)
        denominator = alpha_prod_t_prev * (1 - alpha_prod_t)
        
        adaptive_variance = eta * torch.sqrt(numerator / denominator)
        
        return adaptive_variance 
