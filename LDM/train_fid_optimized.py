#!/usr/bin/env python3
"""
FIDä¼˜åŒ–ä¸“ç”¨è®­ç»ƒè„šæœ¬
ç›®æ ‡ï¼šå°†FIDé™åˆ°20ä»¥å†…
ç‰¹ç‚¹ï¼šå¤§æ¨¡å‹ã€é«˜è´¨é‡è®­ç»ƒã€ç²¾ç»†åŒ–å‚æ•°è°ƒä¼˜
"""

import os
import yaml
import torch
import torch.nn as nn
import torch.optim as optim
from torch.utils.data import DataLoader
import sys
import time
import math
from tqdm import tqdm
import matplotlib.pyplot as plt
import torchvision.utils as vutils
from typing import Dict, Any
import json

# æ·»åŠ è·¯å¾„
sys.path.append(os.path.join(os.path.dirname(__file__), '..', 'VAE'))

from stable_ldm import StableLDM, create_stable_ldm
from dataset import build_dataloader
from fid_evaluation import FIDEvaluator
from metrics import DiffusionMetrics, denormalize_for_metrics

def denormalize(x):
    """åå½’ä¸€åŒ–å›¾åƒï¼Œä»[-1,1]è½¬æ¢åˆ°[0,1]"""
    return (x * 0.5 + 0.5).clamp(0, 1)

def save_sample_images(model, device, config, epoch, save_dir):
    """ç”Ÿæˆå¹¶ä¿å­˜æ ·æœ¬å›¾åƒ"""
    model.eval()
    
    # æ¯ä¸ªç±»åˆ«ç”Ÿæˆ2ä¸ªæ ·æœ¬
    num_classes = config['unet']['num_classes']
    samples_per_class = 2
    
    all_samples = []
    
    with torch.no_grad():
        for class_id in range(min(8, num_classes)):  # åªæ˜¾ç¤ºå‰8ä¸ªç±»åˆ«
            class_labels = torch.tensor([class_id] * samples_per_class, device=device)
            
            # é«˜è´¨é‡é‡‡æ ·
            samples = model.sample(
                batch_size=samples_per_class,
                class_labels=class_labels,
                num_inference_steps=config['inference']['num_inference_steps'],
                guidance_scale=config['inference']['guidance_scale'],
                verbose=False
            )
            
            all_samples.append(samples)
    
    # åˆå¹¶æ ·æœ¬
    all_samples = torch.cat(all_samples, dim=0)
    all_samples = denormalize(all_samples)
    
    # ä¿å­˜æ ·æœ¬ç½‘æ ¼
    grid = vutils.make_grid(all_samples, nrow=samples_per_class, padding=2, normalize=False)
    
    save_path = os.path.join(save_dir, f"samples_epoch_{epoch:03d}.png")
    vutils.save_image(grid, save_path)
    
    print(f"ğŸ’¾ æ ·æœ¬å›¾åƒå·²ä¿å­˜: {save_path}")

def save_model_checkpoint(model, save_path, epoch=None, extra_info=None):
    """ä¿å­˜æ¨¡å‹æ£€æŸ¥ç‚¹"""
    os.makedirs(save_path, exist_ok=True)
    
    # ä¿å­˜æ¨¡å‹æƒé‡
    checkpoint = {
        'unet_state_dict': model.unet.state_dict(),
        'epoch': epoch,
        'extra_info': extra_info or {}
    }
    
    # ä¿å­˜EMAæƒé‡ï¼ˆå¦‚æœå­˜åœ¨ï¼‰
    if model.ema is not None:
        checkpoint['ema_shadow'] = model.ema.shadow
    
    torch.save(checkpoint, os.path.join(save_path, 'model.pth'))
    
    # ä¿å­˜é…ç½®
    if hasattr(model, 'config'):
        with open(os.path.join(save_path, 'config.yaml'), 'w') as f:
            yaml.dump(model.config, f, default_flow_style=False)

def get_cosine_schedule_with_warmup(optimizer, num_warmup_steps: int, num_training_steps: int):
    """ä½™å¼¦å­¦ä¹ ç‡è°ƒåº¦å™¨"""
    def lr_lambda(current_step):
        if current_step < num_warmup_steps:
            return float(current_step) / float(max(1, num_warmup_steps))
        progress = float(current_step - num_warmup_steps) / float(max(1, num_training_steps - num_warmup_steps))
        return max(0.0, 0.5 * (1.0 + math.cos(math.pi * progress)))

    return torch.optim.lr_scheduler.LambdaLR(optimizer, lr_lambda)

def train_fid_optimized():
    """FIDä¼˜åŒ–ä¸“ç”¨è®­ç»ƒä¸»å‡½æ•°"""
    
    # åŠ è½½é…ç½®
    config_path = 'config_fid_optimized.yaml'
    if not os.path.exists(config_path):
        print(f"âŒ é…ç½®æ–‡ä»¶ä¸å­˜åœ¨: {config_path}")
        return
    
    with open(config_path, 'r', encoding='utf-8') as f:
        config = yaml.safe_load(f)
    
    print("ğŸ¯ FIDä¼˜åŒ–è®­ç»ƒå¯åŠ¨ - ç›®æ ‡FID < 20")
    
    # è®¾å¤‡é…ç½®
    if config['device'] == 'auto':
        device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
    else:
        device = torch.device(config['device'])
    print(f"ğŸš€ ä½¿ç”¨è®¾å¤‡: {device}")
    
    # æ··åˆç²¾åº¦è®­ç»ƒ
    use_amp = config.get('mixed_precision', False) and device.type == 'cuda'
    scaler = torch.cuda.amp.GradScaler() if use_amp else None
    print(f"âš¡ æ··åˆç²¾åº¦è®­ç»ƒ: {'å¯ç”¨' if use_amp else 'ç¦ç”¨ (è¿½æ±‚è´¨é‡)'}")
    
    # åˆ›å»ºä¿å­˜ç›®å½•
    save_dir = config['training']['save_dir']
    os.makedirs(save_dir, exist_ok=True)
    
    sample_dir = os.path.join(save_dir, "samples")
    os.makedirs(sample_dir, exist_ok=True)
    
    log_dir = config['logging']['log_dir']
    os.makedirs(log_dir, exist_ok=True)
    
    # æ„å»ºæ•°æ®åŠ è½½å™¨
    print("ğŸ“ åŠ è½½æ•°æ®é›†...")
    train_loader, val_loader, train_dataset_len, val_dataset_len = build_dataloader(
        config['dataset']['root_dir'],
        batch_size=config['dataset']['batch_size'],
        num_workers=config['dataset']['num_workers'],
        shuffle_train=True,
        shuffle_val=False,
        val_split=config['dataset']['val_split']
    )
    
    print(f"âœ… æ•°æ®é›†åŠ è½½å®Œæˆ: è®­ç»ƒé›† {train_dataset_len}, éªŒè¯é›† {val_dataset_len}")
    
    # åˆå§‹åŒ–å¼ºåŒ–LDMæ¨¡å‹
    print("ğŸ”¥ åˆå§‹åŒ–å¼ºåŒ–LDMæ¨¡å‹...")
    
    # å¤„ç†VAEè·¯å¾„
    vae_path = config['vae']['model_path']
    if vae_path.startswith('../'):
        vae_path = os.path.join(os.path.dirname(__file__), vae_path)
    
    # æ£€æŸ¥VAEæ–‡ä»¶
    if not os.path.exists(vae_path):
        print(f"âŒ é”™è¯¯: VAEæƒé‡æ–‡ä»¶ä¸å­˜åœ¨: {vae_path}")
        return
    
    print(f"âœ“ å‘ç°VAEæƒé‡æ–‡ä»¶: {vae_path}")
    config['vae']['model_path'] = vae_path
    
    model = create_stable_ldm(config).to(device)
    
    # æ‰“å°æ¨¡å‹å‚æ•°é‡
    total_params = sum(p.numel() for p in model.unet.parameters())
    print(f"ğŸ§  U-Netå‚æ•°é‡: {total_params:,} ({total_params/1e6:.1f}M)")
    
    # åˆå§‹åŒ–è¯„ä¼°å™¨
    print("ğŸ“Š åˆå§‹åŒ–è¯„ä¼°å™¨...")
    diffusion_metrics = DiffusionMetrics(device=device)
    
    fid_evaluator = None
    if config['fid_evaluation']['enabled']:
        print("ğŸ“ˆ åˆå§‹åŒ–é«˜ç²¾åº¦FIDè¯„ä¼°å™¨...")
        fid_evaluator = FIDEvaluator(device=device)
        print("ğŸ”„ è®¡ç®—çœŸå®æ•°æ®ç‰¹å¾...")
        max_real_samples = config['fid_evaluation']['max_real_samples']
        fid_evaluator.compute_real_features(val_loader, max_samples=max_real_samples)
    
    # ä¼˜åŒ–å™¨é…ç½®
    learning_rate = config['training']['lr']
    optimizer = optim.AdamW(
        model.unet.parameters(),
        lr=learning_rate,
        weight_decay=config['training']['weight_decay'],
        betas=(config['training']['beta1'], config['training']['beta2']),
        eps=config['training']['eps']
    )
    
    # å­¦ä¹ ç‡è°ƒåº¦å™¨
    scheduler = None
    if config['training']['use_scheduler']:
        total_steps = len(train_loader) * config['training']['epochs'] // config['training']['gradient_accumulation_steps']
        scheduler = get_cosine_schedule_with_warmup(
            optimizer,
            num_warmup_steps=config['training']['warmup_steps'],
            num_training_steps=total_steps
        )
        print(f"ğŸ“ˆ ä½¿ç”¨ä½™å¼¦å­¦ä¹ ç‡è°ƒåº¦å™¨ (æ€»æ­¥æ•°: {total_steps})")
    
    # è®­ç»ƒçŠ¶æ€
    start_epoch = 0
    best_loss = float('inf')
    best_fid = float('inf')
    global_step = 0
    
    # è®­ç»ƒæ—¥å¿—
    training_log = {
        'epochs': [],
        'train_loss': [],
        'val_loss': [],
        'fid_scores': [],
        'learning_rates': [],
        'best_fid_epoch': None
    }
    
    print("=" * 80)
    print(f"ğŸ¯ å¼€å§‹FIDä¼˜åŒ–è®­ç»ƒï¼Œç›®æ ‡FID < 20ï¼Œå…± {config['training']['epochs']} ä¸ªepoch")
    print(f"ğŸ“Š å½“å‰é…ç½®: å¤§æ¨¡å‹ ({total_params/1e6:.1f}Må‚æ•°) + é«˜è´¨é‡é‡‡æ ·")
    print("=" * 80)
    
    accumulation_steps = config['training']['gradient_accumulation_steps']
    
    for epoch in range(start_epoch, config['training']['epochs']):
        model.train()
        epoch_loss = 0.0
        epoch_start_time = time.time()
        
        progress_bar = tqdm(train_loader, desc=f"Epoch {epoch+1}/{config['training']['epochs']}")
        
        for batch_idx, (images, labels) in enumerate(progress_bar):
            images = images.to(device)
            labels = labels.to(device)
            
            # æ··åˆç²¾åº¦å‰å‘ä¼ æ’­
            if use_amp:
                with torch.cuda.amp.autocast():
                    outputs = model(images, class_labels=labels)
                    loss = outputs['loss'] / accumulation_steps  # æ¢¯åº¦ç´¯ç§¯
                
                # æ··åˆç²¾åº¦åå‘ä¼ æ’­
                scaler.scale(loss).backward()
                
                if (batch_idx + 1) % accumulation_steps == 0:
                    # æ¢¯åº¦è£å‰ª
                    if config['training']['grad_clip_norm'] > 0:
                        scaler.unscale_(optimizer)
                        torch.nn.utils.clip_grad_norm_(model.unet.parameters(), config['training']['grad_clip_norm'])
                    
                    scaler.step(optimizer)
                    scaler.update()
                    optimizer.zero_grad()
                    
                    if scheduler is not None:
                        scheduler.step()
                    
                    global_step += 1
                    
            else:
                # æ ‡å‡†è®­ç»ƒ
                outputs = model(images, class_labels=labels)
                loss = outputs['loss'] / accumulation_steps
                
                loss.backward()
                
                if (batch_idx + 1) % accumulation_steps == 0:
                    if config['training']['grad_clip_norm'] > 0:
                        torch.nn.utils.clip_grad_norm_(model.unet.parameters(), config['training']['grad_clip_norm'])
                    
                    optimizer.step()
                    optimizer.zero_grad()
                    
                    if scheduler is not None:
                        scheduler.step()
                    
                    global_step += 1
            
            epoch_loss += loss.item() * accumulation_steps
            
            # æ›´æ–°è¿›åº¦æ¡
            current_lr = optimizer.param_groups[0]['lr']
            progress_bar.set_postfix({
                'loss': f'{loss.item() * accumulation_steps:.4f}',
                'lr': f'{current_lr:.2e}',
                'step': global_step
            })
            
            # æ£€æŸ¥æŸå¤±å¥åº·çŠ¶å†µ
            if math.isnan(loss.item()) or math.isinf(loss.item()):
                print(f"âŒ æ£€æµ‹åˆ°å¼‚å¸¸æŸå¤±ï¼Œè·³è¿‡æ‰¹æ¬¡")
                continue
        
        avg_epoch_loss = epoch_loss / len(train_loader)
        epoch_time = time.time() - epoch_start_time
        current_lr = optimizer.param_groups[0]['lr']
        
        # éªŒè¯
        avg_val_loss = None
        if val_loader:
            model.eval()
            val_loss = 0.0
            
            with torch.no_grad():
                for images, labels in val_loader:
                    images = images.to(device)
                    labels = labels.to(device)
                    
                    if use_amp:
                        with torch.cuda.amp.autocast():
                            outputs = model(images, class_labels=labels)
                            loss = outputs['loss']
                    else:
                        outputs = model(images, class_labels=labels)
                        loss = outputs['loss']
                    
                    val_loss += loss.item()
            
            avg_val_loss = val_loss / len(val_loader)
        else:
            avg_val_loss = avg_epoch_loss
        
        print(f"\nEpoch {epoch+1}/{config['training']['epochs']} - "
              f"Train Loss: {avg_epoch_loss:.4f} - "
              f"Val Loss: {avg_val_loss:.4f} - "
              f"Time: {epoch_time:.1f}s - "
              f"LR: {current_lr:.2e}")
        
        # æ˜¾ç¤ºéªŒè¯æŸå¤±è¶‹åŠ¿
        if best_loss != float('inf'):
            loss_diff = avg_val_loss - best_loss
            if loss_diff <= 0:
                print(f"ğŸ“‰ éªŒè¯æŸå¤±: {avg_val_loss:.4f} (æ–°çºªå½•! â¬‡{abs(loss_diff):.4f})")
            else:
                print(f"ğŸ“Š éªŒè¯æŸå¤±: {avg_val_loss:.4f} (è·æœ€ä½³: +{loss_diff:.4f})")
        
        # FIDè¯„ä¼°
        fid_score = None
        eval_interval = config['fid_evaluation'].get('eval_interval', 25)
        if fid_evaluator and (epoch + 1) % eval_interval == 0:
            print(f"ğŸ“Š è®¡ç®—é«˜ç²¾åº¦FIDåˆ†æ•°...")
            try:
                fid_start_time = time.time()
                
                num_samples = config['fid_evaluation'].get('num_samples', 5000)
                batch_size = config['fid_evaluation'].get('batch_size', 20)
                num_inference_steps = config['inference'].get('num_inference_steps', 250)
                guidance_scale = config['inference'].get('guidance_scale', 12.0)
                
                fid_score = fid_evaluator.evaluate_model(
                    model, 
                    num_samples=num_samples,
                    batch_size=batch_size,
                    num_classes=config['unet']['num_classes'],
                    num_inference_steps=num_inference_steps,
                    guidance_scale=guidance_scale
                )
                
                fid_time = time.time() - fid_start_time
                
                # æ˜¾ç¤ºFIDç»“æœå’Œè¶‹åŠ¿
                if best_fid != float('inf'):
                    fid_diff = fid_score - best_fid
                    if fid_score < best_fid:
                        print(f"âœ… FID: {fid_score:.2f} (æ–°çºªå½•! â¬‡{abs(fid_diff):.2f}) | æ—¶é—´: {fid_time:.1f}s")
                    else:
                        print(f"ğŸ“Š FID: {fid_score:.2f} (è·æœ€ä½³: +{fid_diff:.2f}) | æ—¶é—´: {fid_time:.1f}s")
                else:
                    print(f"âœ… FID: {fid_score:.2f} (é¦–æ¬¡è¯„ä¼°) | æ—¶é—´: {fid_time:.1f}s")
                
                # æ›´æ–°æœ€ä½³FID
                if fid_score < best_fid:
                    best_fid = fid_score
                    training_log['best_fid_epoch'] = epoch + 1
                    best_fid_model_path = os.path.join(save_dir, 'best_fid_model')
                    save_model_checkpoint(
                        model, 
                        best_fid_model_path, 
                        epoch=epoch+1, 
                        extra_info={'fid_score': fid_score, 'best_fid': True}
                    )
                    print(f"ğŸ‰ æ–°FIDæœ€ä½³æ¨¡å‹å·²ä¿å­˜!")
                    
                    # å¦‚æœè¾¾åˆ°ç›®æ ‡FID
                    if fid_score < 20:
                        print(f"ğŸ¯ è¾¾åˆ°ç›®æ ‡FIDï¼FID = {fid_score:.2f} < 20")
                
            except Exception as e:
                print(f"âš ï¸ FIDè®¡ç®—å¤±è´¥: {e}")
        
        # è®°å½•è®­ç»ƒæ—¥å¿—
        training_log['epochs'].append(epoch + 1)
        training_log['train_loss'].append(avg_epoch_loss)
        training_log['val_loss'].append(avg_val_loss)
        training_log['fid_scores'].append(fid_score)
        training_log['learning_rates'].append(current_lr)
        
        # ä¿å­˜è®­ç»ƒæ—¥å¿—
        with open(os.path.join(log_dir, 'fid_training_log.json'), 'w') as f:
            json.dump(training_log, f, indent=2)
        
        # ä¿å­˜æœ€ä½³æŸå¤±æ¨¡å‹ï¼ˆåªåœ¨åˆ›å»ºæ–°çºªå½•æ—¶è¾“å‡ºï¼‰
        if avg_val_loss < best_loss:
            best_loss = avg_val_loss
            best_model_path = os.path.join(save_dir, 'best_loss_model')
            save_model_checkpoint(
                model, 
                best_model_path, 
                epoch=epoch+1, 
                extra_info={'val_loss': best_loss, 'best_loss': True}
            )
        
        # å®šæœŸä¿å­˜checkpoint
        if (epoch + 1) % config['training']['save_interval'] == 0:
            checkpoint_path = os.path.join(save_dir, f'checkpoint_epoch_{epoch+1}')
            save_model_checkpoint(
                model, 
                checkpoint_path, 
                epoch=epoch+1, 
                extra_info={'train_loss': avg_epoch_loss, 'val_loss': avg_val_loss}
            )
            print(f"ğŸ’¾ å®šæœŸcheckpointå·²ä¿å­˜: epoch_{epoch+1}")
        
        # ç”Ÿæˆæ ·æœ¬å›¾åƒ
        if (epoch + 1) % config['training']['sample_interval'] == 0:
            print("ğŸ¨ ç”Ÿæˆé«˜è´¨é‡æ ·æœ¬å›¾åƒ...")
            save_sample_images(model, device, config, epoch + 1, sample_dir)
        
        print("-" * 60)
    
    # ä¿å­˜æœ€ç»ˆæ¨¡å‹
    final_model_path = os.path.join(save_dir, 'final_model')
    save_model_checkpoint(
        model, 
        final_model_path, 
        epoch=config['training']['epochs'], 
        extra_info={
            'final_train_loss': avg_epoch_loss,
            'final_val_loss': avg_val_loss,
            'best_fid': best_fid if best_fid != float('inf') else None,
            'training_completed': True
        }
    )
    
    # åˆ›å»ºæœ€ç»ˆæŠ¥å‘Š
    final_report = {
        'model_type': 'StableLDM_FID_Optimized',
        'training_completed': True,
        'total_epochs': config['training']['epochs'],
        'best_train_loss': best_loss,
        'best_fid_score': best_fid if best_fid != float('inf') else None,
        'best_fid_epoch': training_log['best_fid_epoch'],
        'final_train_loss': avg_epoch_loss,
        'final_val_loss': avg_val_loss,
        'unet_parameters': sum(p.numel() for p in model.unet.parameters()),
        'device': str(device),
        'mixed_precision': use_amp,
        'target_achieved': best_fid < 20 if best_fid != float('inf') else False,
        'config': config
    }
    
    with open(os.path.join(save_dir, 'final_report.json'), 'w') as f:
        json.dump(final_report, f, indent=2)
    
    print("=" * 80)
    print(f"ğŸ¯ FIDä¼˜åŒ–è®­ç»ƒå®Œæˆï¼")
    print(f"ğŸ“ æœ€ç»ˆæ¨¡å‹: {final_model_path}")
    print(f"ğŸ“‰ æœ€ä½³æŸå¤±: {best_loss:.4f}")
    if best_fid != float('inf'):
        print(f"ğŸ“Š æœ€ä½³FID: {best_fid:.2f} (Epoch {training_log['best_fid_epoch']})")
        if best_fid < 20:
            print(f"ğŸ‰ æˆåŠŸè¾¾åˆ°ç›®æ ‡FID < 20ï¼")
        else:
            print(f"âš ï¸ æœªè¾¾åˆ°ç›®æ ‡FIDï¼Œè¿˜éœ€ç»§ç»­ä¼˜åŒ–")
    print(f"ğŸ”¥ U-Netå‚æ•°é‡: {sum(p.numel() for p in model.unet.parameters()):,}")
    print("=" * 80)

if __name__ == "__main__":
    # è®¾ç½®éšæœºç§å­
    torch.manual_seed(42)
    if torch.cuda.is_available():
        torch.cuda.manual_seed(42)
    
    # å¼€å§‹FIDä¼˜åŒ–è®­ç»ƒ
    train_fid_optimized() 
