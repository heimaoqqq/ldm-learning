# LDM (Latent Diffusion Model) 配置文件

# VAE 相关配置 (使用预训练的VQ-VAE)
vae:
  model_path: "/kaggle/input/vae-best-fid/adv_vqvae_best_fid.pth"  # Kaggle VAE模型路径
  in_channels: 3
  latent_dim: 256
  num_embeddings: 512
  beta: 0.25
  vq_ema_decay: 0.99
  groups: 32
  freeze: true  # 冻结VAE参数

# 数据集配置
dataset:
  root_dir: "/kaggle/input/dataset"  # Kaggle数据集路径
  batch_size: 8  # 🔧 恢复到16获得更好的训练稳定性
  num_workers: 4  # 保持4个workers获得好的数据加载速度
  val_split: 0.2
  image_size: 256

# 扩散模型配置
diffusion:
  timesteps: 1000  # 扩散步数T
  noise_schedule: "cosine"  # linear 或 cosine (余弦调度更平滑)
  beta_start: 0.0001
  beta_end: 0.02
  clip_denoised: true

# U-Net 网络结构配置
unet:
  # 输入维度
  in_channels: 256  # 潜在空间通道数，与VAE的latent_dim一致
  out_channels: 256  # 输出通道数 (预测噪声)
  model_channels: 192  # 🔧 恢复到192获得更强的表达能力
  
  # 时间嵌入
  time_embed_dim: 768  # 🔧 恢复到768获得更丰富的时间表示
  
  # 条件嵌入 (身份标签)
  num_classes: 31  # 类别数量 (ID_1到ID_31，共31个用户)
  class_embed_dim: 384  # 🔧 恢复到384获得更好的条件控制
  
  # 网络层配置
  num_res_blocks: 3  # 🔧 保持3层获得更深的残差学习
  attention_resolutions: [4, 8, 16]  # 🔧 保持多层注意力获得更细致的特征
  channel_mult: [1, 2, 4, 8]  # 🔧 保持[1,2,4,8]获得更大的特征容量
  num_heads: 12  # 🔧 恢复到12获得更强的注意力能力
  use_scale_shift_norm: true  # 使用条件归一化
  dropout: 0.1  # Dropout率
  
  # 条件机制
  use_cross_attention: true  # 🔧 恢复交叉注意力融合条件
  use_self_attention: true   # 🔧 恢复自注意力

# 训练配置
training:
  epochs: 500
  lr: 0.00005  # 🔧 保持提高的学习率
  weight_decay: 0.01
  warmup_steps: 1000  # 🔧 保持快速预热
  
  # 保存设置
  save_dir: "ldm_models"
  save_interval: 50  # 每隔多少epoch保存一次
  sample_interval: 10  # 每隔多少epoch生成样本
  log_interval: 100  # 每隔多少步打印日志
  
  # 损失权重
  noise_loss_weight: 1.0
  
  # Classifier-Free Guidance
  use_cfg: true  # 使用无分类器引导
  cfg_dropout_prob: 0.2  # 🔧 保持强CFG训练
  
  # 梯度裁剪
  grad_clip_norm: 1.0  # 🔧 保持放宽的梯度裁剪
  
  # 调度器
  use_scheduler: true
  scheduler_type: "cosine_with_restarts"  # 🔧 保持优化的调度器

# FID评估配置
fid_evaluation:
  enabled: true  # 🔧 保持FID评估监控质量
  eval_interval: 5  # 🔧 恢复更频繁的评估 (每5个epoch)
  num_samples: 300  # 🔧 恢复更多样本获得准确的FID
  batch_size: 4  # 🔧 恢复到4获得更好的评估效率
  max_real_samples: 1000  # 🔧 恢复更多真实样本
  save_best_fid_model: true  # 保存最佳FID模型

# 推理配置
inference:
  num_inference_steps: 50  # 🔧 恢复到50步获得更好的生成质量
  guidance_scale: 7.5  # CFG引导强度
  eta: 0.0  # DDIM参数 (0为确定性采样)
  
  # 采样配置
  sample_batch_size: 4  # 🔧 恢复到4获得更好的生成效率
  num_samples_per_class: 8  # 🔧 恢复到8获得更多样化的样本
  
  # 输出设置
  output_dir: "generated_samples"
  save_format: "png"

# 设备配置
device: "auto"  # auto, cpu, cuda
mixed_precision: true  # 🔧 启用混合精度训练节省内存

# 日志配置
logging:
  use_wandb: false  # 是否使用wandb
  project_name: "LDM-Gait"
  experiment_name: "ldm_micro_doppler_32x32_latent"  # 微多普勒特征图实验
  log_dir: "logs" 
