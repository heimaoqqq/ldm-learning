# LDM (Latent Diffusion Model) é…ç½®æ–‡ä»¶

# VAE ç›¸å…³é…ç½® (ä½¿ç”¨é¢„è®­ç»ƒçš„VQ-VAE)
vae:
  model_path: "/kaggle/input/vae-best-fid/adv_vqvae_best_fid.pth"  # Kaggle VAEæ¨¡å‹è·¯å¾„
  in_channels: 3
  latent_dim: 256
  num_embeddings: 512
  beta: 0.25
  vq_ema_decay: 0.99
  groups: 32
  freeze: true  # å†»ç»“VAEå‚æ•°

# æ•°æ®é›†é…ç½®
dataset:
  root_dir: "/kaggle/input/dataset"  # Kaggleæ•°æ®é›†è·¯å¾„
  batch_size: 8  # ğŸ”§ æ¢å¤åˆ°16è·å¾—æ›´å¥½çš„è®­ç»ƒç¨³å®šæ€§
  num_workers: 4  # ä¿æŒ4ä¸ªworkersè·å¾—å¥½çš„æ•°æ®åŠ è½½é€Ÿåº¦
  val_split: 0.2
  image_size: 256

# æ‰©æ•£æ¨¡å‹é…ç½®
diffusion:
  timesteps: 1000  # æ‰©æ•£æ­¥æ•°T
  noise_schedule: "cosine"  # linear æˆ– cosine (ä½™å¼¦è°ƒåº¦æ›´å¹³æ»‘)
  beta_start: 0.0001
  beta_end: 0.02
  clip_denoised: true

# U-Net ç½‘ç»œç»“æ„é…ç½®
unet:
  # è¾“å…¥ç»´åº¦
  in_channels: 256  # æ½œåœ¨ç©ºé—´é€šé“æ•°ï¼Œä¸VAEçš„latent_dimä¸€è‡´
  out_channels: 256  # è¾“å‡ºé€šé“æ•° (é¢„æµ‹å™ªå£°)
  model_channels: 192  # ğŸ”§ æ¢å¤åˆ°192è·å¾—æ›´å¼ºçš„è¡¨è¾¾èƒ½åŠ›
  
  # æ—¶é—´åµŒå…¥
  time_embed_dim: 768  # ğŸ”§ æ¢å¤åˆ°768è·å¾—æ›´ä¸°å¯Œçš„æ—¶é—´è¡¨ç¤º
  
  # æ¡ä»¶åµŒå…¥ (èº«ä»½æ ‡ç­¾)
  num_classes: 31  # ç±»åˆ«æ•°é‡ (ID_1åˆ°ID_31ï¼Œå…±31ä¸ªç”¨æˆ·)
  class_embed_dim: 384  # ğŸ”§ æ¢å¤åˆ°384è·å¾—æ›´å¥½çš„æ¡ä»¶æ§åˆ¶
  
  # ç½‘ç»œå±‚é…ç½®
  num_res_blocks: 3  # ğŸ”§ ä¿æŒ3å±‚è·å¾—æ›´æ·±çš„æ®‹å·®å­¦ä¹ 
  attention_resolutions: [4, 8, 16]  # ğŸ”§ ä¿æŒå¤šå±‚æ³¨æ„åŠ›è·å¾—æ›´ç»†è‡´çš„ç‰¹å¾
  channel_mult: [1, 2, 4, 8]  # ğŸ”§ ä¿æŒ[1,2,4,8]è·å¾—æ›´å¤§çš„ç‰¹å¾å®¹é‡
  num_heads: 12  # ğŸ”§ æ¢å¤åˆ°12è·å¾—æ›´å¼ºçš„æ³¨æ„åŠ›èƒ½åŠ›
  use_scale_shift_norm: true  # ä½¿ç”¨æ¡ä»¶å½’ä¸€åŒ–
  dropout: 0.1  # Dropoutç‡
  
  # æ¡ä»¶æœºåˆ¶
  use_cross_attention: true  # ğŸ”§ æ¢å¤äº¤å‰æ³¨æ„åŠ›èåˆæ¡ä»¶
  use_self_attention: true   # ğŸ”§ æ¢å¤è‡ªæ³¨æ„åŠ›

# è®­ç»ƒé…ç½®
training:
  epochs: 500
  lr: 0.00005  # ğŸ”§ ä¿æŒæé«˜çš„å­¦ä¹ ç‡
  weight_decay: 0.01
  warmup_steps: 1000  # ğŸ”§ ä¿æŒå¿«é€Ÿé¢„çƒ­
  
  # ä¿å­˜è®¾ç½®
  save_dir: "ldm_models"
  save_interval: 50  # æ¯éš”å¤šå°‘epochä¿å­˜ä¸€æ¬¡
  sample_interval: 10  # æ¯éš”å¤šå°‘epochç”Ÿæˆæ ·æœ¬
  log_interval: 100  # æ¯éš”å¤šå°‘æ­¥æ‰“å°æ—¥å¿—
  
  # æŸå¤±æƒé‡
  noise_loss_weight: 1.0
  
  # Classifier-Free Guidance
  use_cfg: true  # ä½¿ç”¨æ— åˆ†ç±»å™¨å¼•å¯¼
  cfg_dropout_prob: 0.2  # ğŸ”§ ä¿æŒå¼ºCFGè®­ç»ƒ
  
  # æ¢¯åº¦è£å‰ª
  grad_clip_norm: 1.0  # ğŸ”§ ä¿æŒæ”¾å®½çš„æ¢¯åº¦è£å‰ª
  
  # è°ƒåº¦å™¨
  use_scheduler: true
  scheduler_type: "cosine_with_restarts"  # ğŸ”§ ä¿æŒä¼˜åŒ–çš„è°ƒåº¦å™¨

# FIDè¯„ä¼°é…ç½®
fid_evaluation:
  enabled: true  # ğŸ”§ ä¿æŒFIDè¯„ä¼°ç›‘æ§è´¨é‡
  eval_interval: 5  # ğŸ”§ æ¢å¤æ›´é¢‘ç¹çš„è¯„ä¼° (æ¯5ä¸ªepoch)
  num_samples: 300  # ğŸ”§ æ¢å¤æ›´å¤šæ ·æœ¬è·å¾—å‡†ç¡®çš„FID
  batch_size: 4  # ğŸ”§ æ¢å¤åˆ°4è·å¾—æ›´å¥½çš„è¯„ä¼°æ•ˆç‡
  max_real_samples: 1000  # ğŸ”§ æ¢å¤æ›´å¤šçœŸå®æ ·æœ¬
  save_best_fid_model: true  # ä¿å­˜æœ€ä½³FIDæ¨¡å‹

# æ¨ç†é…ç½®
inference:
  num_inference_steps: 50  # ğŸ”§ æ¢å¤åˆ°50æ­¥è·å¾—æ›´å¥½çš„ç”Ÿæˆè´¨é‡
  guidance_scale: 7.5  # CFGå¼•å¯¼å¼ºåº¦
  eta: 0.0  # DDIMå‚æ•° (0ä¸ºç¡®å®šæ€§é‡‡æ ·)
  
  # é‡‡æ ·é…ç½®
  sample_batch_size: 4  # ğŸ”§ æ¢å¤åˆ°4è·å¾—æ›´å¥½çš„ç”Ÿæˆæ•ˆç‡
  num_samples_per_class: 8  # ğŸ”§ æ¢å¤åˆ°8è·å¾—æ›´å¤šæ ·åŒ–çš„æ ·æœ¬
  
  # è¾“å‡ºè®¾ç½®
  output_dir: "generated_samples"
  save_format: "png"

# è®¾å¤‡é…ç½®
device: "auto"  # auto, cpu, cuda
mixed_precision: true  # ğŸ”§ å¯ç”¨æ··åˆç²¾åº¦è®­ç»ƒèŠ‚çœå†…å­˜

# æ—¥å¿—é…ç½®
logging:
  use_wandb: false  # æ˜¯å¦ä½¿ç”¨wandb
  project_name: "LDM-Gait"
  experiment_name: "ldm_micro_doppler_32x32_latent"  # å¾®å¤šæ™®å‹’ç‰¹å¾å›¾å®éªŒ
  log_dir: "logs" 
