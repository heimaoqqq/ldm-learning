# LDM (Latent Diffusion Model) é…ç½®æ–‡ä»¶ - åŸºäºStable Diffusionè½»é‡åŒ–ç‰ˆæœ¬

# VAE ç›¸å…³é…ç½® (ä½¿ç”¨é¢„è®­ç»ƒçš„VQ-VAE)
vae:
  model_path: "/kaggle/input/vae-best-fid/adv_vqvae_best_fid.pth"  
  in_channels: 3
  latent_dim: 256  # VAEæ½œåœ¨ç»´åº¦
  num_embeddings: 512
  beta: 0.25
  vq_ema_decay: 0.99
  groups: 32
  freeze: true  # å†»ç»“VAEå‚æ•°
  # VAEè¾“å‡ºä¿¡æ¯ï¼ˆç”¨äºU-Neté€‚é…ï¼‰
  latent_height: 32  # 256/8 = 32
  latent_width: 32
  latent_channels: 256

# æ•°æ®é›†é…ç½®
dataset:
  root_dir: "/kaggle/input/dataset"  # Kaggleæ•°æ®é›†è·¯å¾„
  batch_size: 8  # ğŸš€ è½»é‡åŒ–åå¯ä»¥å¢å¤§batch size
  num_workers: 2
  val_split: 0.2
  image_size: 256

# æ‰©æ•£æ¨¡å‹é…ç½®
diffusion:
  timesteps: 1000
  noise_schedule: "scaled_linear"  # ğŸ”§ SDä½¿ç”¨çš„è°ƒåº¦
  beta_start: 0.00085
  beta_end: 0.012
  scheduler_type: "ddim"
  clip_denoised: true
  prediction_type: "epsilon"  # é¢„æµ‹å™ªå£°

# U-Net ç½‘ç»œç»“æ„é…ç½® (åŸºäºStable Diffusionè½»é‡åŒ–)
unet:
  # è¾“å…¥è¾“å‡ºç»´åº¦
  in_channels: 256  # åŒ¹é…VAEæ½œåœ¨é€šé“æ•°
  out_channels: 256  # é¢„æµ‹å™ªå£°
  
  # åŸºç¡€æ¨¡å‹é…ç½®
  model_channels: 128  # ğŸš€ å¤§å¹…ç®€åŒ–ï¼š320->128
  num_res_blocks: 2  # ğŸš€ å‡å°‘ResNetå—ï¼š3->2
  attention_resolutions: [4, 2]  # ğŸš€ ç®€åŒ–æ³¨æ„åŠ›å±‚
  channel_mult: [1, 2, 4]  # ğŸš€ ç®€åŒ–é€šé“å€æ•°ï¼š[1,2,4,8]->[1,2,4]
  
  # æ³¨æ„åŠ›é…ç½®
  num_head_channels: 32  # ğŸš€ å‡å°‘æ³¨æ„åŠ›å¤´ç»´åº¦
  use_spatial_transformer: true  # ä½¿ç”¨ç©ºé—´transformer
  transformer_depth: 1  # ğŸš€ å•å±‚transformer
  
  # æ¡ä»¶åµŒå…¥
  num_classes: 31  # ç±»åˆ«æ•°é‡
  use_fp16: true  # ğŸš€ å¯ç”¨åŠç²¾åº¦
  
  # æ—¶é—´åµŒå…¥
  time_embed_dim: 512  # 128 * 4

# è®­ç»ƒé…ç½®
training:
  epochs: 200  # ğŸš€ å‡å°‘è®­ç»ƒè½®æ•°ï¼Œæ›´å¿«æ”¶æ•›
  lr: 0.0001  # ğŸš€ æé«˜å­¦ä¹ ç‡ï¼Œè½»é‡æ¨¡å‹æ›´å®¹æ˜“è®­ç»ƒ
  weight_decay: 0.01
  warmup_steps: 1000
  
  # æ¢¯åº¦ç´¯ç§¯
  gradient_accumulation_steps: 1
  
  # ä¿å­˜è®¾ç½®
  save_dir: "sd_ldm_models"
  save_interval: 25  # æ›´é¢‘ç¹ä¿å­˜
  sample_interval: 10  # æ›´é¢‘ç¹ç”Ÿæˆæ ·æœ¬
  log_interval: 50
  
  # æŸå¤±é…ç½®
  loss_type: "l2"  # MSEæŸå¤±
  
  # Classifier-Free Guidance
  use_cfg: true
  cfg_dropout_prob: 0.15  # SDå…¸å‹å€¼
  
  # ä¼˜åŒ–å™¨é…ç½®
  optimizer: "adamw"
  beta1: 0.9
  beta2: 0.999
  eps: 0.00000001
  
  # æ¢¯åº¦è£å‰ª
  grad_clip_norm: 1.0
  
  # è°ƒåº¦å™¨
  use_scheduler: true
  scheduler_type: "cosine"

# FIDè¯„ä¼°é…ç½®
fid_evaluation:
  enabled: true
  eval_interval: 5  # æ¯5ä¸ªepochè¯„ä¼°
  num_samples: 1000  # ğŸš€ å‡å°‘æ ·æœ¬æ•°ï¼Œå¿«é€Ÿè¯„ä¼°
  batch_size: 16  # æ›´å¤§çš„batch size
  max_real_samples: 1000
  save_best_fid_model: true

# æ¨ç†é…ç½®
inference:
  num_inference_steps: 250  # ğŸš€ å‡å°‘æ¨ç†æ­¥æ•°ï¼Œæ›´å¿«ç”Ÿæˆ
  guidance_scale: 7.5
  eta: 0.0  # DDIMç¡®å®šæ€§é‡‡æ ·
  
  # é‡‡æ ·é…ç½®
  sample_batch_size: 4
  num_samples_per_class: 2
  
  # è¾“å‡ºè®¾ç½®
  output_dir: "generated_samples"
  save_format: "png"

# è®¾å¤‡é…ç½®
device: "auto"
mixed_precision: true
use_ema: true  # ğŸš€ ä½¿ç”¨EMAæé«˜ç”Ÿæˆè´¨é‡
ema_decay: 0.9999

# æ—¥å¿—é…ç½®
logging:
  use_wandb: false
  project_name: "SD-LDM-Gait"
  experiment_name: "sd_ldm_lightweight"
  log_dir: "logs" 
