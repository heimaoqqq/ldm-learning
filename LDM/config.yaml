# LDM (Latent Diffusion Model) 配置文件

# VAE 相关配置 (使用预训练的VQ-VAE)
vae:
  model_path: "/kaggle/input/vae-best-fid/adv_vqvae_best_fid.pth"  # Kaggle VAE模型路径
  in_channels: 3
  latent_dim: 256
  num_embeddings: 512
  beta: 0.25
  vq_ema_decay: 0.99
  groups: 32
  freeze: true  # 冻结VAE参数

# 数据集配置
dataset:
  root_dir: "/kaggle/input/dataset"  # Kaggle数据集路径
  batch_size: 8  # 🔧 从16大幅减少到4 (节省75%内存)
  num_workers: 4  # 🔧 减少workers避免额外内存占用
  val_split: 0.2
  image_size: 256

# 扩散模型配置
diffusion:
  timesteps: 1000  # 扩散步数T
  noise_schedule: "cosine"  # linear 或 cosine (余弦调度更平滑)
  beta_start: 0.0001
  beta_end: 0.02
  clip_denoised: true

# U-Net 网络结构配置
unet:
  # 输入维度
  in_channels: 256  # 潜在空间通道数，与VAE的latent_dim一致
  out_channels: 256  # 输出通道数 (预测噪声)
  model_channels: 128  # 🔧 从192降回128 (减少内存占用)
  
  # 时间嵌入
  time_embed_dim: 512  # 🔧 从768降到512 (减少内存)
  
  # 条件嵌入 (身份标签)
  num_classes: 31  # 类别数量 (ID_1到ID_31，共31个用户)
  class_embed_dim: 256  # 🔧 从384降到256 (减少内存)
  
  # 网络层配置
  num_res_blocks: 3  # 🔧 从2增加到3 (更深的残差学习)
  attention_resolutions: [4, 8, 16]  # 🔧 从[8,16]扩展到[4,8,16] (更多注意力层)
  channel_mult: [1, 2, 4, 8]  # 🔧 从[1,2,4,4]改为[1,2,4,8] (更大的特征容量)
  num_heads: 12  # 🔧 从8增加到12 (更强的注意力)
  use_scale_shift_norm: true  # 使用条件归一化
  dropout: 0.1  # Dropout率
  
  # 条件机制
  use_cross_attention: true  # 使用交叉注意力融合条件
  use_self_attention: true   # 使用自注意力

# 训练配置
training:
  epochs: 500
  lr: 0.00005  # 🔧 进一步提高学习率 (从0.00001增加到0.00005)
  weight_decay: 0.01
  warmup_steps: 1000  # 🔧 减少预热步数，更快进入高学习率
  
  # 保存设置
  save_dir: "ldm_models"
  save_interval: 50  # 每隔多少epoch保存一次
  sample_interval: 10  # 每隔多少epoch生成样本
  log_interval: 100  # 每隔多少步打印日志
  
  # 损失权重
  noise_loss_weight: 1.0
  
  # Classifier-Free Guidance
  use_cfg: true  # 使用无分类器引导
  cfg_dropout_prob: 0.2  # 🔧 进一步增加CFG训练强度 (从0.15增加到0.2)
  
  # 梯度裁剪
  grad_clip_norm: 1.0  # 🔧 进一步放宽梯度裁剪 (从0.5增加到1.0)
  
  # 调度器
  use_scheduler: true
  scheduler_type: "cosine_with_restarts"  # 🔧 使用带重启的余弦调度器

# FID评估配置
fid_evaluation:
  enabled: true  # 🔧 启用FID评估以监控生成质量
  eval_interval: 10  # 如果启用，减少评估频率
  num_samples: 100  # 🔧 大幅减少样本数 (从300到100)
  batch_size: 2  # 🔧 从4减少到2 (节省内存)
  max_real_samples: 500  # 🔧 减少真实样本数
  save_best_fid_model: true  # 保存最佳FID模型

# 推理配置
inference:
  num_inference_steps: 25  # 推理时的去噪步数 (从50减少到25以节省时间)
  guidance_scale: 7.5  # CFG引导强度
  eta: 0.0  # DDIM参数 (0为确定性采样)
  
  # 采样配置
  sample_batch_size: 2  # 🔧 从4减少到2 (节省内存)
  num_samples_per_class: 4  # 🔧 从8减少到4 (节省内存)
  
  # 输出设置
  output_dir: "generated_samples"
  save_format: "png"

# 设备配置
device: "auto"  # auto, cpu, cuda
mixed_precision: true  # 🔧 启用混合精度训练节省内存

# 日志配置
logging:
  use_wandb: false  # 是否使用wandb
  project_name: "LDM-Gait"
  experiment_name: "ldm_micro_doppler_32x32_latent"  # 微多普勒特征图实验
  log_dir: "logs" 
