# LDM (Latent Diffusion Model) é…ç½®æ–‡ä»¶

# VAE ç›¸å…³é…ç½® (ä½¿ç”¨é¢„è®­ç»ƒçš„VQ-VAE)
vae:
  model_path: "/kaggle/input/vae-best-fid/adv_vqvae_best_fid.pth"  # Kaggle VAEæ¨¡å‹è·¯å¾„
  in_channels: 3
  latent_dim: 256
  num_embeddings: 512
  beta: 0.25
  vq_ema_decay: 0.99
  groups: 32
  freeze: true  # å†»ç»“VAEå‚æ•°

# æ•°æ®é›†é…ç½®
dataset:
  root_dir: "/kaggle/input/dataset"  # Kaggleæ•°æ®é›†è·¯å¾„
  batch_size: 8  # ğŸ”§ ä»16å¤§å¹…å‡å°‘åˆ°4 (èŠ‚çœ75%å†…å­˜)
  num_workers: 4  # ğŸ”§ å‡å°‘workersé¿å…é¢å¤–å†…å­˜å ç”¨
  val_split: 0.2
  image_size: 256

# æ‰©æ•£æ¨¡å‹é…ç½®
diffusion:
  timesteps: 1000  # æ‰©æ•£æ­¥æ•°T
  noise_schedule: "cosine"  # linear æˆ– cosine (ä½™å¼¦è°ƒåº¦æ›´å¹³æ»‘)
  beta_start: 0.0001
  beta_end: 0.02
  clip_denoised: true

# U-Net ç½‘ç»œç»“æ„é…ç½®
unet:
  # è¾“å…¥ç»´åº¦
  in_channels: 256  # æ½œåœ¨ç©ºé—´é€šé“æ•°ï¼Œä¸VAEçš„latent_dimä¸€è‡´
  out_channels: 256  # è¾“å‡ºé€šé“æ•° (é¢„æµ‹å™ªå£°)
  model_channels: 128  # ğŸ”§ ä»192é™å›128 (å‡å°‘å†…å­˜å ç”¨)
  
  # æ—¶é—´åµŒå…¥
  time_embed_dim: 512  # ğŸ”§ ä»768é™åˆ°512 (å‡å°‘å†…å­˜)
  
  # æ¡ä»¶åµŒå…¥ (èº«ä»½æ ‡ç­¾)
  num_classes: 31  # ç±»åˆ«æ•°é‡ (ID_1åˆ°ID_31ï¼Œå…±31ä¸ªç”¨æˆ·)
  class_embed_dim: 256  # ğŸ”§ ä»384é™åˆ°256 (å‡å°‘å†…å­˜)
  
  # ç½‘ç»œå±‚é…ç½®
  num_res_blocks: 3  # ğŸ”§ ä»2å¢åŠ åˆ°3 (æ›´æ·±çš„æ®‹å·®å­¦ä¹ )
  attention_resolutions: [4, 8, 16]  # ğŸ”§ ä»[8,16]æ‰©å±•åˆ°[4,8,16] (æ›´å¤šæ³¨æ„åŠ›å±‚)
  channel_mult: [1, 2, 4, 8]  # ğŸ”§ ä»[1,2,4,4]æ”¹ä¸º[1,2,4,8] (æ›´å¤§çš„ç‰¹å¾å®¹é‡)
  num_heads: 12  # ğŸ”§ ä»8å¢åŠ åˆ°12 (æ›´å¼ºçš„æ³¨æ„åŠ›)
  use_scale_shift_norm: true  # ä½¿ç”¨æ¡ä»¶å½’ä¸€åŒ–
  dropout: 0.1  # Dropoutç‡
  
  # æ¡ä»¶æœºåˆ¶
  use_cross_attention: true  # ä½¿ç”¨äº¤å‰æ³¨æ„åŠ›èåˆæ¡ä»¶
  use_self_attention: true   # ä½¿ç”¨è‡ªæ³¨æ„åŠ›

# è®­ç»ƒé…ç½®
training:
  epochs: 500
  lr: 0.00005  # ğŸ”§ è¿›ä¸€æ­¥æé«˜å­¦ä¹ ç‡ (ä»0.00001å¢åŠ åˆ°0.00005)
  weight_decay: 0.01
  warmup_steps: 1000  # ğŸ”§ å‡å°‘é¢„çƒ­æ­¥æ•°ï¼Œæ›´å¿«è¿›å…¥é«˜å­¦ä¹ ç‡
  
  # ä¿å­˜è®¾ç½®
  save_dir: "ldm_models"
  save_interval: 50  # æ¯éš”å¤šå°‘epochä¿å­˜ä¸€æ¬¡
  sample_interval: 10  # æ¯éš”å¤šå°‘epochç”Ÿæˆæ ·æœ¬
  log_interval: 100  # æ¯éš”å¤šå°‘æ­¥æ‰“å°æ—¥å¿—
  
  # æŸå¤±æƒé‡
  noise_loss_weight: 1.0
  
  # Classifier-Free Guidance
  use_cfg: true  # ä½¿ç”¨æ— åˆ†ç±»å™¨å¼•å¯¼
  cfg_dropout_prob: 0.2  # ğŸ”§ è¿›ä¸€æ­¥å¢åŠ CFGè®­ç»ƒå¼ºåº¦ (ä»0.15å¢åŠ åˆ°0.2)
  
  # æ¢¯åº¦è£å‰ª
  grad_clip_norm: 1.0  # ğŸ”§ è¿›ä¸€æ­¥æ”¾å®½æ¢¯åº¦è£å‰ª (ä»0.5å¢åŠ åˆ°1.0)
  
  # è°ƒåº¦å™¨
  use_scheduler: true
  scheduler_type: "cosine_with_restarts"  # ğŸ”§ ä½¿ç”¨å¸¦é‡å¯çš„ä½™å¼¦è°ƒåº¦å™¨

# FIDè¯„ä¼°é…ç½®
fid_evaluation:
  enabled: true  # ğŸ”§ å¯ç”¨FIDè¯„ä¼°ä»¥ç›‘æ§ç”Ÿæˆè´¨é‡
  eval_interval: 10  # å¦‚æœå¯ç”¨ï¼Œå‡å°‘è¯„ä¼°é¢‘ç‡
  num_samples: 100  # ğŸ”§ å¤§å¹…å‡å°‘æ ·æœ¬æ•° (ä»300åˆ°100)
  batch_size: 2  # ğŸ”§ ä»4å‡å°‘åˆ°2 (èŠ‚çœå†…å­˜)
  max_real_samples: 500  # ğŸ”§ å‡å°‘çœŸå®æ ·æœ¬æ•°
  save_best_fid_model: true  # ä¿å­˜æœ€ä½³FIDæ¨¡å‹

# æ¨ç†é…ç½®
inference:
  num_inference_steps: 25  # æ¨ç†æ—¶çš„å»å™ªæ­¥æ•° (ä»50å‡å°‘åˆ°25ä»¥èŠ‚çœæ—¶é—´)
  guidance_scale: 7.5  # CFGå¼•å¯¼å¼ºåº¦
  eta: 0.0  # DDIMå‚æ•° (0ä¸ºç¡®å®šæ€§é‡‡æ ·)
  
  # é‡‡æ ·é…ç½®
  sample_batch_size: 2  # ğŸ”§ ä»4å‡å°‘åˆ°2 (èŠ‚çœå†…å­˜)
  num_samples_per_class: 4  # ğŸ”§ ä»8å‡å°‘åˆ°4 (èŠ‚çœå†…å­˜)
  
  # è¾“å‡ºè®¾ç½®
  output_dir: "generated_samples"
  save_format: "png"

# è®¾å¤‡é…ç½®
device: "auto"  # auto, cpu, cuda
mixed_precision: true  # ğŸ”§ å¯ç”¨æ··åˆç²¾åº¦è®­ç»ƒèŠ‚çœå†…å­˜

# æ—¥å¿—é…ç½®
logging:
  use_wandb: false  # æ˜¯å¦ä½¿ç”¨wandb
  project_name: "LDM-Gait"
  experiment_name: "ldm_micro_doppler_32x32_latent"  # å¾®å¤šæ™®å‹’ç‰¹å¾å›¾å®éªŒ
  log_dir: "logs" 
