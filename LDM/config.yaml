# LDM (Latent Diffusion Model) é…ç½®æ–‡ä»¶

# VAE ç›¸å…³é…ç½® (ä½¿ç”¨é¢„è®­ç»ƒçš„VQ-VAE)
vae:
  model_path: "/kaggle/input/vae-best-fid/adv_vqvae_best_fid.pth"  # Kaggle VAEæ¨¡å‹è·¯å¾„
  in_channels: 3
  latent_dim: 256
  num_embeddings: 512
  beta: 0.25
  vq_ema_decay: 0.99
  groups: 32
  freeze: true  # å†»ç»“VAEå‚æ•°

# æ•°æ®é›†é…ç½®
dataset:
  root_dir: "/kaggle/input/dataset"  # Kaggleæ•°æ®é›†è·¯å¾„
  batch_size: 6  # ğŸ¯ å¹³è¡¡ç‚¹ï¼šä¿æŒåˆç†batch sizeä½†é¿å…OOM
  num_workers: 2  # ä¿æŒ2ä¸ªworkerså‡å°‘CPUå†…å­˜å ç”¨
  val_split: 0.2
  image_size: 256

# æ‰©æ•£æ¨¡å‹é…ç½®
diffusion:
  timesteps: 1000  # æ‰©æ•£æ­¥æ•°T
  noise_schedule: "cosine"  # linear æˆ– cosine (ä½™å¼¦è°ƒåº¦æ›´å¹³æ»‘)
  beta_start: 0.0001
  beta_end: 0.02
  clip_denoised: true

# U-Net ç½‘ç»œç»“æ„é…ç½®
unet:
  # è¾“å…¥ç»´åº¦
  in_channels: 256  # æ½œåœ¨ç©ºé—´é€šé“æ•°ï¼Œä¸VAEçš„latent_dimä¸€è‡´
  out_channels: 256  # è¾“å‡ºé€šé“æ•° (é¢„æµ‹å™ªå£°)
  model_channels: 160  # ğŸ¯ é€‚ä¸­é€‰æ‹©ï¼šä»‹äº128-192ä¹‹é—´ï¼Œä¿æŒè¡¨è¾¾èƒ½åŠ›
  
  # æ—¶é—´åµŒå…¥
  time_embed_dim: 640  # ğŸ¯ é€‚ä¸­é€‰æ‹©ï¼šä»‹äº512-768ä¹‹é—´ï¼Œä¿æŒæ—¶é—´è¡¨ç¤ºèƒ½åŠ›
  
  # æ¡ä»¶åµŒå…¥ (èº«ä»½æ ‡ç­¾)
  num_classes: 31  # ç±»åˆ«æ•°é‡ (ID_1åˆ°ID_31ï¼Œå…±31ä¸ªç”¨æˆ·)
  class_embed_dim: 320  # ğŸ¯ é€‚ä¸­é€‰æ‹©ï¼šä»‹äº256-384ä¹‹é—´ï¼Œä¿æŒæ¡ä»¶æ§åˆ¶
  
  # ç½‘ç»œå±‚é…ç½®
  num_res_blocks: 3  # ğŸ¯ ä¿æŒ3å±‚ï¼Œè¿™å¯¹è´¨é‡å¾ˆé‡è¦
  attention_resolutions: [8, 16]  # ğŸ¯ å»æ‰æœ€ç»†ç²’åº¦[4]ï¼Œæ³¨æ„åŠ›å¾ˆè€—å†…å­˜
  channel_mult: [1, 2, 4, 6]  # ğŸ¯ é™ä½æœ€åä¸€å±‚ï¼š[1,2,4,8]â†’[1,2,4,6]
  num_heads: 10  # ğŸ¯ é€‚ä¸­é€‰æ‹©ï¼šä»‹äº8-12ä¹‹é—´ï¼Œä¿æŒæ³¨æ„åŠ›èƒ½åŠ›
  use_scale_shift_norm: true  # ä½¿ç”¨æ¡ä»¶å½’ä¸€åŒ–
  dropout: 0.1  # Dropoutç‡
  
  # æ¡ä»¶æœºåˆ¶
  use_cross_attention: true  # ğŸ¯ ä¿æŒäº¤å‰æ³¨æ„åŠ›ï¼Œè¿™å¯¹æ¡ä»¶ç”Ÿæˆå¾ˆé‡è¦
  use_self_attention: true   # ğŸ¯ ä¿æŒè‡ªæ³¨æ„åŠ›

# è®­ç»ƒé…ç½®
training:
  epochs: 500
  lr: 0.00005  # ğŸ¯ ä¿æŒè¾ƒé«˜å­¦ä¹ ç‡
  weight_decay: 0.01
  warmup_steps: 1000  # ğŸ¯ ä¿æŒé¢„çƒ­æ­¥æ•°
  
  # ä¿å­˜è®¾ç½®
  save_dir: "ldm_models"
  save_interval: 50  # æ¯éš”å¤šå°‘epochä¿å­˜ä¸€æ¬¡
  sample_interval: 15  # ğŸ¯ ç•¥å¾®é™ä½é‡‡æ ·é¢‘ç‡èŠ‚çœå†…å­˜
  log_interval: 100  # æ¯éš”å¤šå°‘æ­¥æ‰“å°æ—¥å¿—
  
  # æŸå¤±æƒé‡
  noise_loss_weight: 1.0
  
  # Classifier-Free Guidance
  use_cfg: true  # ä½¿ç”¨æ— åˆ†ç±»å™¨å¼•å¯¼
  cfg_dropout_prob: 0.2  # ğŸ¯ ä¿æŒå¼ºCFGè®­ç»ƒ
  
  # æ¢¯åº¦è£å‰ª
  grad_clip_norm: 1.0  # ğŸ¯ ä¿æŒæ¢¯åº¦è£å‰ª
  
  # è°ƒåº¦å™¨
  use_scheduler: true
  scheduler_type: "cosine_with_restarts"  # ğŸ¯ ä¿æŒä¼˜åŒ–è°ƒåº¦å™¨

# FIDè¯„ä¼°é…ç½®
fid_evaluation:
  enabled: true  # ğŸ¯ ä¿æŒFIDè¯„ä¼°ç›‘æ§è´¨é‡
  eval_interval: 10  # ğŸ¯ é€‚ä¸­çš„è¯„ä¼°é¢‘ç‡
  num_samples: 200  # ğŸ¯ é€‚ä¸­çš„æ ·æœ¬æ•°ï¼Œå¹³è¡¡å‡†ç¡®æ€§å’Œå†…å­˜
  batch_size: 3  # ğŸ¯ é™ä½åˆ°3ï¼Œé…åˆä¸»è®­ç»ƒbatch_size
  max_real_samples: 800  # ğŸ¯ é€‚ä¸­çš„çœŸå®æ ·æœ¬æ•°
  save_best_fid_model: true  # ä¿å­˜æœ€ä½³FIDæ¨¡å‹

# æ¨ç†é…ç½®
inference:
  num_inference_steps: 40  # ğŸ¯ é€‚ä¸­çš„æ¨ç†æ­¥æ•°ï¼Œå¹³è¡¡è´¨é‡å’Œå†…å­˜
  guidance_scale: 7.5  # CFGå¼•å¯¼å¼ºåº¦
  eta: 0.0  # DDIMå‚æ•° (0ä¸ºç¡®å®šæ€§é‡‡æ ·)
  
  # é‡‡æ ·é…ç½®
  sample_batch_size: 3  # ğŸ¯ é…åˆè®­ç»ƒbatch_size
  num_samples_per_class: 6  # ğŸ¯ é€‚ä¸­çš„æ ·æœ¬æ•°é‡
  
  # è¾“å‡ºè®¾ç½®
  output_dir: "generated_samples"
  save_format: "png"

# è®¾å¤‡é…ç½®
device: "auto"  # auto, cpu, cuda
mixed_precision: true  # ğŸ¯ å¯ç”¨æ··åˆç²¾åº¦è®­ç»ƒèŠ‚çœå†…å­˜

# æ—¥å¿—é…ç½®
logging:
  use_wandb: false  # æ˜¯å¦ä½¿ç”¨wandb
  project_name: "LDM-Gait"
  experiment_name: "ldm_micro_doppler_32x32_latent"  # å¾®å¤šæ™®å‹’ç‰¹å¾å›¾å®éªŒ
  log_dir: "logs" 
