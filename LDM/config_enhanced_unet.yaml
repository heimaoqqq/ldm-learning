# å¢å¼ºç‰ˆU-Neté…ç½® - å®Œæ•´Transformerå®ç°
# ç›®æ ‡ï¼šå°†FIDé™åˆ°20ä»¥å†…ï¼Œä½¿ç”¨çœŸæ­£çš„å¤šå±‚Transformer

device: 'auto'  # 'cuda', 'cpu', or 'auto'

# VAEé…ç½® (é¢„è®­ç»ƒï¼Œå†»ç»“)
vae:
  in_channels: 3
  latent_dim: 256
  num_embeddings: 512
  beta: 0.25
  vq_ema_decay: 0.99
  groups: 1
  model_path: '../VAE/vae_ckpt/checkpoint_epoch_100.pth'
  freeze: true

# ğŸš€ ç®€åŒ–å¢å¼ºç‰ˆU-Net - åŒ…å«çœŸæ­£çš„å¤šå±‚Transformer
unet:
  type: 'simple_enhanced'    # ğŸš€ ä½¿ç”¨ç®€åŒ–å¢å¼ºç‰ˆ (115.8Må‚æ•°)
  in_channels: 256
  out_channels: 256
  model_channels: 192        # æ˜¾å­˜å‹å¥½çš„æ¨¡å‹å¤§å°
  num_classes: 31
  time_embed_dim: 768        # åˆç†çš„åµŒå…¥ç»´åº¦
  
  # ğŸš€ çœŸæ­£çš„Transformeré…ç½®
  transformer_depth: 3       # æ¯ä¸ªæ³¨æ„åŠ›å±‚3å±‚Transformer
  num_heads: 8               # 8ä¸ªæ³¨æ„åŠ›å¤´
  use_attention_layers: [1, 2]  # åœ¨ç¬¬1å±‚å’Œç¬¬2å±‚ä½¿ç”¨å¤šå±‚æ³¨æ„åŠ›
  
  # è¯´æ˜ï¼š
  # - 6ä¸ªæ³¨æ„åŠ›å±‚ Ã— 3å±‚Transformer = 18ä¸ªTransformerå—
  # - æ¯”ç®€å•ç‰ˆå¤š50.3Må‚æ•°ï¼Œä½†å¢åŠ äº†å¼ºå¤§çš„ç©ºé—´æ³¨æ„åŠ›èƒ½åŠ›
  # - é¢„æœŸèƒ½æ˜¾è‘—æ”¹å–„FIDå€¼

# æ‰©æ•£è¿‡ç¨‹é…ç½®
diffusion:
  timesteps: 1000
  beta_start: 0.0001
  beta_end: 0.02
  noise_schedule: 'linear'
  scheduler_type: 'ddim'  # ğŸš€ ä½¿ç”¨æ”¹è¿›çš„DDIMè°ƒåº¦å™¨

# æ¨ç†é…ç½® - é«˜è´¨é‡é‡‡æ ·
inference:
  num_inference_steps: 75   # ğŸš€ 75æ­¥é‡‡æ ·ï¼Œå¹³è¡¡è´¨é‡å’Œé€Ÿåº¦
  guidance_scale: 8.5       # ğŸš€ CFGå¼ºåº¦
  eta: 0.3                  # ğŸš€ DDIMéšæœºæ€§å‚æ•°
  
  # é‡‡æ ·é…ç½® - ğŸš€ èµ„æºä¼˜åŒ–
  sample_batch_size: 16     # ğŸš€ ä»8å¢åŠ åˆ°16ï¼ˆå……åˆ†åˆ©ç”¨æ˜¾å­˜ï¼‰
  num_samples_per_class: 10
  
  # è¾“å‡ºè®¾ç½®
  output_dir: "enhanced_samples"
  save_format: "png"

# è®­ç»ƒé…ç½® - é’ˆå¯¹Transformerä¼˜åŒ–
training:
  epochs: 600  # ğŸ¯ è¶³å¤Ÿçš„è®­ç»ƒè½®æ•°
  lr: 0.00008   # ğŸš€ ä»0.0001è½»å¾®é™ä½ï¼Œé€‚é…batch sizeè°ƒæ•´
  weight_decay: 0.02  # ğŸš€ æ­£åˆ™åŒ–é˜²æ­¢è¿‡æ‹Ÿåˆ
  warmup_steps: 3000  # ğŸš€ ä»5000è°ƒæ•´åˆ°3000ï¼Œé€‚é…æ ·æœ¬æ•°
  
  # æ¢¯åº¦ç´¯ç§¯ - ğŸš€ é’ˆå¯¹4587æ ·æœ¬ä¼˜åŒ–
  gradient_accumulation_steps: 3  # ğŸš€ è°ƒæ•´ä¸º3ï¼Œæœ‰æ•ˆbatch_size = 8Ã—3 = 24
  
  # æ—©åœç­–ç•¥
  early_stopping_patience: 45  # ğŸš€ åŸºäºFIDå€¼æ—©åœ
  early_stopping_metric: "fid"
  
  # ä¿å­˜è®¾ç½®
  save_dir: "enhanced_models"
  save_interval: 50  # ğŸš€ é¢‘ç¹ä¿å­˜
  sample_interval: 15  # ğŸš€ é¢‘ç¹ç”Ÿæˆæ ·æœ¬ç›‘æ§
  log_interval: 15
  
  # æŸå¤±é…ç½®
  loss_type: "l2"
  
  # Classifier-Free Guidance
  use_cfg: true
  cfg_dropout_prob: 0.15
  
  # ä¼˜åŒ–å™¨é…ç½®
  optimizer: "adamw"
  beta1: 0.9
  beta2: 0.999
  eps: 0.00000001
  
  # æ¢¯åº¦è£å‰ª
  grad_clip_norm: 0.5
  
  # è°ƒåº¦å™¨
  use_scheduler: true
  scheduler_type: "cosine"

# FIDè¯„ä¼°é…ç½® - é«˜ç²¾åº¦è¯„ä¼°
fid_evaluation:
  enabled: true
  eval_interval: 15        # ğŸš€ ä»20é™åˆ°15ï¼Œé€‚é…è¾ƒå°æ•°æ®é›†
  num_samples: 1500        # ğŸš€ ä»2000é™åˆ°1500ï¼Œé€‚é…éªŒè¯é›†è§„æ¨¡
  batch_size: 64           # ğŸš€ ä¿æŒ64ç”¨äºFIDè¯„ä¼°
  max_real_samples: 510    # ğŸš€ ä½¿ç”¨å…¨éƒ¨éªŒè¯é›†æ ·æœ¬
  save_best_fid_model: true
  
  # ğŸš€ åŠ é€Ÿå‚æ•°
  eval_classes: 3          # ğŸš€ åªè¯„ä¼°3ä¸ªéšæœºç±»åˆ«
  num_inference_steps: 50  # ğŸš€ è¯„ä¼°æ—¶ä½¿ç”¨50æ­¥
  parallel_generation: true  # ğŸš€ å¯ç”¨å¹¶è¡Œç”Ÿæˆ

# æ•°æ®é›†é…ç½® - ğŸš€ é’ˆå¯¹æ ·æœ¬æ•°ä¼˜åŒ–
dataset:
  root_dir: '/kaggle/input/dataset'  # ğŸ”§ æ­£ç¡®çš„Kaggleæ•°æ®é›†è·¯å¾„
  batch_size: 8            # ğŸš€ é’ˆå¯¹4587æ ·æœ¬ä¼˜åŒ–ï¼Œ8Ã—3ç´¯ç§¯=24æœ‰æ•ˆbatch
  num_workers: 8           # ğŸš€ å……åˆ†åˆ©ç”¨CPU
  val_split: 0.1           # ğŸš€ 10%éªŒè¯é›†ï¼Œé€‚é…å½“å‰æ•°æ®åˆ’åˆ†
  shuffle_train: true
  pin_memory: true         # ğŸš€ åŠ é€Ÿæ•°æ®ä¼ è¾“
  persistent_workers: true # ğŸš€ ä¿æŒworkerè¿›ç¨‹
  
  # ğŸš« æ•°æ®å¢å¼ºå·²ç§»é™¤ - å¯¹å¾®å¤šæ™®å‹’æ—¶é¢‘å›¾æœ‰å®³
  # åŸå› ï¼šæ°´å¹³ç¿»è½¬ã€æ—‹è½¬ã€é¢œè‰²æŠ–åŠ¨ä¼šç ´åæ—¶é¢‘å›¾çš„ç‰©ç†æ„ä¹‰
  # æ—¶é¢‘å›¾çš„æ—¶é—´è½´å’Œé¢‘ç‡è½´å…·æœ‰æ˜ç¡®çš„ç‰©ç†å«ä¹‰ï¼Œä¸åº”éšæ„å˜æ¢
  augmentation:
    enabled: false  # ğŸš« å®Œå…¨ç¦ç”¨æ•°æ®å¢å¼º

# EMAé…ç½®
use_ema: true
ema_decay: 0.99

# æ··åˆç²¾åº¦è®­ç»ƒ
mixed_precision: false  # ğŸ¯ è¿½æ±‚è´¨é‡ï¼Œå…³é—­æ··åˆç²¾åº¦

# æ—¥å¿—é…ç½®
logging:
  log_dir: "enhanced_logs"
  tensorboard: false
  wandb: false 

# ğŸš€ æ€§èƒ½ä¼˜åŒ–é…ç½® - ä¿å®ˆä¼˜åŒ–ä¿è¯è®­ç»ƒè´¨é‡
performance:
  # æ˜¾å­˜ä¼˜åŒ–
  empty_cache_interval: 30  # ğŸš€ ä»50é™åˆ°30ï¼Œæ›´é¢‘ç¹æ¸…ç†
  
  # CPUä¼˜åŒ–
  torch_num_threads: 8      # è®¾ç½®PyTorchçº¿ç¨‹æ•°
  
  # ç¼–è¯‘ä¼˜åŒ–
  compile_model: false      # ğŸš€ å…³é—­ç¼–è¯‘ï¼Œç¡®ä¿è®­ç»ƒç¨³å®šæ€§
  
  # é¢„å–ä¼˜åŒ–
  prefetch_factor: 4        # æ•°æ®é¢„å–å€æ•°

# ğŸš€ è®­ç»ƒè´¨é‡ç›‘æ§
quality_monitoring:
  # æŒ‡æ ‡æ”¹è¿›æ£€æµ‹
  improvement_threshold: 0.02  # FIDæ”¹è¿›é˜ˆå€¼
  loss_improvement_threshold: 0.001  # æŸå¤±æ”¹è¿›é˜ˆå€¼
  
  # è®­ç»ƒç¨³å®šæ€§ç›‘æ§
  gradient_norm_threshold: 10.0  # æ¢¯åº¦çˆ†ç‚¸æ£€æµ‹
  loss_spike_threshold: 2.0      # æŸå¤±çªå¢æ£€æµ‹ 
