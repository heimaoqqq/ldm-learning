# å¢å¼ºç‰ˆU-Neté…ç½® - å®Œæ•´Transformerå®ç°
# ç›®æ ‡ï¼šå°†FIDé™åˆ°20ä»¥å†…ï¼Œä½¿ç”¨çœŸæ­£çš„å¤šå±‚Transformer

device: 'auto'  # 'cuda', 'cpu', or 'auto'

# VAEé…ç½® (é¢„è®­ç»ƒï¼Œå†»ç»“)
vae:
  in_channels: 3
  latent_dim: 256
  num_embeddings: 512
  beta: 0.25
  vq_ema_decay: 0.99
  groups: 1
  model_path: '../VAE/vae_ckpt/checkpoint_epoch_100.pth'
  freeze: true

# ğŸš€ ç®€åŒ–å¢å¼ºç‰ˆU-Net - åŒ…å«çœŸæ­£çš„å¤šå±‚Transformer
unet:
  type: 'simple_enhanced'    # ğŸš€ ä½¿ç”¨ç®€åŒ–å¢å¼ºç‰ˆ (115.8Må‚æ•°)
  in_channels: 256
  out_channels: 256
  model_channels: 192        # æ˜¾å­˜å‹å¥½çš„æ¨¡å‹å¤§å°
  num_classes: 31
  time_embed_dim: 768        # åˆç†çš„åµŒå…¥ç»´åº¦
  
  # ğŸš€ çœŸæ­£çš„Transformeré…ç½®
  transformer_depth: 2       # æ¯ä¸ªæ³¨æ„åŠ›å±‚2å±‚Transformer
  num_heads: 8               # 8ä¸ªæ³¨æ„åŠ›å¤´
  use_attention_layers: [1, 2]  # åœ¨ç¬¬1å±‚å’Œç¬¬2å±‚ä½¿ç”¨å¤šå±‚æ³¨æ„åŠ›
  
  # è¯´æ˜ï¼š
  # - 6ä¸ªæ³¨æ„åŠ›å±‚ Ã— 2å±‚Transformer = 12ä¸ªTransformerå—
  # - æ¯”ç®€å•ç‰ˆå¤š50.3Må‚æ•°ï¼Œä½†å¢åŠ äº†å¼ºå¤§çš„ç©ºé—´æ³¨æ„åŠ›èƒ½åŠ›
  # - é¢„æœŸèƒ½æ˜¾è‘—æ”¹å–„FIDå€¼

# æ‰©æ•£è¿‡ç¨‹é…ç½®
diffusion:
  timesteps: 1000
  beta_start: 0.0001
  beta_end: 0.02
  noise_schedule: 'linear'
  scheduler_type: 'ddim'  # ğŸš€ ä½¿ç”¨æ”¹è¿›çš„DDIMè°ƒåº¦å™¨

# æ¨ç†é…ç½® - é«˜è´¨é‡é‡‡æ ·
inference:
  num_inference_steps: 75   # ğŸš€ 75æ­¥é‡‡æ ·ï¼Œå¹³è¡¡è´¨é‡å’Œé€Ÿåº¦
  guidance_scale: 8.5       # ğŸš€ CFGå¼ºåº¦
  eta: 0.3                  # ğŸš€ DDIMéšæœºæ€§å‚æ•°
  
  # é‡‡æ ·é…ç½®
  sample_batch_size: 8
  num_samples_per_class: 10
  
  # è¾“å‡ºè®¾ç½®
  output_dir: "enhanced_samples"
  save_format: "png"

# è®­ç»ƒé…ç½® - é’ˆå¯¹Transformerä¼˜åŒ–
training:
  epochs: 600  # ğŸ¯ è¶³å¤Ÿçš„è®­ç»ƒè½®æ•°
  lr: 0.0001   # ğŸš€ é€‚åˆTransformerçš„å­¦ä¹ ç‡
  weight_decay: 0.02  # ğŸš€ æ­£åˆ™åŒ–é˜²æ­¢è¿‡æ‹Ÿåˆ
  warmup_steps: 5000  # ğŸ¯ Transformeréœ€è¦warmup
  
  # æ¢¯åº¦ç´¯ç§¯ - æé«˜æœ‰æ•ˆbatch size
  gradient_accumulation_steps: 4  # ğŸ¯ æœ‰æ•ˆbatch_size = 6Ã—4 = 24
  
  # æ—©åœç­–ç•¥
  early_stopping_patience: 60  # ğŸš€ åŸºäºFIDå€¼æ—©åœ
  early_stopping_metric: "fid"
  
  # ä¿å­˜è®¾ç½®
  save_dir: "enhanced_models"
  save_interval: 50  # ğŸš€ é¢‘ç¹ä¿å­˜
  sample_interval: 20  # ğŸš€ é¢‘ç¹ç”Ÿæˆæ ·æœ¬ç›‘æ§
  log_interval: 20
  
  # æŸå¤±é…ç½®
  loss_type: "l2"
  
  # Classifier-Free Guidance
  use_cfg: true
  cfg_dropout_prob: 0.15
  
  # ä¼˜åŒ–å™¨é…ç½®
  optimizer: "adamw"
  beta1: 0.9
  beta2: 0.999
  eps: 0.00000001
  
  # æ¢¯åº¦è£å‰ª
  grad_clip_norm: 0.5
  
  # è°ƒåº¦å™¨
  use_scheduler: true
  scheduler_type: "cosine"

# FIDè¯„ä¼°é…ç½® - é«˜ç²¾åº¦è¯„ä¼°
fid_evaluation:
  enabled: true
  eval_interval: 20        # ğŸš€ æ¯20ä¸ªepochè¯„ä¼°
  num_samples: 2000         # ğŸš€ å……è¶³çš„è¯„ä¼°æ ·æœ¬
  batch_size: 32
  max_real_samples: 2000    # ğŸš€ å……è¶³çš„çœŸå®æ ·æœ¬
  save_best_fid_model: true

# æ•°æ®é›†é…ç½®
dataset:
  root_dir: '/kaggle/input/cell-classification-data/CellData/PCam'
  batch_size: 6  # ğŸ¯ å°batché…åˆæ¢¯åº¦ç´¯ç§¯
  num_workers: 2
  val_split: 0.1
  shuffle_train: true
  
  # æ•°æ®å¢å¼ºé…ç½®
  augmentation:
    horizontal_flip: true
    random_rotation: 15
    color_jitter: 0.1

# EMAé…ç½®
use_ema: true
ema_decay: 0.9999

# æ··åˆç²¾åº¦è®­ç»ƒ
mixed_precision: false  # ğŸ¯ è¿½æ±‚è´¨é‡ï¼Œå…³é—­æ··åˆç²¾åº¦

# æ—¥å¿—é…ç½®
logging:
  log_dir: "enhanced_logs"
  tensorboard: false
  wandb: false 
