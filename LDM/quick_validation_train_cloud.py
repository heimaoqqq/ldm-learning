"""
å¿«é€ŸéªŒè¯è®­ç»ƒ - äº‘æœåŠ¡å™¨å†…å­˜ä¼˜åŒ–ç‰ˆæœ¬
è§£å†³CUDA OOMé—®é¢˜ï¼Œä¼˜åŒ–å†…å­˜ä½¿ç”¨
"""
import torch
import torch.nn.functional as F
import numpy as np
import os
import sys
import gc
from tqdm import tqdm
import matplotlib.pyplot as plt

# äº‘ç¯å¢ƒè·¯å¾„è®¾ç½®
print("ğŸŒ äº‘æœåŠ¡å™¨ç¯å¢ƒåˆå§‹åŒ–...")
print(f"ğŸ“‚ å½“å‰å·¥ä½œç›®å½•: {os.getcwd()}")

# å†…å­˜ä¼˜åŒ–è®¾ç½®
torch.backends.cudnn.benchmark = True  # ä¼˜åŒ–cudnnæ€§èƒ½
if torch.cuda.is_available():
    torch.cuda.empty_cache()  # æ¸…ç©ºCUDAç¼“å­˜
    print(f"ğŸš€ CUDAè®¾å¤‡: {torch.cuda.get_device_name()}")
    print(f"ğŸ’¾ æ€»æ˜¾å­˜: {torch.cuda.get_device_properties(0).total_memory / 1024**3:.1f} GB")

# æ£€æŸ¥å¹¶å®‰è£…å¿…è¦çš„ä¾èµ–
def check_and_install_dependencies():
    """æ£€æŸ¥å¹¶å®‰è£…å¿…è¦çš„ä¾èµ–"""
    try:
        import diffusers
        print("âœ… diffusers å·²å®‰è£…")
    except ImportError:
        print("ğŸ“¦ å®‰è£… diffusers...")
        os.system("pip install diffusers transformers accelerate -q")
    
    try:
        import torchvision
        print("âœ… torchvision å·²å®‰è£…")
    except ImportError:
        print("ğŸ“¦ å®‰è£… torchvision...")
        os.system("pip install torchvision -q")

check_and_install_dependencies()

# æ·»åŠ è·¯å¾„ - äº‘ç¯å¢ƒé€‚é…
current_dir = os.path.dirname(os.path.abspath(__file__))
parent_dir = os.path.dirname(current_dir)
sys.path.append(current_dir)
sys.path.append(parent_dir)

# å°è¯•å¯¼å…¥æ‰€éœ€æ¨¡å—
try:
    from vae_ldm_standard import create_standard_vae_ldm
    print("âœ… æˆåŠŸå¯¼å…¥ vae_ldm_standard")
except ImportError as e:
    print(f"âŒ å¯¼å…¥ vae_ldm_standard å¤±è´¥: {e}")

try:
    from fid_evaluation import FIDEvaluator
    print("âœ… æˆåŠŸå¯¼å…¥ fid_evaluation")
except ImportError as e:
    print(f"âŒ å¯¼å…¥ fid_evaluation å¤±è´¥: {e}")

# äº‘ç¯å¢ƒæ•°æ®åŠ è½½å™¨
from torch.utils.data import Dataset, DataLoader
from torchvision import transforms
from PIL import Image
import glob
from sklearn.model_selection import train_test_split

class CloudGaitDataset(Dataset):
    """äº‘ç¯å¢ƒé€‚é…çš„æ•°æ®é›†ç±»"""
    
    def __init__(self, image_paths, class_ids, transform=None):
        self.image_paths = image_paths
        self.class_ids = class_ids
        self.transform = transform

    def __len__(self):
        return len(self.image_paths)

    def __getitem__(self, idx):
        img_path = self.image_paths[idx]
        image = Image.open(img_path).convert('RGB')
        if self.transform:
            image = self.transform(image)
        label = self.class_ids[idx]
        
        # ç¡®ä¿æ ‡ç­¾åœ¨æœ‰æ•ˆèŒƒå›´å†…
        if label < 0 or label > 30:
            label = max(0, min(30, label))
        
        return image, label

def build_cloud_dataloader(root_dir, batch_size=4, num_workers=2, val_split=0.3):
    """äº‘ç¯å¢ƒæ•°æ®åŠ è½½å™¨"""
    print(f"ğŸ” æ‰«æäº‘æ•°æ®é›†ç›®å½•: {root_dir}")
    
    transform = transforms.Compose([
        transforms.Resize((256, 256)),
        transforms.ToTensor(),
        transforms.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5])
    ])

    all_image_paths = []
    all_class_ids = []
    
    # æ£€æŸ¥ç›®å½•ç»“æ„
    if not os.path.exists(root_dir):
        raise ValueError(f"âŒ æ•°æ®é›†ç›®å½•ä¸å­˜åœ¨: {root_dir}")
    
    # æ”¯æŒID_1, ID_2, ... ID_31æ–‡ä»¶å¤¹ç»“æ„
    id_folders = []
    for item in os.listdir(root_dir):
        item_path = os.path.join(root_dir, item)
        if os.path.isdir(item_path) and item.startswith('ID_'):
            id_folders.append(item)
    
    if id_folders:
        print(f"ğŸ“ å‘ç°IDæ–‡ä»¶å¤¹ç»“æ„: {len(id_folders)} ä¸ªæ–‡ä»¶å¤¹")
        
        for folder_name in sorted(id_folders):
            folder_path = os.path.join(root_dir, folder_name)
            
            try:
                # æå–ç±»åˆ«ID
                class_id = int(folder_name.split('_')[1]) - 1  # è½¬æ¢ä¸º0-based
                
                if not (0 <= class_id <= 30):
                    print(f"âš ï¸  è·³è¿‡è¶…å‡ºèŒƒå›´çš„ç±»åˆ«: {folder_name}")
                    continue
                
                # æ”¶é›†å›¾ç‰‡
                folder_images = []
                for ext in ["*.jpg", "*.jpeg", "*.png", "*.bmp"]:
                    folder_images.extend(glob.glob(os.path.join(folder_path, ext)))
                
                print(f"  {folder_name}: {len(folder_images)} å¼ å›¾ç‰‡")
                
                all_image_paths.extend(folder_images)
                all_class_ids.extend([class_id] * len(folder_images))
                
            except (ValueError, IndexError) as e:
                print(f"âš ï¸  æ— æ³•è§£ææ–‡ä»¶å¤¹å {folder_name}: {e}")
                continue

    if not all_image_paths:
        raise ValueError(f"âŒ åœ¨ {root_dir} ä¸­æ²¡æœ‰æ‰¾åˆ°å›¾ç‰‡æ–‡ä»¶")

    print(f"ğŸ“Š æ•°æ®é›†ç»Ÿè®¡:")
    print(f"  æ€»å›¾ç‰‡æ•°: {len(all_image_paths)}")
    print(f"  ç±»åˆ«æ•°: {len(set(all_class_ids))}")

    # æ•°æ®é›†åˆ’åˆ†
    train_paths, val_paths, train_ids, val_ids = train_test_split(
        all_image_paths, all_class_ids, 
        test_size=val_split, 
        random_state=42,
        stratify=all_class_ids if len(set(all_class_ids)) > 1 else None
    )

    print(f"  è®­ç»ƒé›†: {len(train_paths)} å¼ ")
    print(f"  éªŒè¯é›†: {len(val_paths)} å¼ ")

    # åˆ›å»ºæ•°æ®é›†å’ŒåŠ è½½å™¨
    train_dataset = CloudGaitDataset(train_paths, train_ids, transform=transform)
    val_dataset = CloudGaitDataset(val_paths, val_ids, transform=transform)

    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, 
                             num_workers=num_workers, pin_memory=True)
    val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False, 
                           num_workers=num_workers, pin_memory=True)
    
    return train_loader, val_loader, len(train_dataset), len(val_dataset)

class OptimizedCloudTrainer:
    """å†…å­˜ä¼˜åŒ–çš„äº‘ç¯å¢ƒå¿«é€ŸéªŒè¯è®­ç»ƒå™¨"""
    
    def __init__(self, data_dir='/kaggle/input/dataset'):
        self.device = 'cuda' if torch.cuda.is_available() else 'cpu'
        print(f"ğŸš€ äº‘æœåŠ¡å™¨è®¾å¤‡: {self.device}")
        
        # å†…å­˜ä¼˜åŒ–é…ç½®
        self.config = {
            'batch_size': 4,  # å‡å°æ‰¹æ¬¡å¤§å°ä»¥èŠ‚çº¦å†…å­˜
            'learning_rate': 0.0005,
            'weight_decay': 0.001,
            'max_epochs': 5,
            'data_dir': data_dir,
            'save_dir': './quick_validation_results',
            'num_workers': 1,  # å‡å°‘å·¥ä½œè¿›ç¨‹
            'fid_samples': 50,  # å¤§å¹…å‡å°‘FIDè¯„ä¼°æ ·æœ¬æ•°
            'sample_batch_size': 8,  # å°æ‰¹æ¬¡ç”Ÿæˆæ ·æœ¬
        }
        
        # åˆ›å»ºä¿å­˜ç›®å½•
        os.makedirs(self.config['save_dir'], exist_ok=True)
        
        # 1. åˆ›å»ºæ•°æ®åŠ è½½å™¨
        print("ğŸ“ åŠ è½½äº‘æ•°æ®é›†...")
        self.train_loader, self.val_loader, train_size, val_size = build_cloud_dataloader(
            root_dir=self.config['data_dir'],
            batch_size=self.config['batch_size'],
            num_workers=self.config['num_workers'],
            val_split=0.3
        )
        print(f"   è®­ç»ƒé›†: {len(self.train_loader)} batches ({train_size} samples)")
        print(f"   éªŒè¯é›†: {len(self.val_loader)} batches ({val_size} samples)")
        
        # 2. åˆ›å»ºæ ‡å‡†VAE-LDMæ¨¡å‹
        print("ğŸ”§ åˆ›å»ºæ ‡å‡†VAE-LDMæ¨¡å‹...")
        self.model = create_standard_vae_ldm(
            image_size=32,
            num_classes=31,
            diffusion_steps=1000,
            noise_schedule="cosine",
            device=self.device
        )
        
        # 3. é…ç½®ä¼˜åŒ–å™¨
        self.optimizer = self.model.configure_optimizers(
            lr=self.config['learning_rate'],
            weight_decay=self.config['weight_decay']
        )
        
        # 4. åˆå§‹åŒ–FIDè¯„ä¼°å™¨ - æ›´å°‘æ ·æœ¬
        print("ğŸ“Š åˆå§‹åŒ–FIDè¯„ä¼°å™¨...")
        self.fid_evaluator = FIDEvaluator(device=self.device)
        self.fid_evaluator.compute_real_features(
            self.val_loader, 
            max_samples=100  # å‡å°‘çœŸå®æ ·æœ¬æ•°
        )
        
        # è®°å½•è®­ç»ƒå†å²
        self.train_history = {
            'epoch': [],
            'train_loss': [],
            'fid_score': []
        }
        
        print("âœ… å†…å­˜ä¼˜åŒ–äº‘ç¯å¢ƒè®­ç»ƒå™¨åˆå§‹åŒ–å®Œæˆ!")
    
    def clear_memory(self):
        """æ¸…ç†CUDAå†…å­˜"""
        if torch.cuda.is_available():
            torch.cuda.empty_cache()
            gc.collect()
    
    def train_epoch(self, epoch: int):
        """è®­ç»ƒä¸€ä¸ªepoch"""
        self.model.train()
        
        total_loss = 0
        num_batches = 0
        
        pbar = tqdm(self.train_loader, desc=f"Epoch {epoch+1}")
        
        for batch_idx, batch in enumerate(pbar):
            images, labels = batch
            images = images.to(self.device)
            labels = labels.to(self.device)
            
            # å‰å‘ä¼ æ’­
            losses = self.model(images, labels, current_epoch=epoch)
            loss = losses['loss'].mean()
            
            # åå‘ä¼ æ’­
            self.optimizer.zero_grad()
            loss.backward()
            torch.nn.utils.clip_grad_norm_(self.model.unet.parameters(), max_norm=2.0)
            self.optimizer.step()
            
            # è®°å½•æŸå¤±
            total_loss += loss.item()
            num_batches += 1
            
            # æ›´æ–°è¿›åº¦æ¡
            pbar.set_postfix({
                'Loss': f'{loss.item():.4f}',
                'Avg': f'{total_loss/num_batches:.4f}'
            })
            
            # å®šæœŸæ¸…ç†å†…å­˜
            if batch_idx % 20 == 0:
                self.clear_memory()
            
            # è®­ç»ƒ100ä¸ªbatchååœæ­¢
            if batch_idx >= 100:
                break
        
        avg_loss = total_loss / num_batches
        self.clear_memory()  # è®­ç»ƒå®Œæˆåæ¸…ç†å†…å­˜
        return avg_loss
    
    @torch.no_grad()
    def evaluate_fid(self, epoch: int):
        """å†…å­˜ä¼˜åŒ–çš„FIDè¯„ä¼°"""
        print(f"ğŸ“Š Epoch {epoch+1} FIDè¯„ä¼°ï¼ˆå†…å­˜ä¼˜åŒ–æ¨¡å¼ï¼‰...")
        
        self.model.eval()
        self.clear_memory()  # å¼€å§‹å‰æ¸…ç†å†…å­˜
        
        num_samples = self.config['fid_samples']  # ä½¿ç”¨æ›´å°‘æ ·æœ¬
        batch_size = self.config['sample_batch_size']  # å°æ‰¹æ¬¡ç”Ÿæˆ
        
        all_generated_images = []
        
        # åˆ†æ‰¹ç”Ÿæˆæ ·æœ¬ä»¥èŠ‚çº¦å†…å­˜
        for i in range(0, num_samples, batch_size):
            current_batch_size = min(batch_size, num_samples - i)
            
            # éšæœºé€‰æ‹©ç±»åˆ«
            classes = torch.randint(0, 31, (current_batch_size,), device=self.device)
            
            try:
                # ç”Ÿæˆæ ·æœ¬
                generated_images, _ = self.model.sample(
                    num_samples=current_batch_size,
                    class_labels=classes,
                    use_ddim=True,
                    num_inference_steps=20  # å‡å°‘æ¨ç†æ­¥æ•°
                )
                
                # ç§»åŠ¨åˆ°CPUèŠ‚çº¦GPUå†…å­˜
                all_generated_images.append(generated_images.cpu())
                
                # æ¸…ç†GPUå†…å­˜
                del generated_images, classes
                self.clear_memory()
                
                print(f"   å®Œæˆ {i+current_batch_size}/{num_samples} æ ·æœ¬")
                
            except torch.cuda.OutOfMemoryError:
                print(f"âš ï¸  å†…å­˜ä¸è¶³ï¼Œè·³è¿‡ç¬¬{i//batch_size+1}æ‰¹")
                self.clear_memory()
                continue
        
        if not all_generated_images:
            print("âŒ æ— æ³•ç”Ÿæˆä»»ä½•æ ·æœ¬ï¼ŒFIDè¯„ä¼°å¤±è´¥")
            return float('inf')
        
        # åˆå¹¶æ‰€æœ‰ç”Ÿæˆçš„å›¾åƒ
        generated_images = torch.cat(all_generated_images, dim=0).to(self.device)
        
        try:
            # è®¡ç®—FID
            fid_score = self.fid_evaluator.calculate_fid_score(generated_images)
            print(f"ğŸ¯ Epoch {epoch+1} FID: {fid_score:.2f} (åŸºäº{len(generated_images)}ä¸ªæ ·æœ¬)")
            
        except Exception as e:
            print(f"âŒ FIDè®¡ç®—å¤±è´¥: {e}")
            fid_score = float('inf')
        
        finally:
            # æ¸…ç†å†…å­˜
            del generated_images
            self.clear_memory()
        
        return fid_score
    
    def save_sample_images(self, epoch: int, num_samples: int = 8):
        """ä¿å­˜æ ·æœ¬å›¾åƒ - å†…å­˜ä¼˜åŒ–ç‰ˆæœ¬"""
        self.model.eval()
        self.clear_memory()
        
        try:
            with torch.no_grad():
                # ç”Ÿæˆå°‘é‡æ ·æœ¬ç”¨äºå¯è§†åŒ–
                classes = torch.arange(min(num_samples, 31), device=self.device)[:num_samples]
                generated_images, _ = self.model.sample(
                    num_samples=num_samples,
                    class_labels=classes,
                    use_ddim=True,
                    num_inference_steps=20
                )
                
                # åå½’ä¸€åŒ–
                def denormalize(tensor):
                    return torch.clamp((tensor + 1) / 2, 0, 1)
                
                images = denormalize(generated_images).cpu()
                
                # åˆ›å»ºç½‘æ ¼æ˜¾ç¤º
                grid_size = int(np.ceil(np.sqrt(num_samples)))
                fig, axes = plt.subplots(grid_size, grid_size, figsize=(12, 12))
                axes = axes.flatten() if num_samples > 1 else [axes]
                
                for i in range(num_samples):
                    img = images[i].permute(1, 2, 0).numpy()
                    axes[i].imshow(img)
                    axes[i].set_title(f'Class {classes[i].item()}')
                    axes[i].axis('off')
                
                # éšè—å¤šä½™çš„å­å›¾
                for i in range(num_samples, len(axes)):
                    axes[i].axis('off')
                
                plt.tight_layout()
                plt.savefig(f'{self.config["save_dir"]}/samples_epoch_{epoch+1}.png', 
                           dpi=150, bbox_inches='tight')
                plt.close()
                
                # æ¸…ç†å†…å­˜
                del generated_images, images
                self.clear_memory()
                
        except Exception as e:
            print(f"âš ï¸  æ ·æœ¬ç”Ÿæˆå¤±è´¥: {e}")
            self.clear_memory()
    
    def train(self):
        """ä¸»è®­ç»ƒå¾ªç¯"""
        print("ğŸš€ å¼€å§‹å†…å­˜ä¼˜åŒ–äº‘ç¯å¢ƒè®­ç»ƒ...")
        print("=" * 60)
        
        best_fid = float('inf')
        
        for epoch in range(self.config['max_epochs']):
            print(f"\nğŸ“… Epoch {epoch+1}/{self.config['max_epochs']}")
            
            # è®­ç»ƒä¸€ä¸ªepoch
            avg_loss = self.train_epoch(epoch)
            print(f"ğŸ“Š è®­ç»ƒæŸå¤±: {avg_loss:.4f}")
            
            # è¯„ä¼°FID - å†…å­˜ä¼˜åŒ–ç‰ˆæœ¬
            fid_score = self.evaluate_fid(epoch)
            
            # ä¿å­˜æ ·æœ¬å›¾åƒ
            if epoch % 2 == 0:
                self.save_sample_images(epoch)
            
            # è®°å½•å†å²
            self.train_history['epoch'].append(epoch + 1)
            self.train_history['train_loss'].append(avg_loss)
            self.train_history['fid_score'].append(fid_score)
            
            # æ›´æ–°æœ€ä½³FID
            if fid_score < best_fid:
                best_fid = fid_score
                try:
                    # ä¿å­˜æœ€ä½³æ¨¡å‹
                    self.model.save_checkpoint(
                        f'{self.config["save_dir"]}/best_model.pth',
                        epoch,
                        self.optimizer.state_dict()
                    )
                    print(f"ğŸ’¾ ä¿å­˜æœ€ä½³æ¨¡å‹ (FID: {best_fid:.2f})")
                except Exception as e:
                    print(f"âš ï¸  æ¨¡å‹ä¿å­˜å¤±è´¥: {e}")
            
            print(f"ğŸ† å½“å‰æœ€ä½³FID: {best_fid:.2f}")
            
            # æ¯ä¸ªepochåæ¸…ç†å†…å­˜
            self.clear_memory()
        
        # è®­ç»ƒå®Œæˆæ€»ç»“
        print("\n" + "=" * 60)
        print("ğŸ‰ å†…å­˜ä¼˜åŒ–äº‘ç¯å¢ƒè®­ç»ƒå®Œæˆ!")
        print(f"ğŸ† æœ€ä½³FID: {best_fid:.2f}")
        
        # åˆ¤æ–­ç»“æœ
        if best_fid < 50:
            print("âœ… æˆåŠŸï¼FID < 50ï¼Œæ ‡å‡†AutoencoderKLå¯ä»¥ç›´æ¥ä½¿ç”¨")
            print("ğŸ’¡ å»ºè®®ï¼šç»§ç»­ç”¨æ–¹æ¡ˆAè¿›è¡Œå®Œæ•´è®­ç»ƒ")
        elif best_fid < 100:
            print("âš ï¸  FIDåœ¨å¯æ¥å—èŒƒå›´ï¼Œå»ºè®®Fine-tune VAE")
            print("ğŸ’¡ å»ºè®®ï¼šè½¬å‘æ–¹æ¡ˆBï¼Œå…ˆFine-tune AutoencoderKL")
        else:
            print("âŒ FIDè¾ƒé«˜ï¼Œéœ€è¦è¿›ä¸€æ­¥ä¼˜åŒ–")
            print("ğŸ’¡ å»ºè®®ï¼šæ£€æŸ¥æ•°æ®è´¨é‡æˆ–ä½¿ç”¨æ–¹æ¡ˆB/C")
        
        return best_fid

def main():
    """ä¸»å‡½æ•°"""
    print("ğŸŒ å¯åŠ¨å†…å­˜ä¼˜åŒ–äº‘ç¯å¢ƒè®­ç»ƒ...")
    
    # æ£€æŸ¥æ•°æ®è·¯å¾„
    data_paths = ['/kaggle/input/dataset', './dataset', '../dataset']
    data_dir = None
    
    for path in data_paths:
        if os.path.exists(path):
            data_dir = path
            print(f"âœ… æ‰¾åˆ°æ•°æ®é›†: {data_dir}")
            break
    
    if data_dir is None:
        print("âŒ æœªæ‰¾åˆ°æ•°æ®é›†ï¼Œè¯·æ£€æŸ¥è·¯å¾„")
        return None
    
    try:
        trainer = OptimizedCloudTrainer(data_dir=data_dir)
        best_fid = trainer.train()
        print(f"\nğŸ¯ æœ€ç»ˆç»“æœ: FID = {best_fid:.2f}")
        return best_fid
        
    except Exception as e:
        print(f"âŒ è®­ç»ƒè¿‡ç¨‹ä¸­å‡ºç°é”™è¯¯: {e}")
        # æ¸…ç†å†…å­˜
        if torch.cuda.is_available():
            torch.cuda.empty_cache()
        gc.collect()
        return None

if __name__ == "__main__":
    main() 
