import os
import yaml
import torch
import torch.nn as nn
import torch.optim as optim
from torch.utils.data import DataLoader
import sys
import time
import math
from tqdm import tqdm
import matplotlib.pyplot as plt
import torchvision.utils as vutils
from typing import Dict, Any
import json

# æ·»åŠ æ¨¡å—è·¯å¾„
sys.path.append(os.path.join(os.path.dirname(__file__), '..', 'VAE'))

from ldm import LatentDiffusionModel
from dataset import build_dataloader
from fid_evaluation import FIDEvaluator

def get_cosine_schedule_with_warmup(
    optimizer: torch.optim.Optimizer,
    num_warmup_steps: int,
    num_training_steps: int,
    num_cycles: float = 0.5,
    last_epoch: int = -1,
):
    """
    åˆ›å»ºå¸¦é¢„çƒ­çš„ä½™å¼¦å­¦ä¹ ç‡è°ƒåº¦å™¨
    """
    def lr_lambda(current_step):
        if current_step < num_warmup_steps:
            return float(current_step) / float(max(1, num_warmup_steps))
        progress = float(current_step - num_warmup_steps) / float(max(1, num_training_steps - num_warmup_steps))
        return max(0.0, 0.5 * (1.0 + math.cos(math.pi * float(num_cycles) * 2.0 * progress)))

    return torch.optim.lr_scheduler.LambdaLR(optimizer, lr_lambda, last_epoch)

def denormalize(x):
    """åå½’ä¸€åŒ–å›¾åƒï¼Œä»[-1,1]è½¬æ¢åˆ°[0,1]"""
    return (x * 0.5 + 0.5).clamp(0, 1)

def save_sample_images(model, device, config, epoch, save_dir):
    """ç”Ÿæˆå¹¶ä¿å­˜æ ·æœ¬å›¾åƒ"""
    model.eval()
    with torch.no_grad():
        # ä¸ºæ¯ä¸ªç±»åˆ«ç”Ÿæˆæ ·æœ¬
        num_classes = config['unet']['num_classes']
        num_samples_per_class = min(4, config['inference']['num_samples_per_class'])
        
        all_images = []
        for class_id in range(min(8, num_classes)):  # æœ€å¤šæ˜¾ç¤º8ä¸ªç±»åˆ«
            class_labels = torch.tensor([class_id] * num_samples_per_class, device=device)
            
            generated_images = model.generate(
                batch_size=num_samples_per_class,
                class_labels=class_labels,
                num_inference_steps=config['inference']['num_inference_steps'],
                guidance_scale=config['inference']['guidance_scale'],
                eta=config['inference']['eta'],
            )
            
            # åå½’ä¸€åŒ–
            generated_images = denormalize(generated_images)
            all_images.append(generated_images)
        
        # æ‹¼æ¥æ‰€æœ‰å›¾åƒ
        if all_images:
            all_images = torch.cat(all_images, dim=0)
            
            # ä¿å­˜å›¾åƒç½‘æ ¼
            grid = vutils.make_grid(all_images, nrow=num_samples_per_class, normalize=False, padding=2)
            save_path = os.path.join(save_dir, f"samples_epoch_{epoch:04d}.png")
            vutils.save_image(grid, save_path)
            print(f"æ ·æœ¬å›¾åƒå·²ä¿å­˜: {save_path}")

def train_ldm():
    """LDMè®­ç»ƒä¸»å‡½æ•°"""
    
    # åŠ è½½é…ç½®
    with open('config.yaml', 'r', encoding='utf-8') as f:
        config = yaml.safe_load(f)
    
    # è®¾å¤‡é…ç½®
    if config['device'] == 'auto':
        device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
    else:
        device = torch.device(config['device'])
    print(f"ä½¿ç”¨è®¾å¤‡: {device}")
    
    # åˆ›å»ºä¿å­˜ç›®å½•
    save_dir = config['training']['save_dir']
    os.makedirs(save_dir, exist_ok=True)
    
    sample_dir = os.path.join(save_dir, "samples")
    os.makedirs(sample_dir, exist_ok=True)
    
    log_dir = os.path.join(save_dir, "logs")
    os.makedirs(log_dir, exist_ok=True)
    
    # æ„å»ºæ•°æ®åŠ è½½å™¨
    print("åŠ è½½æ•°æ®é›†...")
    train_loader, val_loader, train_dataset_len, val_dataset_len = build_dataloader(
        config['dataset']['root_dir'],
        batch_size=config['dataset']['batch_size'],
        num_workers=config['dataset']['num_workers'],
        shuffle_train=True,
        shuffle_val=False,
        val_split=config['dataset']['val_split']
    )
    
    print(f"æ•°æ®é›†åŠ è½½å®Œæˆ: è®­ç»ƒé›† {train_dataset_len}, éªŒè¯é›† {val_dataset_len}")
    
    # åˆå§‹åŒ–LDMæ¨¡å‹
    print("åˆå§‹åŒ–LDMæ¨¡å‹...")
    
    # å¤„ç†VAEè·¯å¾„
    vae_path = config['vae']['model_path']
    if vae_path.startswith('../'):
        vae_path = os.path.join(os.path.dirname(__file__), vae_path)
    
    model = LatentDiffusionModel(
        vae_config=config['vae'],
        unet_config=config['unet'],
        scheduler_config=config['diffusion'],
        vae_path=vae_path,
        freeze_vae=config['vae']['freeze'],
        use_cfg=config['training']['use_cfg'],
        cfg_dropout_prob=config['training']['cfg_dropout_prob'],
    ).to(device)
    
    # åˆå§‹åŒ–FIDè¯„ä¼°å™¨
    print("åˆå§‹åŒ–FIDè¯„ä¼°å™¨...")
    fid_evaluator = FIDEvaluator(device=device)
    
    # è®¡ç®—çœŸå®æ•°æ®ç‰¹å¾ï¼ˆç”¨äºFIDè®¡ç®—ï¼‰
    # ä½¿ç”¨éªŒè¯é›†æ¥è®¡ç®—çœŸå®æ•°æ®ç‰¹å¾ï¼Œå‡å°‘è®¡ç®—å¼€é”€
    print("è®¡ç®—çœŸå®æ•°æ®ç‰¹å¾ç”¨äºFIDè¯„ä¼°...")
    fid_evaluator.compute_real_features(val_loader, max_samples=1000)
    
    # ä¼˜åŒ–å™¨
    optimizer = optim.AdamW(
        model.unet.parameters(),  # åªä¼˜åŒ–U-Netå‚æ•°
        lr=config['training']['lr'],
        weight_decay=config['training']['weight_decay'],
    )
    
    # å­¦ä¹ ç‡è°ƒåº¦å™¨
    if config['training']['use_scheduler']:
        total_steps = len(train_loader) * config['training']['epochs']
        scheduler = get_cosine_schedule_with_warmup(
            optimizer,
            num_warmup_steps=config['training']['warmup_steps'],
            num_training_steps=total_steps,
        )
    else:
        scheduler = None
    
    # æ··åˆç²¾åº¦è®­ç»ƒ
    scaler = torch.cuda.amp.GradScaler() if config.get('mixed_precision', False) and device.type == 'cuda' else None
    
    # è®­ç»ƒçŠ¶æ€å’Œæ—¥å¿—
    start_epoch = 0
    best_loss = float('inf')
    best_fid = float('inf')
    global_step = 0
    
    # è®­ç»ƒæ—¥å¿—
    training_log = {
        'epochs': [],
        'train_loss': [],
        'val_loss': [],
        'fid_scores': [],
        'learning_rates': []
    }
    
    # è®­ç»ƒå¾ªç¯
    print(f"å¼€å§‹è®­ç»ƒï¼Œå…± {config['training']['epochs']} ä¸ªepoch...")
    
    for epoch in range(start_epoch, config['training']['epochs']):
        model.train()
        epoch_loss = 0.0
        epoch_start_time = time.time()
        
        progress_bar = tqdm(train_loader, desc=f"Epoch {epoch+1}/{config['training']['epochs']}")
        
        for batch_idx, (images, labels) in enumerate(progress_bar):
            images = images.to(device)
            labels = labels.to(device)
            
            # å‰å‘ä¼ æ’­
            if scaler is not None:
                with torch.cuda.amp.autocast():
                    outputs = model(images, class_labels=labels)
                    loss = outputs['loss']
                
                # åå‘ä¼ æ’­
                optimizer.zero_grad()
                scaler.scale(loss).backward()
                
                # æ¢¯åº¦è£å‰ª
                if config['training']['grad_clip_norm'] > 0:
                    scaler.unscale_(optimizer)
                    torch.nn.utils.clip_grad_norm_(model.unet.parameters(), config['training']['grad_clip_norm'])
                
                scaler.step(optimizer)
                scaler.update()
            else:
                outputs = model(images, class_labels=labels)
                loss = outputs['loss']
                
                # åå‘ä¼ æ’­
                optimizer.zero_grad()
                loss.backward()
                
                # æ¢¯åº¦è£å‰ª
                if config['training']['grad_clip_norm'] > 0:
                    torch.nn.utils.clip_grad_norm_(model.unet.parameters(), config['training']['grad_clip_norm'])
                
                optimizer.step()
            
            # æ›´æ–°å­¦ä¹ ç‡
            if scheduler is not None:
                scheduler.step()
            
            # è®°å½•æŸå¤±
            epoch_loss += loss.item()
            global_step += 1
            
            # æ›´æ–°è¿›åº¦æ¡
            current_lr = optimizer.param_groups[0]['lr']
            progress_bar.set_postfix({
                'loss': f'{loss.item():.4f}',
                'lr': f'{current_lr:.2e}'
            })
            
            # å®šæœŸæ‰“å°æ—¥å¿—
            if global_step % config['training']['log_interval'] == 0:
                print(f"Step {global_step}, Loss: {loss.item():.4f}, LR: {current_lr:.2e}")
        
        # è®¡ç®—å¹³å‡æŸå¤±
        avg_epoch_loss = epoch_loss / len(train_loader)
        epoch_time = time.time() - epoch_start_time
        current_lr = optimizer.param_groups[0]['lr']
        
        print(f"Epoch {epoch+1} å®Œæˆ:")
        print(f"  å¹³å‡è®­ç»ƒæŸå¤±: {avg_epoch_loss:.4f}")
        print(f"  ç”¨æ—¶: {epoch_time:.1f}s")
        print(f"  å­¦ä¹ ç‡: {current_lr:.2e}")
        
        # éªŒè¯
        avg_val_loss = None
        if val_loader:
            model.eval()
            val_loss = 0.0
            val_steps = 0
            
            with torch.no_grad():
                for images, labels in val_loader:
                    images = images.to(device)
                    labels = labels.to(device)
                    
                    if scaler is not None:
                        with torch.cuda.amp.autocast():
                            outputs = model(images, class_labels=labels)
                            loss = outputs['loss']
                    else:
                        outputs = model(images, class_labels=labels)
                        loss = outputs['loss']
                    
                    val_loss += loss.item()
                    val_steps += 1
            
            avg_val_loss = val_loss / val_steps
            print(f"  éªŒè¯æŸå¤±: {avg_val_loss:.4f}")
        else:
            avg_val_loss = avg_epoch_loss
        
        # FIDè¯„ä¼° - æ¯10ä¸ªepochè®¡ç®—ä¸€æ¬¡
        fid_score = None
        if (epoch + 1) % 10 == 0:
            print(f"  è®¡ç®—FIDåˆ†æ•°...")
            try:
                fid_start_time = time.time()
                fid_score = fid_evaluator.evaluate_model(
                    model, 
                    num_samples=min(500, val_dataset_len),  # é™åˆ¶æ ·æœ¬æ•°ä»¥èŠ‚çœæ—¶é—´
                    batch_size=4,  # è¾ƒå°çš„æ‰¹é‡å¤§å°é¿å…å†…å­˜é—®é¢˜
                    num_classes=config['unet']['num_classes']
                )
                fid_time = time.time() - fid_start_time
                print(f"  FIDåˆ†æ•°: {fid_score:.2f} (ç”¨æ—¶: {fid_time:.1f}s)")
                
                # æ›´æ–°æœ€ä½³FID
                if fid_score < best_fid:
                    best_fid = fid_score
                    best_fid_model_path = os.path.join(save_dir, 'best_fid_model')
                    model.save_pretrained(best_fid_model_path)
                    print(f"  ğŸ‰ FIDæ–°çºªå½•ï¼ä¿å­˜æœ€ä½³FIDæ¨¡å‹: {best_fid_model_path}")
                
            except Exception as e:
                print(f"  âš ï¸ FIDè®¡ç®—å¤±è´¥: {e}")
                fid_score = None
        
        # è®°å½•è®­ç»ƒæ—¥å¿—
        training_log['epochs'].append(epoch + 1)
        training_log['train_loss'].append(avg_epoch_loss)
        training_log['val_loss'].append(avg_val_loss)
        training_log['fid_scores'].append(fid_score)
        training_log['learning_rates'].append(current_lr)
        
        # ä¿å­˜è®­ç»ƒæ—¥å¿—
        with open(os.path.join(log_dir, 'training_log.json'), 'w') as f:
            json.dump(training_log, f, indent=2)
        
        # ä¿å­˜æœ€ä½³æŸå¤±æ¨¡å‹
        if avg_val_loss < best_loss:
            best_loss = avg_val_loss
            best_model_path = os.path.join(save_dir, 'best_loss_model')
            model.save_pretrained(best_model_path)
            print(f"  ä¿å­˜æœ€ä½³æŸå¤±æ¨¡å‹: {best_model_path}")
        
        # å®šæœŸä¿å­˜checkpoint
        if (epoch + 1) % config['training']['save_interval'] == 0:
            checkpoint_path = os.path.join(save_dir, f'checkpoint_epoch_{epoch+1}')
            model.save_pretrained(checkpoint_path)
            print(f"  ä¿å­˜checkpoint: {checkpoint_path}")
        
        # ç”Ÿæˆæ ·æœ¬å›¾åƒ
        if (epoch + 1) % config['training']['sample_interval'] == 0:
            print("  ç”Ÿæˆæ ·æœ¬å›¾åƒ...")
            save_sample_images(model, device, config, epoch + 1, sample_dir)
        
        print("-" * 80)
    
    # ä¿å­˜æœ€ç»ˆæ¨¡å‹
    final_model_path = os.path.join(save_dir, 'final_model')
    model.save_pretrained(final_model_path)
    
    # ä¿å­˜æœ€ç»ˆè®­ç»ƒæŠ¥å‘Š
    final_report = {
        'training_completed': True,
        'total_epochs': config['training']['epochs'],
        'best_train_loss': best_loss,
        'best_fid_score': best_fid if best_fid != float('inf') else None,
        'final_train_loss': avg_epoch_loss,
        'final_val_loss': avg_val_loss,
        'total_parameters': sum(p.numel() for p in model.unet.parameters()),
        'device': str(device),
        'config': config
    }
    
    with open(os.path.join(save_dir, 'training_report.json'), 'w') as f:
        json.dump(final_report, f, indent=2)
    
    print("=" * 80)
    print(f"ğŸ‰ è®­ç»ƒå®Œæˆï¼")
    print(f"  æœ€ç»ˆæ¨¡å‹: {final_model_path}")
    print(f"  æœ€ä½³æŸå¤±: {best_loss:.4f}")
    if best_fid != float('inf'):
        print(f"  æœ€ä½³FID: {best_fid:.2f}")
    print(f"  è®­ç»ƒæ—¥å¿—: {os.path.join(log_dir, 'training_log.json')}")
    print("=" * 80)

if __name__ == "__main__":
    # è®¾ç½®éšæœºç§å­
    torch.manual_seed(42)
    if torch.cuda.is_available():
        torch.cuda.manual_seed(42)
    
    # å¼€å§‹è®­ç»ƒ
    train_ldm() 