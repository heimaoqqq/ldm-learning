# VAE-LDM 优化训练配置
# 🎯 针对FID问题的参数优化

# ================== 📁 路径配置 ==================
paths:
  vae_checkpoint: '/kaggle/input/vae-best-fid/adv_vqvae_best_fid.pth'  # VAE预训练权重
  data_dir: '/kaggle/input/dataset'                                 # 数据集路径
  save_dir: './checkpoints_optimized'                       # 模型保存路径

# ================== 🎛️ 模型配置 ==================
model:
  num_classes: 31           # 微多普勒信号类别数
  image_size: 32           # VAE潜在空间分辨率 (32×32) 
  diffusion_steps: 1000    # 扩散步数
  noise_schedule: "cosine" # 噪声调度 [linear, cosine]

# ================== 🏃 训练配置 ==================
training:   
  # 优化配置
  batch_size: 8                    # 增加batch size
  gradient_accumulation_steps: 1   # 简化梯度累积
  learning_rate: 0.0005            # 🔥 提高学习率 (5倍)
  weight_decay: 0.001              # 🔥 降低权重衰减 (10倍)
  max_epochs: 100                  # 减少训练轮数，专注质量
  
  # 保存和日志配置
  log_interval: 5           # 更频繁的日志
  save_interval_epochs: 10  # 更频繁的保存
  eval_interval: 5          # 更频繁的评估
  
  # 训练优化
  enable_wandb: false       # 禁用wandb
  num_workers: 2           # 数据加载器工作进程数

# ================== 📊 评估配置 ==================
evaluation:
  # FID评估配置
  eval_classes: 5           # 增加评估类别数
  samples_per_class: 40     # 每类生成样本数
  ddim_steps: 50           # DDIM采样步数
  eta: 0.0                 # DDIM随机性参数
  max_real_samples: 1000   # 增加真实数据样本数

# ================== 🎮 GPU优化配置 ==================
gpu:
  device: 'cuda'           # 设备
  mixed_precision: false   # 混合精度 (P100不支持)
  gradient_clip: 2.0       # 🔥 放宽梯度裁剪

# ================== 🎨 采样配置 ==================
sampling:
  guidance_scale: 1.5      # 🔥 增加引导强度
  use_ddim: true          # 使用DDIM采样
  num_inference_steps: 50  # 推理步数

# ================== 📝 实验记录 ==================
experiment:
  name: "VAE-LDM-Optimized"   # 实验名称
  description: "优化参数的VAE潜在扩散模型 - 针对FID问题"
  version: "v2.0"
  
# ================== 🔧 调试配置 ==================
debug:
  verbose: true            # 详细输出
  save_samples: true       # 保存生成样本
  profile: false          # 性能分析 (调试用)

# ================== 💡 优化说明 ==================
# 主要改进：
# 1. 学习率从0.0001提高到0.0005 (5倍)
# 2. 权重衰减从0.01降低到0.001 (10倍)
# 3. 梯度裁剪从1.0放宽到2.0
# 4. 增加分类器引导强度
# 5. 更频繁的评估和保存
# 6. 增加batch size减少gradient accumulation 
