# VAE-LDM ä¼˜åŒ–è®­ç»ƒé…ç½®
# ğŸ¯ é’ˆå¯¹FIDé—®é¢˜çš„å‚æ•°ä¼˜åŒ–

# ================== ğŸ“ è·¯å¾„é…ç½® ==================
paths:
  vae_checkpoint: '/kaggle/input/vae-best-fid/adv_vqvae_best_fid.pth'  # VAEé¢„è®­ç»ƒæƒé‡
  data_dir: '/kaggle/input/dataset'                                 # æ•°æ®é›†è·¯å¾„
  save_dir: './checkpoints_optimized'                       # æ¨¡å‹ä¿å­˜è·¯å¾„

# ================== ğŸ›ï¸ æ¨¡å‹é…ç½® ==================
model:
  num_classes: 31           # å¾®å¤šæ™®å‹’ä¿¡å·ç±»åˆ«æ•°
  image_size: 32           # VAEæ½œåœ¨ç©ºé—´åˆ†è¾¨ç‡ (32Ã—32) 
  diffusion_steps: 1000    # æ‰©æ•£æ­¥æ•°
  noise_schedule: "cosine" # å™ªå£°è°ƒåº¦ [linear, cosine]

# ================== ğŸƒ è®­ç»ƒé…ç½® ==================
training:   
  # ä¼˜åŒ–é…ç½®
  batch_size: 8                    # å¢åŠ batch size
  gradient_accumulation_steps: 1   # ç®€åŒ–æ¢¯åº¦ç´¯ç§¯
  learning_rate: 0.0005            # ğŸ”¥ æé«˜å­¦ä¹ ç‡ (5å€)
  weight_decay: 0.001              # ğŸ”¥ é™ä½æƒé‡è¡°å‡ (10å€)
  max_epochs: 100                  # å‡å°‘è®­ç»ƒè½®æ•°ï¼Œä¸“æ³¨è´¨é‡
  
  # ä¿å­˜å’Œæ—¥å¿—é…ç½®
  log_interval: 5           # æ›´é¢‘ç¹çš„æ—¥å¿—
  save_interval_epochs: 10  # æ›´é¢‘ç¹çš„ä¿å­˜
  eval_interval: 5          # æ›´é¢‘ç¹çš„è¯„ä¼°
  
  # è®­ç»ƒä¼˜åŒ–
  enable_wandb: false       # ç¦ç”¨wandb
  num_workers: 2           # æ•°æ®åŠ è½½å™¨å·¥ä½œè¿›ç¨‹æ•°

# ================== ğŸ“Š è¯„ä¼°é…ç½® ==================
evaluation:
  # FIDè¯„ä¼°é…ç½®
  eval_classes: 5           # å¢åŠ è¯„ä¼°ç±»åˆ«æ•°
  samples_per_class: 40     # æ¯ç±»ç”Ÿæˆæ ·æœ¬æ•°
  ddim_steps: 50           # DDIMé‡‡æ ·æ­¥æ•°
  eta: 0.0                 # DDIMéšæœºæ€§å‚æ•°
  max_real_samples: 1000   # å¢åŠ çœŸå®æ•°æ®æ ·æœ¬æ•°

# ================== ğŸ® GPUä¼˜åŒ–é…ç½® ==================
gpu:
  device: 'cuda'           # è®¾å¤‡
  mixed_precision: false   # æ··åˆç²¾åº¦ (P100ä¸æ”¯æŒ)
  gradient_clip: 2.0       # ğŸ”¥ æ”¾å®½æ¢¯åº¦è£å‰ª

# ================== ğŸ¨ é‡‡æ ·é…ç½® ==================
sampling:
  guidance_scale: 1.5      # ğŸ”¥ å¢åŠ å¼•å¯¼å¼ºåº¦
  use_ddim: true          # ä½¿ç”¨DDIMé‡‡æ ·
  num_inference_steps: 50  # æ¨ç†æ­¥æ•°

# ================== ğŸ“ å®éªŒè®°å½• ==================
experiment:
  name: "VAE-LDM-Optimized"   # å®éªŒåç§°
  description: "ä¼˜åŒ–å‚æ•°çš„VAEæ½œåœ¨æ‰©æ•£æ¨¡å‹ - é’ˆå¯¹FIDé—®é¢˜"
  version: "v2.0"
  
# ================== ğŸ”§ è°ƒè¯•é…ç½® ==================
debug:
  verbose: true            # è¯¦ç»†è¾“å‡º
  save_samples: true       # ä¿å­˜ç”Ÿæˆæ ·æœ¬
  profile: false          # æ€§èƒ½åˆ†æ (è°ƒè¯•ç”¨)

# ================== ğŸ’¡ ä¼˜åŒ–è¯´æ˜ ==================
# ä¸»è¦æ”¹è¿›ï¼š
# 1. å­¦ä¹ ç‡ä»0.0001æé«˜åˆ°0.0005 (5å€)
# 2. æƒé‡è¡°å‡ä»0.01é™ä½åˆ°0.001 (10å€)
# 3. æ¢¯åº¦è£å‰ªä»1.0æ”¾å®½åˆ°2.0
# 4. å¢åŠ åˆ†ç±»å™¨å¼•å¯¼å¼ºåº¦
# 5. æ›´é¢‘ç¹çš„è¯„ä¼°å’Œä¿å­˜
# 6. å¢åŠ batch sizeå‡å°‘gradient accumulation 
