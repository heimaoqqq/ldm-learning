"""
ğŸš€ å¢å¼ºç‰ˆLDMè®­ç»ƒè„šæœ¬
ä½¿ç”¨åŒ…å«çœŸæ­£Transformerçš„ç®€åŒ–å¢å¼ºç‰ˆU-Net
é›†æˆå®Œæ•´çš„æŒ‡æ ‡è¯„ä¼°ç³»ç»Ÿ
"""

import yaml
import torch
import torch.nn as nn
import torch.optim as optim
from torch.utils.data import DataLoader
import sys
import os
import time
from tqdm import tqdm
import numpy as np
from datetime import datetime

# æ·»åŠ VAEæ¨¡å—è·¯å¾„
sys.path.append(os.path.join(os.path.dirname(__file__), '..', 'VAE'))

from stable_ldm import create_stable_ldm
from fid_evaluation import FIDEvaluator
from metrics import DiffusionMetrics, denormalize_for_metrics
from dataset_adapter import build_dataloader

class EnhancedTrainer:
    """å¢å¼ºç‰ˆLDMè®­ç»ƒå™¨"""
    
    def __init__(self, config_path: str, compile_model: bool = False):
        # åŠ è½½é…ç½®
        with open(config_path, 'r', encoding='utf-8') as f:
            self.config = yaml.safe_load(f)
        
        print("ğŸ”§ åˆå§‹åŒ–å¢å¼ºç‰ˆLDMè®­ç»ƒå™¨...")
        
        # è®¾å¤‡é…ç½®
        self.device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
        print(f"ğŸ–¥ï¸  ä½¿ç”¨è®¾å¤‡: {self.device}")
        
        # åˆ›å»ºæ¨¡å‹
        self.model = create_stable_ldm(self.config).to(self.device)
        
        # ğŸš€ æ¨¡å‹ç¼–è¯‘ä¼˜åŒ–
        if compile_model and hasattr(torch, 'compile'):
            try:
                print("ğŸš€ ç¼–è¯‘æ¨¡å‹ä»¥æé«˜æ€§èƒ½...")
                self.model = torch.compile(self.model)
                print("âœ… æ¨¡å‹ç¼–è¯‘æˆåŠŸ")
            except Exception as e:
                print(f"âš ï¸ æ¨¡å‹ç¼–è¯‘å¤±è´¥ï¼Œç»§ç»­ä½¿ç”¨æœªç¼–è¯‘ç‰ˆæœ¬: {e}")
        
        # æ‰“å°æ¨¡å‹ä¿¡æ¯
        total_params = sum(p.numel() for p in self.model.parameters())
        trainable_params = sum(p.numel() for p in self.model.parameters() if p.requires_grad)
        print(f"ğŸ“Š æ¨¡å‹å‚æ•°ç»Ÿè®¡:")
        print(f"   æ€»å‚æ•°: {total_params/1e6:.1f}M")
        print(f"   å¯è®­ç»ƒå‚æ•°: {trainable_params/1e6:.1f}M")
        
        # åˆ›å»ºæŒ‡æ ‡è®¡ç®—å™¨
        self.metrics_calculator = DiffusionMetrics(self.device)
        
        # åˆ›å»ºFIDè¯„ä¼°å™¨
        self.fid_evaluator = FIDEvaluator(self.device)
        
        # è®¾ç½®ä¼˜åŒ–å™¨
        self.optimizer = optim.AdamW(
            self.model.unet.parameters(),
            lr=self.config['training']['lr'],
            betas=(self.config['training']['beta1'], self.config['training']['beta2']),
            eps=self.config['training']['eps'],
            weight_decay=self.config['training']['weight_decay']
        )
        
        # æ¢¯åº¦ç´¯ç§¯è®¾ç½®
        self.gradient_accumulation_steps = self.config['training'].get('gradient_accumulation_steps', 1)
        
        # æ—©åœè®¾ç½®
        self.best_fid = float('inf')
        self.best_loss = float('inf')
        self.best_is_score = 0.0
        self.patience_counter = 0
        self.early_stopping_patience = self.config['training'].get('early_stopping_patience', 50)
        
        # ğŸš€ è®­ç»ƒæ”¹è¿›ç›‘æ§
        self.previous_metrics = {}
        self.improvement_history = []
        
        # ğŸš€ è´¨é‡ç›‘æ§é…ç½®
        self.quality_config = self.config.get('quality_monitoring', {})
        self.fid_improvement_threshold = self.quality_config.get('improvement_threshold', 0.02)
        self.loss_improvement_threshold = self.quality_config.get('loss_improvement_threshold', 0.001)
        
        # æ—¥å¿—å­˜å‚¨
        self.training_logs = []
        
        # åˆ›å»ºä¿å­˜ç›®å½•
        self.save_dir = self.config['training']['save_dir']
        os.makedirs(self.save_dir, exist_ok=True)
        
        print("âœ… è®­ç»ƒå™¨åˆå§‹åŒ–å®Œæˆ")
        print(f"ğŸ¯ ä¼˜åŒ–é…ç½®: batch_size=8, æ¢¯åº¦ç´¯ç§¯=3, æœ‰æ•ˆbatch=24")
        print(f"ğŸ“ˆ å­¦ä¹ ç‡è°ƒæ•´: 0.00008 (é€‚é…batch sizeå˜åŒ–)")
        print(f"ğŸ“‚ æ•°æ®é›†è·¯å¾„: {self.config['dataset']['root_dir']}")
        print(f"ğŸš« æ•°æ®å¢å¼º: å·²ç¦ç”¨ (ä¿æŠ¤æ—¶é¢‘å›¾ç‰©ç†æ„ä¹‰)")
        
    def check_gradient_health(self) -> dict:
        """æ£€æŸ¥æ¢¯åº¦å¥åº·çŠ¶å†µ"""
        total_norm = 0.0
        param_count = 0
        
        for param in self.model.unet.parameters():
            if param.grad is not None:
                param_norm = param.grad.data.norm(2)
                total_norm += param_norm.item() ** 2
                param_count += 1
        
        total_norm = total_norm ** (1. / 2)
        
        # æ£€æŸ¥æ¢¯åº¦çˆ†ç‚¸
        gradient_threshold = self.quality_config.get('gradient_norm_threshold', 10.0)
        gradient_exploding = total_norm > gradient_threshold
        
        return {
            'gradient_norm': total_norm,
            'gradient_exploding': gradient_exploding,
            'param_count': param_count
        }
    
    def detect_improvements(self, current_metrics: dict, epoch: int) -> dict:
        """æ£€æµ‹è®­ç»ƒæ”¹è¿›"""
        improvements = {
            'fid_improved': False,
            'loss_improved': False,
            'is_improved': False,
            'overall_improved': False
        }
        
        if not self.previous_metrics:
            self.previous_metrics = current_metrics.copy()
            return improvements
        
        # FIDæ”¹è¿›æ£€æµ‹ (è¶Šå°è¶Šå¥½)
        if 'fid_score' in current_metrics and 'fid_score' in self.previous_metrics:
            fid_improvement = self.previous_metrics['fid_score'] - current_metrics['fid_score']
            if fid_improvement > self.fid_improvement_threshold:
                improvements['fid_improved'] = True
                print(f"ğŸ‰ FIDæ˜¾è‘—æ”¹è¿›! {self.previous_metrics['fid_score']:.3f} â†’ {current_metrics['fid_score']:.3f} (æ”¹è¿›: {fid_improvement:.3f})")
        
        # æŸå¤±æ”¹è¿›æ£€æµ‹ (è¶Šå°è¶Šå¥½)
        if 'loss' in current_metrics and 'loss' in self.previous_metrics:
            loss_improvement = self.previous_metrics['loss'] - current_metrics['loss']
            if loss_improvement > self.loss_improvement_threshold:
                improvements['loss_improved'] = True
                print(f"ğŸ“‰ è®­ç»ƒæŸå¤±æ”¹è¿›! {self.previous_metrics['loss']:.4f} â†’ {current_metrics['loss']:.4f} (æ”¹è¿›: {loss_improvement:.4f})")
        
        # ISåˆ†æ•°æ”¹è¿›æ£€æµ‹ (è¶Šå¤§è¶Šå¥½)
        if 'inception_score_mean' in current_metrics and 'inception_score_mean' in self.previous_metrics:
            is_improvement = current_metrics['inception_score_mean'] - self.previous_metrics['inception_score_mean']
            if is_improvement > 0.1:  # ISæ”¹è¿›é˜ˆå€¼
                improvements['is_improved'] = True
                print(f"ğŸŒŸ ISåˆ†æ•°æ”¹è¿›! {self.previous_metrics['inception_score_mean']:.3f} â†’ {current_metrics['inception_score_mean']:.3f} (æ”¹è¿›: {is_improvement:.3f})")
        
        # ç»¼åˆæ”¹è¿›åˆ¤æ–­
        if any([improvements['fid_improved'], improvements['loss_improved'], improvements['is_improved']]):
            improvements['overall_improved'] = True
            print(f"ğŸš€ Epoch {epoch}: è®­ç»ƒè´¨é‡æœ‰æ˜¾è‘—æå‡!")
        
        # è®°å½•æ”¹è¿›å†å²
        self.improvement_history.append({
            'epoch': epoch,
            'improvements': improvements.copy(),
            'metrics': current_metrics.copy()
        })
        
        # æ›´æ–°å‰ä¸€è½®æŒ‡æ ‡
        self.previous_metrics = current_metrics.copy()
        
        return improvements
    
    def train_epoch(self, dataloader: DataLoader, epoch: int) -> dict:
        """è®­ç»ƒä¸€ä¸ªepoch"""
        self.model.train()
        
        epoch_losses = []
        epoch_metrics = {
            'noise_mse': [],
            'noise_mae': [],
            'noise_psnr': [],
            'noise_cosine_similarity': [],
            'noise_correlation': []
        }
        
        # ğŸš€ æ¢¯åº¦å¥åº·ç›‘æ§
        gradient_health_issues = 0
        
        progress_bar = tqdm(dataloader, desc=f'Epoch {epoch}')
        
        for batch_idx, batch in enumerate(progress_bar):
            # å‰å‘ä¼ æ’­ - ç¡®ä¿æ•°æ®åœ¨æ­£ç¡®çš„è®¾å¤‡ä¸Š
            images = batch['image'].to(self.device)
            labels = batch.get('label', None)
            if labels is not None:
                labels = labels.to(self.device)
            
            loss_dict = self.model(images, labels)
            
            loss = loss_dict['loss'] / self.gradient_accumulation_steps
            
            # ğŸš€ æ£€æŸ¥æŸå¤±çªå¢
            loss_spike_threshold = self.quality_config.get('loss_spike_threshold', 2.0)
            if epoch_losses and loss.item() > np.mean(epoch_losses[-10:]) * loss_spike_threshold:
                print(f"âš ï¸ æ£€æµ‹åˆ°æŸå¤±çªå¢: {loss.item():.4f} (å¹³å‡: {np.mean(epoch_losses[-10:]):.4f})")
            
            # è®¡ç®—å™ªå£°é¢„æµ‹æŒ‡æ ‡
            noise_metrics = self.metrics_calculator.calculate_all_metrics(
                loss_dict['predicted_noise'],
                loss_dict['target_noise']
            )
            
            # æ›´æ–°æŒ‡æ ‡
            for key in epoch_metrics:
                if key in noise_metrics:
                    epoch_metrics[key].append(noise_metrics[key])
            
            # åå‘ä¼ æ’­
            loss.backward()
            
            if (batch_idx + 1) % self.gradient_accumulation_steps == 0:
                # ğŸš€ æ¢¯åº¦å¥åº·æ£€æŸ¥
                grad_health = self.check_gradient_health()
                if grad_health['gradient_exploding']:
                    gradient_health_issues += 1
                    print(f"âš ï¸ æ¢¯åº¦çˆ†ç‚¸è­¦å‘Š: æ¢¯åº¦èŒƒæ•° {grad_health['gradient_norm']:.2f}")
                
                # æ¢¯åº¦è£å‰ª
                if 'grad_clip_norm' in self.config['training']:
                    torch.nn.utils.clip_grad_norm_(
                        self.model.unet.parameters(), 
                        self.config['training']['grad_clip_norm']
                    )
                
                self.optimizer.step()
                self.optimizer.zero_grad()
                
                # æ›´æ–°EMA
                if hasattr(self.model, 'ema') and self.model.ema is not None:
                    self.model.ema.update()
            
            epoch_losses.append(loss.item() * self.gradient_accumulation_steps)
            
            # æ›´æ–°è¿›åº¦æ¡
            progress_bar.set_postfix({
                'Loss': f'{epoch_losses[-1]:.4f}',
                'PSNR': f'{noise_metrics.get("noise_psnr", 0):.4f}dB',
                'Cosine': f'{noise_metrics.get("noise_cosine_similarity", 0):.4f}',
                'GradNorm': f'{grad_health.get("gradient_norm", 0):.2f}' if (batch_idx + 1) % self.gradient_accumulation_steps == 0 else 'N/A'
            })
        
        # ğŸš€ è¾“å‡ºæ¢¯åº¦å¥åº·ç»Ÿè®¡
        if gradient_health_issues > 0:
            print(f"âš ï¸ Epoch {epoch}: æ£€æµ‹åˆ° {gradient_health_issues} æ¬¡æ¢¯åº¦å¼‚å¸¸")
        
        # è®¡ç®—epochå¹³å‡æŒ‡æ ‡
        avg_metrics = {
            'epoch': epoch,
            'loss': np.mean(epoch_losses),
            'noise_mse': np.mean(epoch_metrics['noise_mse']),
            'noise_mae': np.mean(epoch_metrics['noise_mae']),
            'noise_psnr': np.mean(epoch_metrics['noise_psnr']),
            'noise_cosine_similarity': np.mean(epoch_metrics['noise_cosine_similarity']),
            'noise_correlation': np.mean(epoch_metrics['noise_correlation']),
            'gradient_health_issues': gradient_health_issues
        }
        
        return avg_metrics
    
    def evaluate_fid(self, epoch: int) -> float:
        """è¯„ä¼°FIDåˆ†æ•°"""
        print(f"\nğŸ” Epoch {epoch} FIDè¯„ä¼°")
        
        try:
            # ğŸš€ è·å–ä¼˜åŒ–åçš„è¯„ä¼°å‚æ•°
            fid_config = self.config['fid_evaluation']
            
            fid_score = self.fid_evaluator.evaluate_model(
                model=self.model,
                num_samples=fid_config['num_samples'],
                batch_size=fid_config['batch_size'],  # ğŸš€ ä½¿ç”¨ä¼˜åŒ–åçš„batch size (64)
                num_classes=self.config['unet']['num_classes'],
                num_inference_steps=fid_config.get('num_inference_steps', 75),  # ğŸš€ å¯é…ç½®æ¨ç†æ­¥æ•°
                guidance_scale=self.config['inference']['guidance_scale'],
                eta=self.config['inference']['eta'],
                eval_classes=fid_config.get('eval_classes', 3),  # ğŸš€ åªè¯„ä¼°3ä¸ªç±»åˆ«
                parallel_generation=fid_config.get('parallel_generation', False)  # ğŸš€ å¹¶è¡Œç”Ÿæˆä¼˜åŒ–
            )
            
            print(f"  âœ… FIDè¯„ä¼°å®Œæˆ: {fid_score:.2f}")
            return fid_score
            
        except Exception as e:
            print(f"  âŒ FIDè¯„ä¼°å¤±è´¥: {e}")
            return float('inf')
    
    def generate_samples(self, epoch: int, num_samples: int = 16):
        """ç”Ÿæˆæ ·æœ¬å¹¶è®¡ç®—ISåˆ†æ•°"""
        try:
            self.model.eval()
            
            with torch.no_grad():
                # ç”Ÿæˆæ ·æœ¬
                class_labels = torch.randint(0, self.config['unet']['num_classes'], 
                                           (num_samples,), device=self.device)
                
                generated_images = self.model.sample(
                    batch_size=num_samples,
                    class_labels=class_labels,
                    num_inference_steps=self.config['inference']['num_inference_steps'],
                    guidance_scale=self.config['inference']['guidance_scale'],
                    eta=self.config['inference']['eta'],
                    use_ema=True,
                    verbose=False
                )
                
                # è®¡ç®—ISåˆ†æ•°
                try:
                    # ç¡®ä¿å›¾åƒåœ¨æ­£ç¡®èŒƒå›´å†…
                    images_for_is = torch.clamp(generated_images.cpu(), 0, 1)
                    
                    is_mean, is_std = self.metrics_calculator.inception_calculator.calculate_inception_score(
                        images_for_is, splits=min(10, num_samples//2)
                    )
                    
                    # éªŒè¯ISåˆ†æ•°åˆç†æ€§
                    if is_mean < 1.0 or is_mean > 50.0:
                        print(f"âš ï¸ ISåˆ†æ•°å¼‚å¸¸: {is_mean:.3f}, å¯èƒ½è®¡ç®—æœ‰è¯¯")
                    
                    return is_mean, is_std
                    
                except Exception as e:
                    print(f"âš ï¸ ISåˆ†æ•°è®¡ç®—å¤±è´¥: {e}")
                    return None, None
                
                # ä¿å­˜æ ·æœ¬
                if epoch % self.config['training']['sample_interval'] == 0:
                    import torchvision
                    sample_path = os.path.join(self.save_dir, f'samples_epoch_{epoch}.png')
                    torchvision.utils.save_image(
                        generated_images, sample_path,
                        nrow=4, normalize=True, value_range=(0, 1)
                    )
                    print(f"ğŸ“¸ æ ·æœ¬å·²ä¿å­˜: {sample_path}")
                
        except Exception as e:
            print(f"âš ï¸ æ ·æœ¬ç”Ÿæˆå¤±è´¥: {e}")
            return None, None
    
    def train(self):
        """ä¸»è®­ç»ƒå¾ªç¯"""
        print("ğŸš€ å¯åŠ¨å¢å¼ºç‰ˆLDMè®­ç»ƒ")
        print("=" * 80)
        print("ğŸ“Š æ¨¡å‹ç‰¹ç‚¹:")
        print("  - ç®€åŒ–å¢å¼ºç‰ˆU-Net (115.8Må‚æ•°)")
        print("  - 6ä¸ªæ³¨æ„åŠ›å±‚ Ã— 2å±‚Transformer = 12ä¸ªTransformerå—")
        print("  - å¤šå¤´æ³¨æ„åŠ›æœºåˆ¶å¢å¼ºç©ºé—´ç†è§£èƒ½åŠ›")
        print("  - P100æ˜¾å­˜å‹å¥½è®¾è®¡")
        print("  - é›†æˆå®Œæ•´æŒ‡æ ‡è¯„ä¼°ï¼šISã€å™ªå£°ç²¾åº¦ã€FIDç­‰")
        print("=" * 80)
        print("ğŸ¯ è®­ç»ƒé…ç½®ä¼˜åŒ–:")
        print(f"  - batch_size: {self.config['dataset']['batch_size']}")
        print(f"  - æ¢¯åº¦ç´¯ç§¯: {self.gradient_accumulation_steps}")
        print(f"  - å­¦ä¹ ç‡: {self.config['training']['lr']}")
        print(f"  - æ—©åœè€å¿ƒ: {self.early_stopping_patience}è½®")
        print("=" * 80)
        
        # ğŸš€ æ„å»ºä¼˜åŒ–çš„æ•°æ®åŠ è½½å™¨
        print("\nğŸš€ æ„å»ºæ•°æ®åŠ è½½å™¨ï¼ˆåº”ç”¨æ€§èƒ½ä¼˜åŒ–ï¼‰...")
        train_loader, val_loader = build_dataloader(self.config)
        
        print(f"âœ… æ•°æ®åŠ è½½å™¨åˆ›å»ºå®Œæˆ (æ€§èƒ½ä¼˜åŒ–ç‰ˆæœ¬)")
        print(f"   æ¯epochçº¦ {len(train_loader)} ä¸ªbatch")
        
        # é¢„è®¡ç®—çœŸå®æ•°æ®ç‰¹å¾ï¼ˆç”¨äºFIDï¼‰
        print("ğŸ”„ é¢„è®¡ç®—çœŸå®æ•°æ®ç‰¹å¾...")
        self.fid_evaluator.compute_real_features(val_loader)
        
        start_time = time.time()
        
        for epoch in range(1, self.config['training']['epochs'] + 1):
            # ğŸš€ æ˜¾å­˜ä¼˜åŒ–ï¼šå®šæœŸæ¸…ç†ç¼“å­˜
            if epoch % self.config.get('performance', {}).get('empty_cache_interval', 30) == 0:
                if torch.cuda.is_available():
                    torch.cuda.empty_cache()
                    print(f"ğŸ§¹ å·²æ¸…ç†GPUç¼“å­˜ (Epoch {epoch})")
            
            # è®­ç»ƒä¸€ä¸ªepoch
            epoch_metrics = self.train_epoch(train_loader, epoch)
            
            # ç”Ÿæˆæ ·æœ¬å¹¶è®¡ç®—IS
            is_mean, is_std = self.generate_samples(epoch)
            if is_mean is not None:
                epoch_metrics['inception_score_mean'] = is_mean
                epoch_metrics['inception_score_std'] = is_std
            
            # FIDè¯„ä¼°
            if epoch % self.config['fid_evaluation']['eval_interval'] == 0:
                fid_score = self.evaluate_fid(epoch)
                epoch_metrics['fid_score'] = fid_score
                
                # ğŸš€ æ£€æµ‹è®­ç»ƒæ”¹è¿›
                improvements = self.detect_improvements(epoch_metrics, epoch)
                
                # æ—©åœæ£€æŸ¥
                if fid_score < self.best_fid:
                    self.best_fid = fid_score
                    self.patience_counter = 0
                    
                    # ä¿å­˜æœ€ä½³æ¨¡å‹
                    best_model_path = os.path.join(self.save_dir, 'best_fid_model.pth')
                    torch.save(self.model.state_dict(), best_model_path)
                    print(f"ğŸ† æ–°çš„æœ€ä½³FID: {fid_score:.2f}ï¼Œæ¨¡å‹å·²ä¿å­˜")
                else:
                    self.patience_counter += 1
                    
                if self.patience_counter >= self.early_stopping_patience:
                    print(f"â¹ï¸ æ—©åœè§¦å‘ï¼Œ{self.early_stopping_patience}ä¸ªepochæ— æ”¹å–„")
                    break
            else:
                # å³ä½¿ä¸æ˜¯FIDè¯„ä¼°è½®æ¬¡ï¼Œä¹Ÿæ£€æµ‹æŸå¤±å’ŒISæ”¹è¿›
                improvements = self.detect_improvements(epoch_metrics, epoch)
            
            # ğŸš€ æ›´æ–°æœ€ä½³æŒ‡æ ‡è®°å½•
            if epoch_metrics['loss'] < self.best_loss:
                self.best_loss = epoch_metrics['loss']
                print(f"ğŸ“‰ æ–°çš„æœ€ä½³æŸå¤±: {self.best_loss:.4f}")
            
            if 'inception_score_mean' in epoch_metrics and epoch_metrics['inception_score_mean'] > self.best_is_score:
                self.best_is_score = epoch_metrics['inception_score_mean']
                print(f"â­ æ–°çš„æœ€ä½³ISåˆ†æ•°: {self.best_is_score:.3f}")
            
            # å®šæœŸä¿å­˜æ¨¡å‹
            if epoch % self.config['training']['save_interval'] == 0:
                checkpoint_path = os.path.join(self.save_dir, f'checkpoint_epoch_{epoch}.pth')
                torch.save({
                    'epoch': epoch,
                    'model_state_dict': self.model.state_dict(),
                    'optimizer_state_dict': self.optimizer.state_dict(),
                    'best_fid': self.best_fid,
                    'best_loss': self.best_loss,
                    'best_is_score': self.best_is_score,
                    'improvement_history': self.improvement_history,
                    'config': self.config
                }, checkpoint_path)
                print(f"ğŸ’¾ æ£€æŸ¥ç‚¹å·²ä¿å­˜: {checkpoint_path}")
            
            # è®°å½•æ—¥å¿—
            self.training_logs.append(epoch_metrics)
            
            # ğŸš€ æ‰“å°è¯¦ç»†æŒ‡æ ‡ï¼ˆæ”¹è¿›ç‰ˆï¼‰
            print(f"\nğŸ“Š Epoch {epoch} æŒ‡æ ‡æ€»ç»“:")
            print(f"  è®­ç»ƒæŸå¤±: {epoch_metrics['loss']:.4f} {'ğŸ”¥' if improvements.get('loss_improved', False) else ''}")
            print(f"  å™ªå£°PSNR: {epoch_metrics['noise_psnr']:.2f}dB")
            print(f"  ä½™å¼¦ç›¸ä¼¼åº¦: {epoch_metrics['noise_cosine_similarity']:.6f}")
            print(f"  ç›¸å…³ç³»æ•°: {epoch_metrics['noise_correlation']:.6f}")
            if 'inception_score_mean' in epoch_metrics:
                print(f"  ISåˆ†æ•°: {epoch_metrics['inception_score_mean']:.3f} Â± {epoch_metrics['inception_score_std']:.3f} {'ğŸŒŸ' if improvements.get('is_improved', False) else ''}")
            if 'fid_score' in epoch_metrics:
                print(f"  FIDåˆ†æ•°: {epoch_metrics['fid_score']:.2f} {'ğŸ‰' if improvements.get('fid_improved', False) else ''}")
            if epoch_metrics['gradient_health_issues'] > 0:
                print(f"  âš ï¸ æ¢¯åº¦å¼‚å¸¸: {epoch_metrics['gradient_health_issues']} æ¬¡")
            
            # ğŸš€ æ˜¾ç¤ºå†å²æœ€ä½³è®°å½•
            print(f"  ğŸ“ˆ å†å²æœ€ä½³: æŸå¤±={self.best_loss:.4f}, IS={self.best_is_score:.3f}, FID={self.best_fid:.2f}")
            print("-" * 60)
        
        total_time = time.time() - start_time
        print(f"\nâœ… è®­ç»ƒå®Œæˆï¼æ€»ç”¨æ—¶: {total_time/3600:.2f}å°æ—¶")
        print(f"ğŸ† æœ€ç»ˆæˆç»©:")
        print(f"   æœ€ä½³FIDåˆ†æ•°: {self.best_fid:.2f}")
        print(f"   æœ€ä½³æŸå¤±: {self.best_loss:.4f}")
        print(f"   æœ€ä½³ISåˆ†æ•°: {self.best_is_score:.3f}")
        
        # ğŸš€ ç»Ÿè®¡æ”¹è¿›æ¬¡æ•°
        improvement_count = sum(1 for record in self.improvement_history if record['improvements']['overall_improved'])
        print(f"   è®­ç»ƒæ”¹è¿›æ¬¡æ•°: {improvement_count} æ¬¡")
        
        # ä¿å­˜æœ€ç»ˆæ¨¡å‹å’Œæ—¥å¿—
        final_model_path = os.path.join(self.save_dir, 'final_model.pth')
        torch.save(self.model.state_dict(), final_model_path)
        
        import json
        log_path = os.path.join(self.save_dir, 'training_logs.json')
        with open(log_path, 'w') as f:
            json.dump(self.training_logs, f, indent=2)
        
        # ğŸš€ ä¿å­˜æ”¹è¿›å†å²
        improvement_log_path = os.path.join(self.save_dir, 'improvement_history.json')
        with open(improvement_log_path, 'w') as f:
            json.dump(self.improvement_history, f, indent=2)
        
        print(f"ğŸ’¾ æœ€ç»ˆæ¨¡å‹å·²ä¿å­˜: {final_model_path}")
        print(f"ğŸ“Š è®­ç»ƒæ—¥å¿—å·²ä¿å­˜: {log_path}")
        print(f"ğŸ“ˆ æ”¹è¿›å†å²å·²ä¿å­˜: {improvement_log_path}")

def main(config_path: str = "config_enhanced_unet.yaml"):
    """ä¸»å‡½æ•°"""
    
    if not os.path.exists(config_path):
        print(f"âŒ é…ç½®æ–‡ä»¶ä¸å­˜åœ¨: {config_path}")
        return
    
    # éªŒè¯é…ç½®
    try:
        config = load_config(config_path)
        
        if config['unet']['type'] != 'simple_enhanced':
            print("âŒ é…ç½®æ–‡ä»¶ä¸æ˜¯å¢å¼ºç‰ˆç±»å‹")
            return
            
        print(f"âœ… é…ç½®éªŒè¯æˆåŠŸ: {config['unet']['type']}")
        print(f"âœ… Transformeræ·±åº¦: {config['unet']['transformer_depth']}")
        
        # ğŸš€ è®¾ç½®æ€§èƒ½ä¼˜åŒ–
        print("\nğŸš€ åº”ç”¨æ€§èƒ½ä¼˜åŒ–...")
        compile_model = setup_performance_optimizations(config)
        
    except Exception as e:
        print(f"âŒ é…ç½®æ–‡ä»¶é”™è¯¯: {e}")
        return
    
    # åˆ›å»ºè®­ç»ƒå™¨å¹¶å¼€å§‹è®­ç»ƒ
    trainer = EnhancedTrainer(config_path, compile_model=compile_model)
    trainer.train()

def load_config(config_path):
    """åŠ è½½é…ç½®æ–‡ä»¶"""
    with open(config_path, 'r', encoding='utf-8') as f:
        config = yaml.safe_load(f)
    return config

def setup_performance_optimizations(config):
    """è®¾ç½®æ€§èƒ½ä¼˜åŒ–å‚æ•°"""
    if 'performance' in config:
        perf_config = config['performance']
        
        # è®¾ç½®PyTorchçº¿ç¨‹æ•°
        if 'torch_num_threads' in perf_config:
            torch.set_num_threads(perf_config['torch_num_threads'])
            print(f"  ğŸš€ è®¾ç½®PyTorchçº¿ç¨‹æ•°: {perf_config['torch_num_threads']}")
        
        # å¯ç”¨Tensorç¼–è¯‘åŠ é€Ÿ
        if perf_config.get('compile_model', False) and hasattr(torch, 'compile'):
            print(f"  ğŸš€ å¯ç”¨torch.compileæ¨¡å‹ç¼–è¯‘åŠ é€Ÿ")
            return True
        
    return False

def create_optimized_dataloader(dataset, config):
    """åˆ›å»ºä¼˜åŒ–çš„æ•°æ®åŠ è½½å™¨"""
    dataset_config = config['dataset']
    
    # åŸºç¡€å‚æ•°
    batch_size = dataset_config['batch_size']
    num_workers = dataset_config['num_workers']
    
    # æ€§èƒ½ä¼˜åŒ–å‚æ•°
    pin_memory = dataset_config.get('pin_memory', True)
    persistent_workers = dataset_config.get('persistent_workers', True) and num_workers > 0
    
    # é¢„å–å‚æ•°
    prefetch_factor = 2  # é»˜è®¤å€¼
    if 'performance' in config:
        prefetch_factor = config['performance'].get('prefetch_factor', 2)
    
    print(f"  ğŸš€ æ•°æ®åŠ è½½å™¨ä¼˜åŒ–:")
    print(f"     - batch_size: {batch_size}")
    print(f"     - num_workers: {num_workers}")
    print(f"     - pin_memory: {pin_memory}")
    print(f"     - persistent_workers: {persistent_workers}")
    print(f"     - prefetch_factor: {prefetch_factor}")
    
    return DataLoader(
        dataset,
        batch_size=batch_size,
        shuffle=dataset_config.get('shuffle_train', True),
        num_workers=num_workers,
        pin_memory=pin_memory,
        persistent_workers=persistent_workers,
        prefetch_factor=prefetch_factor if num_workers > 0 else 2,
        drop_last=True  # ç¡®ä¿batch sizeä¸€è‡´
    )

if __name__ == "__main__":
    main() 
