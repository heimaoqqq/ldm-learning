#!/usr/bin/env python3
"""
åŸºäºStable Diffusionçš„è½»é‡åŒ–LDMè®­ç»ƒè„šæœ¬
é«˜æ•ˆè®­ç»ƒï¼Œå¿«é€Ÿæ”¶æ•›ï¼Œä¸“é—¨é€‚é…æ‚¨çš„VAE
"""

import os
import yaml
import torch
import torch.nn as nn
import torch.optim as optim
from torch.utils.data import DataLoader
import sys
import time
import math
from tqdm import tqdm
import matplotlib.pyplot as plt
import torchvision.utils as vutils
from typing import Dict, Any
import json

# æ·»åŠ æ¨¡å—è·¯å¾„
sys.path.append(os.path.join(os.path.dirname(__file__), '..', 'VAE'))

from stable_ldm import StableLDM, create_stable_ldm
from dataset import build_dataloader
from fid_evaluation import FIDEvaluator
from metrics import DiffusionMetrics, denormalize_for_metrics

def denormalize(x):
    """åå½’ä¸€åŒ–å›¾åƒï¼Œä»[-1,1]è½¬æ¢åˆ°[0,1]"""
    return (x * 0.5 + 0.5).clamp(0, 1)

def save_sample_images(model, device, config, epoch, save_dir):
    """ç”Ÿæˆå¹¶ä¿å­˜æ ·æœ¬å›¾åƒ"""
    model.eval()
    with torch.no_grad():
        num_classes = config['unet']['num_classes']
        num_samples_per_class = min(2, config['inference']['num_samples_per_class'])
        
        all_images = []
        for class_id in range(min(8, num_classes)):  # æœ€å¤šæ˜¾ç¤º8ä¸ªç±»åˆ«
            class_labels = torch.tensor([class_id] * num_samples_per_class, device=device)
            
            generated_images = model.sample(
                batch_size=num_samples_per_class,
                class_labels=class_labels,
                num_inference_steps=config['inference']['num_inference_steps'],
                guidance_scale=config['inference']['guidance_scale'],
                eta=config['inference']['eta'],
                use_ema=config.get('use_ema', False),
                verbose=True
            )
            
            all_images.append(generated_images)
        
        # æ‹¼æ¥æ‰€æœ‰å›¾åƒ
        if all_images:
            all_images = torch.cat(all_images, dim=0)
            
            # ä¿å­˜å›¾åƒç½‘æ ¼
            grid = vutils.make_grid(all_images, nrow=num_samples_per_class, normalize=False, padding=2)
            save_path = os.path.join(save_dir, f"samples_epoch_{epoch:04d}.png")
            vutils.save_image(grid, save_path)
            print(f"  æ ·æœ¬å›¾åƒå·²ä¿å­˜: {save_path}")

def save_model_checkpoint(model, save_path, epoch=None, extra_info=None):
    """ä¿å­˜æ¨¡å‹æ£€æŸ¥ç‚¹"""
    os.makedirs(save_path, exist_ok=True)
    
    # ä¿å­˜U-Netæƒé‡
    model_path = os.path.join(save_path, 'unet.pth')
    torch.save(model.unet.state_dict(), model_path)
    
    # ä¿å­˜EMAæƒé‡ï¼ˆå¦‚æœæœ‰ï¼‰
    if hasattr(model, 'ema') and model.ema is not None:
        ema_path = os.path.join(save_path, 'ema.pth')
        torch.save(model.ema.shadow, ema_path)
    
    # ä¿å­˜æ£€æŸ¥ç‚¹ä¿¡æ¯
    checkpoint_info = {
        'model_type': 'StableLDM',
        'epoch': epoch,
        'unet_path': model_path,
        'has_ema': hasattr(model, 'ema') and model.ema is not None,
        'timestamp': time.time()
    }
    
    if extra_info:
        checkpoint_info.update(extra_info)
    
    info_path = os.path.join(save_path, 'checkpoint_info.json')
    with open(info_path, 'w') as f:
        json.dump(checkpoint_info, f, indent=2)
    
    return model_path

def get_cosine_schedule_with_warmup(optimizer, num_warmup_steps: int, num_training_steps: int):
    """ä½™å¼¦å­¦ä¹ ç‡è°ƒåº¦å™¨"""
    def lr_lambda(current_step):
        if current_step < num_warmup_steps:
            return float(current_step) / float(max(1, num_warmup_steps))
        progress = float(current_step - num_warmup_steps) / float(max(1, num_training_steps - num_warmup_steps))
        return max(0.0, 0.5 * (1.0 + math.cos(math.pi * progress)))

    return torch.optim.lr_scheduler.LambdaLR(optimizer, lr_lambda)

def train_stable_ldm():
    """è½»é‡åŒ–LDMè®­ç»ƒä¸»å‡½æ•°"""
    
    # åŠ è½½é…ç½®
    with open('config.yaml', 'r', encoding='utf-8') as f:
        config = yaml.safe_load(f)
    
    # è®¾å¤‡é…ç½®
    if config['device'] == 'auto':
        device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
    else:
        device = torch.device(config['device'])
    print(f"ğŸš€ ä½¿ç”¨è®¾å¤‡: {device}")
    
    # æ··åˆç²¾åº¦è®­ç»ƒ
    use_amp = config.get('mixed_precision', True) and device.type == 'cuda'
    scaler = torch.cuda.amp.GradScaler() if use_amp else None
    print(f"âš¡ æ··åˆç²¾åº¦è®­ç»ƒ: {'å¯ç”¨' if use_amp else 'ç¦ç”¨'}")
    
    # åˆ›å»ºä¿å­˜ç›®å½•
    save_dir = config['training']['save_dir']
    os.makedirs(save_dir, exist_ok=True)
    
    sample_dir = os.path.join(save_dir, "samples")
    os.makedirs(sample_dir, exist_ok=True)
    
    log_dir = os.path.join(save_dir, "logs")
    os.makedirs(log_dir, exist_ok=True)
    
    # æ„å»ºæ•°æ®åŠ è½½å™¨
    print("ğŸ“ åŠ è½½æ•°æ®é›†...")
    train_loader, val_loader, train_dataset_len, val_dataset_len = build_dataloader(
        config['dataset']['root_dir'],
        batch_size=config['dataset']['batch_size'],
        num_workers=config['dataset']['num_workers'],
        shuffle_train=True,
        shuffle_val=False,
        val_split=config['dataset']['val_split']
    )
    
    print(f"âœ… æ•°æ®é›†åŠ è½½å®Œæˆ: è®­ç»ƒé›† {train_dataset_len}, éªŒè¯é›† {val_dataset_len}")
    
    # åˆå§‹åŒ–è½»é‡åŒ–LDMæ¨¡å‹
    print("ğŸ”¥ åˆå§‹åŒ–è½»é‡åŒ–LDMæ¨¡å‹...")
    
    # å¤„ç†VAEè·¯å¾„
    vae_path = config['vae']['model_path']
    if vae_path.startswith('../'):
        vae_path = os.path.join(os.path.dirname(__file__), vae_path)
    
    # æ£€æŸ¥VAEæ–‡ä»¶
    if not os.path.exists(vae_path):
        print(f"âŒ é”™è¯¯: VAEæƒé‡æ–‡ä»¶ä¸å­˜åœ¨: {vae_path}")
        print(f"ğŸ’¡ è¯·ç¡®ä¿VAEæ¨¡å‹å·²è®­ç»ƒå®Œæˆ")
        return
    
    print(f"âœ“ å‘ç°VAEæƒé‡æ–‡ä»¶: {vae_path}")
    config['vae']['model_path'] = vae_path
    
    model = create_stable_ldm(config).to(device)
    
    # åˆå§‹åŒ–è¯„ä¼°å™¨
    print("ğŸ“Š åˆå§‹åŒ–è¯„ä¼°å™¨...")
    diffusion_metrics = DiffusionMetrics(device=device)
    
    fid_evaluator = None
    if config['fid_evaluation']['enabled']:
        print("ğŸ“ˆ åˆå§‹åŒ–FIDè¯„ä¼°å™¨...")
        fid_evaluator = FIDEvaluator(device=device)
        print("ğŸ”„ è®¡ç®—çœŸå®æ•°æ®ç‰¹å¾...")
        fid_evaluator.compute_real_features(val_loader, max_samples=1000)
    
    # ä¼˜åŒ–å™¨é…ç½®
    learning_rate = config['training']['lr']
    optimizer = optim.AdamW(
        model.unet.parameters(),
        lr=learning_rate,
        weight_decay=config['training']['weight_decay'],
        betas=(config['training']['beta1'], config['training']['beta2']),
        eps=config['training']['eps']
    )
    
    # å­¦ä¹ ç‡è°ƒåº¦å™¨
    scheduler = None
    if config['training']['use_scheduler']:
        total_steps = len(train_loader) * config['training']['epochs']
        scheduler = get_cosine_schedule_with_warmup(
            optimizer,
            num_warmup_steps=config['training']['warmup_steps'],
            num_training_steps=total_steps
        )
        print(f"ğŸ“ˆ ä½¿ç”¨ä½™å¼¦å­¦ä¹ ç‡è°ƒåº¦å™¨")
    
    # è®­ç»ƒçŠ¶æ€
    start_epoch = 0
    best_loss = float('inf')
    best_fid = float('inf')
    global_step = 0
    
    # è®­ç»ƒæ—¥å¿—
    training_log = {
        'epochs': [],
        'train_loss': [],
        'val_loss': [],
        'fid_scores': [],
        'learning_rates': []
    }
    
    print("=" * 80)
    print(f"ğŸš€ å¼€å§‹è½»é‡åŒ–LDMè®­ç»ƒï¼Œå…± {config['training']['epochs']} ä¸ªepoch")
    print("=" * 80)
    
    for epoch in range(start_epoch, config['training']['epochs']):
        model.train()
        epoch_loss = 0.0
        epoch_start_time = time.time()
        
        progress_bar = tqdm(train_loader, desc=f"Epoch {epoch+1}/{config['training']['epochs']}")
        
        for batch_idx, (images, labels) in enumerate(progress_bar):
            images = images.to(device)
            labels = labels.to(device)
            
            optimizer.zero_grad()
            
            # æ··åˆç²¾åº¦å‰å‘ä¼ æ’­
            if use_amp:
                with torch.cuda.amp.autocast():
                    outputs = model(images, class_labels=labels)
                    loss = outputs['loss']
                
                # æ··åˆç²¾åº¦åå‘ä¼ æ’­
                scaler.scale(loss).backward()
                
                # æ¢¯åº¦è£å‰ª
                if config['training']['grad_clip_norm'] > 0:
                    scaler.unscale_(optimizer)
                    torch.nn.utils.clip_grad_norm_(model.unet.parameters(), config['training']['grad_clip_norm'])
                
                scaler.step(optimizer)
                scaler.update()
            else:
                # æ ‡å‡†è®­ç»ƒ
                outputs = model(images, class_labels=labels)
                loss = outputs['loss']
                
                loss.backward()
                
                if config['training']['grad_clip_norm'] > 0:
                    torch.nn.utils.clip_grad_norm_(model.unet.parameters(), config['training']['grad_clip_norm'])
                
                optimizer.step()
            
            if scheduler is not None:
                scheduler.step()
            
            epoch_loss += loss.item()
            global_step += 1
            
            # æ›´æ–°è¿›åº¦æ¡
            current_lr = optimizer.param_groups[0]['lr']
            progress_bar.set_postfix({
                'loss': f'{loss.item():.4f}',
                'lr': f'{current_lr:.2e}',
                'step': global_step
            })
            
            # æ£€æŸ¥æŸå¤±å¥åº·çŠ¶å†µ
            if math.isnan(loss.item()) or math.isinf(loss.item()):
                print(f"âŒ æ£€æµ‹åˆ°å¼‚å¸¸æŸå¤±ï¼Œè·³è¿‡æ‰¹æ¬¡")
                continue
        
        avg_epoch_loss = epoch_loss / len(train_loader)
        epoch_time = time.time() - epoch_start_time
        current_lr = optimizer.param_groups[0]['lr']
        
        # éªŒè¯
        avg_val_loss = None
        if val_loader:
            model.eval()
            val_loss = 0.0
            
            with torch.no_grad():
                for images, labels in val_loader:
                    images = images.to(device)
                    labels = labels.to(device)
                    
                    if use_amp:
                        with torch.cuda.amp.autocast():
                            outputs = model(images, class_labels=labels)
                            loss = outputs['loss']
                    else:
                        outputs = model(images, class_labels=labels)
                        loss = outputs['loss']
                    
                    val_loss += loss.item()
            
            avg_val_loss = val_loss / len(val_loader)
        else:
            avg_val_loss = avg_epoch_loss
        
        print(f"\nEpoch {epoch+1}/{config['training']['epochs']} - "
              f"Train Loss: {avg_epoch_loss:.4f} - "
              f"Val Loss: {avg_val_loss:.4f} - "
              f"Time: {epoch_time:.1f}s - "
              f"LR: {current_lr:.2e}")
        
        # FIDè¯„ä¼°
        fid_score = None
        eval_interval = config['fid_evaluation'].get('eval_interval', 5)
        if fid_evaluator and (epoch + 1) % eval_interval == 0:
            print(f"ğŸ“Š è®¡ç®—FIDåˆ†æ•°...")
            try:
                fid_start_time = time.time()
                
                num_samples = config['fid_evaluation'].get('num_samples', 1000)
                batch_size = config['fid_evaluation'].get('batch_size', 16)
                num_inference_steps = config['inference'].get('num_inference_steps', 50)
                guidance_scale = config['inference'].get('guidance_scale', 7.5)
                
                fid_score = fid_evaluator.evaluate_model(
                    model, 
                    num_samples=num_samples,
                    batch_size=batch_size,
                    num_classes=config['unet']['num_classes'],
                    num_inference_steps=num_inference_steps,
                    guidance_scale=guidance_scale
                )
                
                fid_time = time.time() - fid_start_time
                print(f"âœ… FID: {fid_score:.2f} | æ—¶é—´: {fid_time:.1f}s")
                
                # æ›´æ–°æœ€ä½³FID
                if fid_score < best_fid:
                    best_fid = fid_score
                    best_fid_model_path = os.path.join(save_dir, 'best_fid_model')
                    save_model_checkpoint(
                        model, 
                        best_fid_model_path, 
                        epoch=epoch+1, 
                        extra_info={'fid_score': fid_score, 'best_fid': True}
                    )
                    print(f"ğŸ‰ æ–°FIDçºªå½•: {best_fid:.2f}")
                
            except Exception as e:
                print(f"âš ï¸ FIDè®¡ç®—å¤±è´¥: {e}")
        
        # è®°å½•è®­ç»ƒæ—¥å¿—
        training_log['epochs'].append(epoch + 1)
        training_log['train_loss'].append(avg_epoch_loss)
        training_log['val_loss'].append(avg_val_loss)
        training_log['fid_scores'].append(fid_score)
        training_log['learning_rates'].append(current_lr)
        
        # ä¿å­˜è®­ç»ƒæ—¥å¿—
        with open(os.path.join(log_dir, 'training_log.json'), 'w') as f:
            json.dump(training_log, f, indent=2)
        
        # ä¿å­˜æœ€ä½³æŸå¤±æ¨¡å‹
        if avg_val_loss < best_loss:
            best_loss = avg_val_loss
            best_model_path = os.path.join(save_dir, 'best_loss_model')
            save_model_checkpoint(
                model, 
                best_model_path, 
                epoch=epoch+1, 
                extra_info={'val_loss': best_loss, 'best_loss': True}
            )
            print(f"ğŸ¯ æ–°æœ€ä½³æŸå¤±: {best_loss:.4f}")
        
        # å®šæœŸä¿å­˜checkpoint
        if (epoch + 1) % config['training']['save_interval'] == 0:
            checkpoint_path = os.path.join(save_dir, f'checkpoint_epoch_{epoch+1}')
            save_model_checkpoint(
                model, 
                checkpoint_path, 
                epoch=epoch+1, 
                extra_info={'train_loss': avg_epoch_loss, 'val_loss': avg_val_loss}
            )
            print(f"ğŸ’¾ ä¿å­˜checkpoint: epoch_{epoch+1}")
        
        # ç”Ÿæˆæ ·æœ¬å›¾åƒ
        if (epoch + 1) % config['training']['sample_interval'] == 0:
            print("ğŸ¨ ç”Ÿæˆæ ·æœ¬å›¾åƒ...")
            save_sample_images(model, device, config, epoch + 1, sample_dir)
        
        print("-" * 60)
    
    # ä¿å­˜æœ€ç»ˆæ¨¡å‹
    final_model_path = os.path.join(save_dir, 'final_model')
    save_model_checkpoint(
        model, 
        final_model_path, 
        epoch=config['training']['epochs'], 
        extra_info={
            'final_train_loss': avg_epoch_loss,
            'final_val_loss': avg_val_loss,
            'best_fid': best_fid if best_fid != float('inf') else None,
            'training_completed': True
        }
    )
    
    # åˆ›å»ºè®­ç»ƒæŠ¥å‘Š
    final_report = {
        'model_type': 'StableLDM_Lightweight',
        'training_completed': True,
        'total_epochs': config['training']['epochs'],
        'best_train_loss': best_loss,
        'best_fid_score': best_fid if best_fid != float('inf') else None,
        'final_train_loss': avg_epoch_loss,
        'final_val_loss': avg_val_loss,
        'unet_parameters': sum(p.numel() for p in model.unet.parameters()),
        'device': str(device),
        'mixed_precision': use_amp,
        'has_ema': hasattr(model, 'ema') and model.ema is not None,
        'config': config
    }
    
    with open(os.path.join(save_dir, 'training_report.json'), 'w') as f:
        json.dump(final_report, f, indent=2)
    
    print("=" * 80)
    print(f"ğŸ‰ è½»é‡åŒ–LDMè®­ç»ƒå®Œæˆï¼")
    print(f"ğŸ“ æœ€ç»ˆæ¨¡å‹: {final_model_path}")
    print(f"ğŸ“‰ æœ€ä½³æŸå¤±: {best_loss:.4f}")
    if best_fid != float('inf'):
        print(f"ğŸ“Š æœ€ä½³FID: {best_fid:.2f}")
    print(f"ğŸ”¥ U-Netå‚æ•°é‡: {sum(p.numel() for p in model.unet.parameters()):,}")
    print(f"ğŸ“ˆ è®­ç»ƒæ—¥å¿—: {os.path.join(log_dir, 'training_log.json')}")
    print("=" * 80)

if __name__ == "__main__":
    # è®¾ç½®éšæœºç§å­
    torch.manual_seed(42)
    if torch.cuda.is_available():
        torch.cuda.manual_seed(42)
    
    # å¼€å§‹è®­ç»ƒ
    train_stable_ldm() 
