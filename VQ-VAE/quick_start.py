#!/usr/bin/env python3
"""
VQ-VAEå¿«é€Ÿå¼€å§‹è„šæœ¬
å¸®åŠ©æ‚¨å¿«é€Ÿæµ‹è¯•å’Œä½¿ç”¨VQ-VAEè®­ç»ƒç³»ç»Ÿ
"""

import os
import sys
import subprocess
import torch

def check_basic_environment():
    """æ£€æŸ¥åŸºæœ¬ç¯å¢ƒ"""
    print("ğŸ” æ£€æŸ¥åŸºæœ¬ç¯å¢ƒ...")
    print(f"Pythonç‰ˆæœ¬: {sys.version}")
    print(f"PyTorchç‰ˆæœ¬: {torch.__version__}")
    print(f"CUDAå¯ç”¨: {torch.cuda.is_available()}")
    
    if torch.cuda.is_available():
        print(f"GPU: {torch.cuda.get_device_name(0)}")
        print(f"GPUå†…å­˜: {torch.cuda.get_device_properties(0).total_memory / 1e9:.1f}GB")
    print()

def create_sample_data():
    """åˆ›å»ºç¤ºä¾‹æ•°æ®ç”¨äºæµ‹è¯•"""
    print("ğŸ¨ åˆ›å»ºç¤ºä¾‹æ•°æ®é›†...")
    
    import numpy as np
    from PIL import Image
    
    # åˆ›å»ºdataç›®å½•
    os.makedirs("data", exist_ok=True)
    
    # ç”Ÿæˆä¸€äº›éšæœºå½©è‰²å›¾åƒä½œä¸ºç¤ºä¾‹
    for i in range(50):
        # åˆ›å»º256x256çš„éšæœºå½©è‰²å›¾åƒ
        img_array = np.random.randint(0, 255, (256, 256, 3), dtype=np.uint8)
        
        # æ·»åŠ ä¸€äº›å‡ ä½•å½¢çŠ¶ä½¿å›¾åƒæ›´æœ‰æ„ä¹‰
        if i % 3 == 0:
            # æ·»åŠ åœ†å½¢
            center = (128, 128)
            for y in range(256):
                for x in range(256):
                    if (x - center[0])**2 + (y - center[1])**2 < 3000:
                        img_array[y, x] = [255, 100, 100]
        elif i % 3 == 1:
            # æ·»åŠ çŸ©å½¢
            img_array[50:200, 50:200] = [100, 255, 100]
        else:
            # æ·»åŠ æ¡çº¹
            for y in range(256):
                if y % 20 < 10:
                    img_array[y, :] = [100, 100, 255]
        
        # ä¿å­˜å›¾åƒ
        img = Image.fromarray(img_array)
        img.save(f"data/sample_image_{i:03d}.png")
    
    print(f"âœ… åˆ›å»ºäº†50å¼ ç¤ºä¾‹å›¾åƒåˆ° data/ ç›®å½•")
    print()

def install_minimal_dependencies():
    """å®‰è£…æœ€å°ä¾èµ–"""
    print("ğŸ“¦ å®‰è£…å¿…è¦ä¾èµ–...")
    
    packages = [
        "torch",
        "torchvision", 
        "pytorch-lightning",
        "omegaconf",
        "pillow",
        "numpy",
        "matplotlib",
        "scikit-learn",
        "tqdm"
    ]
    
    for package in packages:
        try:
            __import__(package.replace('-', '_'))
            print(f"âœ… {package} å·²å®‰è£…")
        except ImportError:
            print(f"ğŸ“¦ å®‰è£… {package}...")
            subprocess.check_call([sys.executable, "-m", "pip", "install", package])
    
    print()

def test_dataset_loading():
    """æµ‹è¯•æ•°æ®åŠ è½½"""
    print("ğŸ”„ æµ‹è¯•æ•°æ®åŠ è½½...")
    
    try:
        from dataset import create_dataloaders
        
        train_loader, val_loader, test_loader = create_dataloaders(
            data_path="data",
            batch_size=4,
            num_workers=0,  # é¿å…å¤šè¿›ç¨‹é—®é¢˜
            image_size=256
        )
        
        # æµ‹è¯•åŠ è½½ä¸€ä¸ªæ‰¹æ¬¡
        batch = next(iter(train_loader))
        print(f"âœ… æ•°æ®åŠ è½½æˆåŠŸ! æ‰¹æ¬¡å½¢çŠ¶: {batch.shape}")
        print(f"   è®­ç»ƒé›†: {len(train_loader.dataset)} å¼ ")
        print(f"   éªŒè¯é›†: {len(val_loader.dataset)} å¼ ")
        print(f"   æµ‹è¯•é›†: {len(test_loader.dataset)} å¼ ")
        
    except Exception as e:
        print(f"âŒ æ•°æ®åŠ è½½å¤±è´¥: {e}")
        return False
    
    print()
    return True

def test_model_creation():
    """æµ‹è¯•æ¨¡å‹åˆ›å»º"""
    print("ğŸ—ï¸ æµ‹è¯•æ¨¡å‹åˆ›å»º...")
    
    try:
        # ä½¿ç”¨ç®€åŒ–é…ç½®é¿å…taming-transformersä¾èµ–
        from vqvae_model import create_vqvae_model
        
        model = create_vqvae_model(
            n_embed=1024,      # å°ç æœ¬ç”¨äºæµ‹è¯•
            embed_dim=64,      # å°åµŒå…¥ç»´åº¦
            ch=32,             # å°é€šé“æ•°
            resolution=256,
            learning_rate=1e-4
        )
        
        # æµ‹è¯•å‰å‘ä¼ æ’­
        x = torch.randn(2, 3, 256, 256)
        with torch.no_grad():
            recon, loss = model(x)
        
        print(f"âœ… æ¨¡å‹åˆ›å»ºæˆåŠŸ!")
        print(f"   è¾“å…¥å½¢çŠ¶: {x.shape}")
        print(f"   è¾“å‡ºå½¢çŠ¶: {recon.shape}")
        print(f"   å‚æ•°æ•°é‡: {sum(p.numel() for p in model.parameters()) / 1e6:.2f}M")
        
    except Exception as e:
        print(f"âŒ æ¨¡å‹åˆ›å»ºå¤±è´¥: {e}")
        print("å¯èƒ½éœ€è¦å®‰è£…taming-transformersï¼Œè¯·è¿è¡Œ: python setup_environment.py")
        return False
    
    print()
    return True

def run_quick_training():
    """è¿è¡Œå¿«é€Ÿè®­ç»ƒæµ‹è¯•"""
    print("ğŸš€ è¿è¡Œå¿«é€Ÿè®­ç»ƒæµ‹è¯• (5ä¸ªepoch)...")
    
    # åˆ›å»ºç®€åŒ–çš„è®­ç»ƒé…ç½®
    quick_config = """
# å¿«é€Ÿæµ‹è¯•é…ç½®
model:
  target: vqvae_model.VQVAEModel  
  params:
    embed_dim: 64
    n_embed: 1024
    ch: 32
    ch_mult: [1,2,2]
    num_res_blocks: 1
    attn_resolutions: []
    resolution: 256
    in_channels: 3
    out_ch: 3
    z_channels: 64
    beta: 0.25
    learning_rate: 1e-4
    disc_start: 10000
    disc_weight: 0.5

data:
  target: dataset.create_dataloaders
  params:
    data_path: "data"
    batch_size: 4
    num_workers: 0
    image_size: 256

trainer:
  accelerator: "auto"
  devices: 1
  precision: 32
  max_epochs: 5
  check_val_every_n_epoch: 1
  log_every_n_steps: 5
  enable_progress_bar: true
"""
    
    # ä¿å­˜é…ç½®
    os.makedirs("configs", exist_ok=True)
    with open("configs/quick_test_config.yaml", "w") as f:
        f.write(quick_config)
    
    print("é…ç½®æ–‡ä»¶å·²åˆ›å»º: configs/quick_test_config.yaml")
    print("ç°åœ¨å¯ä»¥è¿è¡Œ:")
    print("  python train_vqvae.py --config configs/quick_test_config.yaml")
    print()

def main():
    """ä¸»å‡½æ•°"""
    print("ğŸ¯ VQ-VAEå¿«é€Ÿå¼€å§‹å‘å¯¼")
    print("=" * 50)
    
    # 1. æ£€æŸ¥ç¯å¢ƒ
    check_basic_environment()
    
    # 2. å®‰è£…ä¾èµ–
    install_minimal_dependencies()
    
    # 3. åˆ›å»ºç¤ºä¾‹æ•°æ®
    if not os.path.exists("data") or len(os.listdir("data")) == 0:
        create_sample_data()
    else:
        print("âœ… æ•°æ®ç›®å½•å·²å­˜åœ¨ï¼Œè·³è¿‡ç¤ºä¾‹æ•°æ®åˆ›å»º")
        print()
    
    # 4. æµ‹è¯•æ•°æ®åŠ è½½
    if not test_dataset_loading():
        print("âŒ æ•°æ®åŠ è½½æµ‹è¯•å¤±è´¥ï¼Œè¯·æ£€æŸ¥ç¯å¢ƒ")
        return
    
    # 5. æµ‹è¯•æ¨¡å‹åˆ›å»º
    if not test_model_creation():
        print("âŒ æ¨¡å‹åˆ›å»ºæµ‹è¯•å¤±è´¥")
        print("å»ºè®®è¿è¡Œå®Œæ•´ç¯å¢ƒè®¾ç½®: python setup_environment.py")
        return
    
    # 6. åˆ›å»ºå¿«é€Ÿè®­ç»ƒé…ç½®
    run_quick_training()
    
    print("ğŸ‰ å¿«é€Ÿå¼€å§‹é…ç½®å®Œæˆ!")
    print()
    print("ğŸ“‹ æ¥ä¸‹æ¥çš„æ­¥éª¤:")
    print("1. å°†æ‚¨çš„256Ã—256å½©è‰²å›¾åƒæ”¾å…¥ data/ ç›®å½•")
    print("2. è¿è¡Œå¿«é€Ÿè®­ç»ƒæµ‹è¯•:")
    print("   python train_vqvae.py --config configs/quick_test_config.yaml")
    print("3. å¦‚éœ€å®Œæ•´åŠŸèƒ½ï¼Œè¯·è¿è¡Œ:")
    print("   python setup_environment.py")
    print()
    print("ğŸ’¡ æç¤º:")
    print("- å½“å‰ä½¿ç”¨ç®€åŒ–é…ç½®ï¼Œé€‚åˆå¿«é€Ÿæµ‹è¯•")
    print("- å®Œæ•´åŠŸèƒ½éœ€è¦å®‰è£…taming-transformers")
    print("- æŸ¥çœ‹README.mdè·å–è¯¦ç»†ä½¿ç”¨è¯´æ˜")

if __name__ == "__main__":
    main() 
