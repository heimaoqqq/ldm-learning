#!/usr/bin/env python3
"""
å¿«é€Ÿæµ‹è¯•è„šæœ¬ - éªŒè¯VQ-VAEç¯å¢ƒè®¾ç½®
"""

import os
import sys
import torch
from pathlib import Path

def test_environment():
    """æµ‹è¯•åŸºæœ¬ç¯å¢ƒ"""
    print("ğŸ§ª ç¯å¢ƒæµ‹è¯•")
    print("=" * 40)
    
    # Pythonå’ŒPyTorchç‰ˆæœ¬
    print(f"âœ… Python: {sys.version.split()[0]}")
    print(f"âœ… PyTorch: {torch.__version__}")
    
    # CUDAæ£€æŸ¥
    if torch.cuda.is_available():
        print(f"âœ… CUDA: {torch.version.cuda}")
        print(f"âœ… GPU: {torch.cuda.get_device_name(0)}")
        print(f"âœ… GPUå†…å­˜: {torch.cuda.get_device_properties(0).total_memory / 1e9:.1f}GB")
    else:
        print("âŒ CUDAä¸å¯ç”¨")
    
    print()

def test_taming_import():
    """æµ‹è¯•taming-transformerså¯¼å…¥"""
    print("ğŸ“¦ taming-transformerså¯¼å…¥æµ‹è¯•")
    print("=" * 40)
    
    # æ·»åŠ è·¯å¾„
    taming_dir = Path("../taming-transformers-master").resolve()
    if not taming_dir.exists():
        print(f"âŒ æœªæ‰¾åˆ°taming-transformersç›®å½•: {taming_dir}")
        return False
    
    sys.path.insert(0, str(taming_dir))
    
    try:
        from taming.models.vqgan import VQModel
        print("âœ… taming.models.vqgan.VQModel å¯¼å…¥æˆåŠŸ")
        
        from taming.modules.losses.vqperceptual import VQLPIPSWithDiscriminator
        print("âœ… VQLPIPSWithDiscriminator å¯¼å…¥æˆåŠŸ")
        
        from taming.modules.vqvae.quantize import VectorQuantizer2
        print("âœ… VectorQuantizer2 å¯¼å…¥æˆåŠŸ")
        
        return True
        
    except ImportError as e:
        print(f"âŒ å¯¼å…¥å¤±è´¥: {e}")
        return False

def test_model_creation():
    """æµ‹è¯•æ¨¡å‹åˆ›å»º"""
    print("\nğŸ”§ æ¨¡å‹åˆ›å»ºæµ‹è¯•")
    print("=" * 40)
    
    try:
        from taming.models.vqgan import VQModel
        
        # æœ€å°é…ç½®
        ddconfig = {
            "double_z": False,
            "z_channels": 256,
            "resolution": 256,
            "in_channels": 3,
            "out_ch": 3,
            "ch": 64,  # å‡å°‘é€šé“æ•°ç”¨äºæµ‹è¯•
            "ch_mult": [1, 2],
            "num_res_blocks": 1,
            "attn_resolutions": [],
            "dropout": 0.0
        }
        
        lossconfig = {
            "target": "taming.modules.losses.vqperceptual.VQLPIPSWithDiscriminator",
            "params": {
                "disc_conditional": False,
                "disc_in_channels": 3,
                "disc_start": 10000,
                "disc_weight": 0.8,
                "codebook_weight": 1.0
            }
        }
        
        model = VQModel(
            ddconfig=ddconfig,
            lossconfig=lossconfig,
            n_embed=1024,  # å°ç æœ¬ç”¨äºæµ‹è¯•
            embed_dim=256
        )
        
        print("âœ… VQModel åˆ›å»ºæˆåŠŸ")
        
        # è®¡ç®—å‚æ•°
        total_params = sum(p.numel() for p in model.parameters())
        print(f"âœ… æ¨¡å‹å‚æ•°: {total_params/1e6:.2f}M")
        
        return True
        
    except Exception as e:
        print(f"âŒ æ¨¡å‹åˆ›å»ºå¤±è´¥: {e}")
        return False

def test_forward_pass():
    """æµ‹è¯•å‰å‘ä¼ æ’­"""
    print("\nğŸš€ å‰å‘ä¼ æ’­æµ‹è¯•")
    print("=" * 40)
    
    try:
        from taming.models.vqgan import VQModel
        
        # åˆ›å»ºæµ‹è¯•æ¨¡å‹ (æ›´å°çš„é…ç½®)
        ddconfig = {
            "double_z": False,
            "z_channels": 64,
            "resolution": 64,
            "in_channels": 3,
            "out_ch": 3,
            "ch": 32,
            "ch_mult": [1, 2],
            "num_res_blocks": 1,
            "attn_resolutions": [],
            "dropout": 0.0
        }
        
        lossconfig = {
            "target": "taming.modules.losses.vqperceptual.VQLPIPSWithDiscriminator",
            "params": {
                "disc_conditional": False,
                "disc_in_channels": 3,
                "disc_start": 10000,
                "disc_weight": 0.8,
                "codebook_weight": 1.0
            }
        }
        
        model = VQModel(
            ddconfig=ddconfig,
            lossconfig=lossconfig,
            n_embed=512,
            embed_dim=64
        )
        
        # åˆ›å»ºæµ‹è¯•è¾“å…¥
        x = torch.randn(1, 3, 64, 64)
        
        with torch.no_grad():
            # å‰å‘ä¼ æ’­
            dec, diff = model(x)
            print(f"âœ… è¾“å…¥å½¢çŠ¶: {x.shape}")
            print(f"âœ… è¾“å‡ºå½¢çŠ¶: {dec.shape}")
            print(f"âœ… é‡åŒ–æŸå¤±: {diff.item():.4f}")
            
            # ç¼–ç è§£ç æµ‹è¯•
            quant, emb_loss, info = model.encode(x)
            rec = model.decode(quant)
            print(f"âœ… ç¼–ç å½¢çŠ¶: {quant.shape}")
            print(f"âœ… é‡å»ºå½¢çŠ¶: {rec.shape}")
        
        return True
        
    except Exception as e:
        print(f"âŒ å‰å‘ä¼ æ’­å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        return False

def test_dataset_creation():
    """æµ‹è¯•æ•°æ®é›†åˆ›å»º"""
    print("\nğŸ“Š æ•°æ®é›†æµ‹è¯•")
    print("=" * 40)
    
    try:
        # åˆ›å»ºæµ‹è¯•å›¾åƒ
        test_dir = Path("test_images")
        test_dir.mkdir(exist_ok=True)
        
        # ç”Ÿæˆä¸€äº›æµ‹è¯•å›¾åƒ
        from PIL import Image
        import numpy as np
        
        for i in range(3):
            # åˆ›å»ºéšæœºRGBå›¾åƒ
            img_array = np.random.randint(0, 255, (256, 256, 3), dtype=np.uint8)
            img = Image.fromarray(img_array)
            img.save(test_dir / f"test_image_{i}.jpg")
        
        print(f"âœ… åˆ›å»ºäº†3å¼ æµ‹è¯•å›¾åƒåœ¨ {test_dir}")
        
        # æµ‹è¯•æ•°æ®é›†ç±»
        dataset_code = '''
import torch
from torch.utils.data import Dataset
from torchvision import transforms
from PIL import Image
from pathlib import Path

class TestDataset(Dataset):
    def __init__(self, data_path="test_images", size=256):
        self.data_path = Path(data_path)
        self.size = size
        self.image_paths = list(self.data_path.glob("*.jpg"))
        
        self.transform = transforms.Compose([
            transforms.Resize(size),
            transforms.CenterCrop(size),
            transforms.ToTensor(),
            transforms.Normalize([0.5, 0.5, 0.5], [0.5, 0.5, 0.5])
        ])
    
    def __len__(self):
        return len(self.image_paths)
    
    def __getitem__(self, idx):
        image = Image.open(self.image_paths[idx]).convert('RGB')
        return {"image": self.transform(image)}

# æµ‹è¯•æ•°æ®é›†
dataset = TestDataset()
print(f"æ•°æ®é›†å¤§å°: {len(dataset)}")

# æµ‹è¯•åŠ è½½
sample = dataset[0]
print(f"æ ·æœ¬å½¢çŠ¶: {sample['image'].shape}")
print(f"æ•°æ®èŒƒå›´: [{sample['image'].min():.2f}, {sample['image'].max():.2f}]")
'''
        
        exec(dataset_code)
        print("âœ… æ•°æ®é›†åˆ›å»ºå’ŒåŠ è½½æˆåŠŸ")
        
        return True
        
    except Exception as e:
        print(f"âŒ æ•°æ®é›†æµ‹è¯•å¤±è´¥: {e}")
        return False

def main():
    """ä¸»æµ‹è¯•å‡½æ•°"""
    print("ğŸ¯ VQ-VAEç¯å¢ƒå®Œæ•´æµ‹è¯•")
    print("=" * 50)
    
    tests = [
        ("ç¯å¢ƒåŸºç¡€", test_environment),
        ("tamingå¯¼å…¥", test_taming_import),
        ("æ¨¡å‹åˆ›å»º", test_model_creation),
        ("å‰å‘ä¼ æ’­", test_forward_pass),
        ("æ•°æ®é›†åˆ›å»º", test_dataset_creation)
    ]
    
    results = {}
    
    for test_name, test_func in tests:
        try:
            results[test_name] = test_func()
        except Exception as e:
            print(f"âŒ {test_name}æµ‹è¯•å‡ºé”™: {e}")
            results[test_name] = False
        
        print()
    
    # æ€»ç»“
    print("ğŸ“‹ æµ‹è¯•æ€»ç»“")
    print("=" * 50)
    
    all_passed = True
    for test_name, passed in results.items():
        status = "âœ… é€šè¿‡" if passed else "âŒ å¤±è´¥"
        print(f"{test_name}: {status}")
        if not passed:
            all_passed = False
    
    print()
    if all_passed:
        print("ğŸ‰ æ‰€æœ‰æµ‹è¯•é€šè¿‡ï¼ç¯å¢ƒé…ç½®æ­£ç¡®ã€‚")
        print("ç°åœ¨å¯ä»¥è¿è¡Œ:")
        print("  python kaggle_vqvae_setup.py")
        print("  python train_kaggle_vqgan.py")
    else:
        print("âš ï¸ éƒ¨åˆ†æµ‹è¯•å¤±è´¥ï¼Œè¯·æ£€æŸ¥ç¯å¢ƒé…ç½®ã€‚")
    
    # æ¸…ç†æµ‹è¯•æ–‡ä»¶
    import shutil
    if Path("test_images").exists():
        shutil.rmtree("test_images")
        print("ğŸ§¹ å·²æ¸…ç†æµ‹è¯•æ–‡ä»¶")

if __name__ == "__main__":
    main() 
