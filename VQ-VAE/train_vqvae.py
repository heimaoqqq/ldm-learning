#!/usr/bin/env python3
"""
åŸºäºå®˜æ–¹taming-transformersçš„VQ-VAEè®­ç»ƒè„šæœ¬
é’ˆå¯¹Kaggle P100 16GB GPUç¯å¢ƒä¼˜åŒ–
"""

import os
import sys
import torch
import pytorch_lightning as pl
from pytorch_lightning.callbacks import ModelCheckpoint, LearningRateMonitor
from pytorch_lightning.loggers import TensorBoardLogger
from omegaconf import OmegaConf
from pathlib import Path

# æ·»åŠ taming-transformersåˆ°è·¯å¾„
sys.path.insert(0, str(Path("../taming-transformers-master").resolve()))

def main():
    print("ğŸš€ å¼€å§‹VQ-VAEè®­ç»ƒ (åŸºäºå®˜æ–¹taming-transformers)")
    print("=" * 70)
    
    # æ£€æŸ¥GPU
    if not torch.cuda.is_available():
        print("âŒ æœªæ£€æµ‹åˆ°GPU")
        return
        
    print(f"âœ… ä½¿ç”¨GPU: {torch.cuda.get_device_name(0)}")
    print(f"GPUå†…å­˜: {torch.cuda.get_device_properties(0).total_memory / 1e9:.1f}GB")
    
    # å¯¼å…¥tamingæ¨¡å—
    try:
        from taming.models.vqgan import VQModel
        print("âœ… æˆåŠŸå¯¼å…¥taming.models.vqgan.VQModel")
    except ImportError as e:
        print(f"âŒ å¯¼å…¥å¤±è´¥: {e}")
        print("è¯·æ£€æŸ¥taming-transformers-masterè·¯å¾„")
        return
    
    # å¯¼å…¥è‡ªå®šä¹‰æ•°æ®æ¨¡å—
    try:
        from kaggle_dataset import KaggleDataModule
        print("âœ… æˆåŠŸå¯¼å…¥KaggleDataModule")
    except ImportError as e:
        print(f"âŒ å¯¼å…¥kaggle_datasetå¤±è´¥: {e}")
        return
    
    # åŠ è½½é…ç½®
    config_path = "configs/kaggle_p100_vqgan.yaml"
    if not os.path.exists(config_path):
        print(f"âŒ é…ç½®æ–‡ä»¶ä¸å­˜åœ¨: {config_path}")
        return
        
    config = OmegaConf.load(config_path)
    print("âœ… é…ç½®åŠ è½½æˆåŠŸ")
    
    # åˆ›å»ºæ•°æ®æ¨¡å—
    try:
        data_module = KaggleDataModule(
            data_path="/kaggle/input/dataset",
            batch_size=12,  # P100ä¼˜åŒ–æ‰¹æ¬¡å¤§å°
            num_workers=2,
            image_size=256
        )
        print("âœ… æ•°æ®æ¨¡å—åˆ›å»ºæˆåŠŸ")
    except Exception as e:
        print(f"âŒ æ•°æ®æ¨¡å—åˆ›å»ºå¤±è´¥: {e}")
        return
    
    # åˆ›å»ºæ¨¡å‹
    try:
        model = VQModel(**config.model.params)
        model.learning_rate = config.model.base_learning_rate
        print(f"âœ… VQ-GANæ¨¡å‹åˆ›å»ºæˆåŠŸ")
        
        # è®¡ç®—æ¨¡å‹å‚æ•°
        total_params = sum(p.numel() for p in model.parameters())
        trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)
        print(f"æ€»å‚æ•°: {total_params/1e6:.2f}M")
        print(f"å¯è®­ç»ƒå‚æ•°: {trainable_params/1e6:.2f}M")
        
    except Exception as e:
        print(f"âŒ æ¨¡å‹åˆ›å»ºå¤±è´¥: {e}")
        return
    
    # åˆ›å»ºå›è°ƒå‡½æ•°
    callbacks = []
    
    # æ£€æŸ¥ç‚¹å›è°ƒ
    checkpoint_callback = ModelCheckpoint(
        dirpath="checkpoints",
        filename="vqvae-{epoch:02d}-{val_rec_loss:.4f}",
        monitor="val/rec_loss",
        mode="min",
        save_top_k=3,
        save_last=True,
        every_n_epochs=5,
        save_weights_only=False
    )
    callbacks.append(checkpoint_callback)
    
    # å­¦ä¹ ç‡ç›‘æ§
    lr_monitor = LearningRateMonitor(logging_interval='step')
    callbacks.append(lr_monitor)
    
    # åˆ›å»ºæ—¥å¿—è®°å½•å™¨
    logger = TensorBoardLogger(
        save_dir="logs",
        name="vqvae_training",
        version=None
    )
    
    # åˆ›å»ºè®­ç»ƒå™¨
    trainer = pl.Trainer(
        accelerator="gpu",
        devices=1,
        precision=16,  # æ··åˆç²¾åº¦
        max_epochs=100,
        callbacks=callbacks,
        logger=logger,
        log_every_n_steps=50,
        check_val_every_n_epoch=2,
        accumulate_grad_batches=2,  # æ¢¯åº¦ç´¯ç§¯
        gradient_clip_val=1.0,
        enable_progress_bar=True,
        benchmark=True
    )
    
    print("âœ… è®­ç»ƒå™¨åˆ›å»ºæˆåŠŸ")
    
    # å¼€å§‹è®­ç»ƒ
    try:
        print("\nğŸš€ å¼€å§‹è®­ç»ƒ...")
        print("ğŸ“Š è®­ç»ƒé…ç½®:")
        print(f"  - æ‰¹æ¬¡å¤§å°: 12 (æœ‰æ•ˆ: 24)")
        print(f"  - å­¦ä¹ ç‡: {config.model.base_learning_rate}")
        print(f"  - ç æœ¬å¤§å°: {config.model.params.n_embed}")
        print(f"  - æœ€å¤§epochs: 100")
        print(f"  - æ··åˆç²¾åº¦: 16-bit")
        
        trainer.fit(model, data_module)
        print("\nâœ… è®­ç»ƒå®Œæˆ!")
        
        # ä¿å­˜æœ€ç»ˆæ¨¡å‹
        final_path = "checkpoints/final_vqvae_model.ckpt"
        trainer.save_checkpoint(final_path)
        print(f"âœ… æœ€ç»ˆæ¨¡å‹å·²ä¿å­˜: {final_path}")
        
    except Exception as e:
        print(f"âŒ è®­ç»ƒè¿‡ç¨‹ä¸­å‡ºé”™: {e}")
        import traceback
        traceback.print_exc()

if __name__ == "__main__":
    main() 
