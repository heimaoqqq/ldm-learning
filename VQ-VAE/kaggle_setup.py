#!/usr/bin/env python3
"""
Kaggleç¯å¢ƒVQ-VAEè®¾ç½®è„šæœ¬
ä¸“é—¨ä¸ºKaggle P100 16GB GPUä¼˜åŒ–
"""

import os
import sys
import subprocess
import torch

def setup_kaggle_environment():
    """è®¾ç½®Kaggleç¯å¢ƒ"""
    print("ğŸ”§ è®¾ç½®Kaggle VQ-VAEè®­ç»ƒç¯å¢ƒ")
    print("=" * 50)
    
    # æ£€æŸ¥ç¯å¢ƒ
    print("ğŸ“Š ç¯å¢ƒä¿¡æ¯:")
    print(f"Pythonç‰ˆæœ¬: {sys.version}")
    print(f"PyTorchç‰ˆæœ¬: {torch.__version__}")
    print(f"CUDAå¯ç”¨: {torch.cuda.is_available()}")
    
    if torch.cuda.is_available():
        print(f"GPU: {torch.cuda.get_device_name(0)}")
        print(f"GPUå†…å­˜: {torch.cuda.get_device_properties(0).total_memory / 1e9:.1f}GB")
    print()
    
    # å®‰è£…å¿…è¦ä¾èµ–
    print("ğŸ“¦ å®‰è£…ä¾èµ–åŒ…...")
    packages = [
        "omegaconf",
        "einops", 
        "lpips",
        "transformers",
        "albumentations",
        "kornia"  # ç”¨äºæ•°æ®å¢å¼º
    ]
    
    for package in packages:
        try:
            print(f"å®‰è£… {package}...")
            subprocess.check_call([
                sys.executable, "-m", "pip", "install", package, "--quiet"
            ])
        except subprocess.CalledProcessError as e:
            print(f"å®‰è£… {package} å¤±è´¥: {e}")
    
    # å…‹éš†taming-transformers
    print("ğŸ“¥ å…‹éš†taming-transformers...")
    if not os.path.exists("/kaggle/working/taming-transformers"):
        try:
            subprocess.check_call([
                "git", "clone", 
                "https://github.com/CompVis/taming-transformers.git",
                "/kaggle/working/taming-transformers"
            ])
            print("âœ… taming-transformerså…‹éš†æˆåŠŸ")
        except subprocess.CalledProcessError:
            print("âŒ å…‹éš†å¤±è´¥ï¼Œä½¿ç”¨å¤‡ç”¨æ–¹æ¡ˆ")
            return False
    
    # å®‰è£…taming-transformers
    try:
        os.chdir("/kaggle/working/taming-transformers")
        subprocess.check_call([sys.executable, "-m", "pip", "install", "-e", ".", "--quiet"])
        os.chdir("/kaggle/working")
        print("âœ… taming-transformerså®‰è£…æˆåŠŸ")
    except subprocess.CalledProcessError as e:
        print(f"âŒ å®‰è£…å¤±è´¥: {e}")
        return False
    
    # åˆ›å»ºç›®å½•ç»“æ„
    directories = [
        "/kaggle/working/checkpoints",
        "/kaggle/working/logs", 
        "/kaggle/working/results",
        "/kaggle/working/configs"
    ]
    
    for directory in directories:
        os.makedirs(directory, exist_ok=True)
        print(f"âœ… åˆ›å»ºç›®å½•: {directory}")
    
    print("\nğŸ‰ Kaggleç¯å¢ƒè®¾ç½®å®Œæˆ!")
    return True

def create_kaggle_dataset_loader():
    """åˆ›å»ºKaggleæ•°æ®é›†åŠ è½½å™¨"""
    kaggle_dataset_code = '''
import os
import torch
from torch.utils.data import Dataset, DataLoader
from torchvision import transforms
from PIL import Image
import glob
import numpy as np

class KaggleImageDataset(Dataset):
    """Kaggleç¯å¢ƒä¸“ç”¨æ•°æ®é›†åŠ è½½å™¨"""
    
    def __init__(self, data_path="/kaggle/input/dataset", split="train", image_size=256):
        self.data_path = data_path
        self.split = split
        self.image_size = image_size
        
        # è·å–æ‰€æœ‰å›¾åƒæ–‡ä»¶
        self.image_paths = self._get_image_paths()
        print(f"Kaggleæ•°æ®é›† - {split}: {len(self.image_paths)} å¼ å›¾åƒ")
        
        # å›¾åƒå˜æ¢
        self.transform = self._get_transforms()
    
    def _get_image_paths(self):
        """è·å–å›¾åƒè·¯å¾„"""
        extensions = ['*.jpg', '*.jpeg', '*.png', '*.bmp', '*.tiff']
        image_paths = []
        
        # æœç´¢æ•°æ®é›†ç›®å½•
        for ext in extensions:
            paths = glob.glob(os.path.join(self.data_path, "**", ext), recursive=True)
            image_paths.extend(paths)
        
        return sorted(image_paths)
    
    def _get_transforms(self):
        """å®šä¹‰å˜æ¢"""
        if self.split == "train":
            return transforms.Compose([
                transforms.Resize((self.image_size, self.image_size)),
                transforms.RandomHorizontalFlip(p=0.5),
                transforms.ColorJitter(brightness=0.1, contrast=0.1, saturation=0.1, hue=0.05),
                transforms.ToTensor(),
                transforms.Normalize([0.5, 0.5, 0.5], [0.5, 0.5, 0.5])
            ])
        else:
            return transforms.Compose([
                transforms.Resize((self.image_size, self.image_size)),
                transforms.ToTensor(),
                transforms.Normalize([0.5, 0.5, 0.5], [0.5, 0.5, 0.5])
            ])
    
    def __len__(self):
        return len(self.image_paths)
    
    def __getitem__(self, idx):
        try:
            image_path = self.image_paths[idx]
            image = Image.open(image_path).convert('RGB')
            return self.transform(image)
        except Exception as e:
            print(f"åŠ è½½å›¾åƒå¤±è´¥ {self.image_paths[idx]}: {e}")
            return torch.randn(3, self.image_size, self.image_size)

def create_kaggle_dataloaders(data_path="/kaggle/input/dataset", batch_size=12):
    """åˆ›å»ºKaggleæ•°æ®åŠ è½½å™¨"""
    # åˆ›å»ºæ•°æ®é›†
    full_dataset = KaggleImageDataset(data_path, "train")
    
    # åˆ†å‰²æ•°æ®é›†
    total_size = len(full_dataset)
    train_size = int(total_size * 0.8)
    val_size = int(total_size * 0.1) 
    test_size = total_size - train_size - val_size
    
    train_dataset, val_dataset, test_dataset = torch.utils.data.random_split(
        full_dataset, [train_size, val_size, test_size]
    )
    
    # åˆ›å»ºæ•°æ®åŠ è½½å™¨ (P100ä¼˜åŒ–é…ç½®)
    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, 
                            num_workers=2, pin_memory=True, drop_last=True)
    val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False,
                          num_workers=2, pin_memory=True)
    test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False,
                           num_workers=2, pin_memory=True)
    
    print(f"Kaggleæ•°æ®åŠ è½½å™¨åˆ›å»ºå®Œæˆ:")
    print(f"  è®­ç»ƒé›†: {len(train_dataset)} å¼ ")
    print(f"  éªŒè¯é›†: {len(val_dataset)} å¼ ") 
    print(f"  æµ‹è¯•é›†: {len(test_dataset)} å¼ ")
    print(f"  æ‰¹æ¬¡å¤§å°: {batch_size}")
    
    return train_loader, val_loader, test_loader
'''
    
    with open("/kaggle/working/kaggle_dataset.py", "w") as f:
        f.write(kaggle_dataset_code)
    
    print("âœ… Kaggleæ•°æ®é›†åŠ è½½å™¨åˆ›å»ºå®Œæˆ")

def create_p100_optimized_config():
    """åˆ›å»ºP100 GPUä¼˜åŒ–é…ç½®"""
    p100_config = """# Kaggle P100 16GB GPUä¼˜åŒ–é…ç½®
# ä¸“é—¨é’ˆå¯¹æ‚¨çš„ç¡¬ä»¶å’Œæ•°æ®é›†è·¯å¾„

model:
  target: taming.models.vqgan.VQModel
  params:
    # æ¨¡å‹å‚æ•° - P100ä¼˜åŒ–
    embed_dim: 256
    n_embed: 8192          # é€‚ä¸­çš„ç æœ¬å¤§å°ï¼Œå¹³è¡¡è´¨é‡å’Œå†…å­˜
    
    # ç¼–ç å™¨/è§£ç å™¨ - å†…å­˜ä¼˜åŒ–
    ddconfig:
      double_z: false
      z_channels: 256
      resolution: 256
      in_channels: 3
      out_ch: 3
      ch: 128              # åŸºç¡€é€šé“æ•°
      ch_mult: [1,1,2,4]   # å‡å°‘å±‚æ•°èŠ‚çœå†…å­˜
      num_res_blocks: 2
      attn_resolutions: [32]  # åªåœ¨32x32ä½¿ç”¨æ³¨æ„åŠ›
      dropout: 0.0
    
    # æŸå¤±å‡½æ•°é…ç½®
    lossconfig:
      target: taming.modules.losses.vqperceptual.VQLPIPSWithDiscriminator
      params:
        disc_conditional: false
        disc_in_channels: 3
        disc_start: 30001      # è¾ƒæ—©å¯åŠ¨åˆ¤åˆ«å™¨
        disc_weight: 0.6       # é€‚ä¸­çš„åˆ¤åˆ«å™¨æƒé‡
        codebook_weight: 1.0
        pixelloss_weight: 1.0
        perceptual_weight: 1.0

# æ•°æ®é…ç½® - Kaggleè·¯å¾„
data:
  target: kaggle_dataset.create_kaggle_dataloaders
  params:
    data_path: "/kaggle/input/dataset"
    batch_size: 12         # P100 16GBæœ€ä¼˜æ‰¹æ¬¡å¤§å°
    image_size: 256

# è®­ç»ƒå™¨é…ç½® - P100ä¼˜åŒ–
trainer:
  accelerator: "gpu"
  devices: 1
  precision: 16          # æ··åˆç²¾åº¦è®­ç»ƒèŠ‚çœå†…å­˜
  max_epochs: 80
  check_val_every_n_epoch: 2
  accumulate_grad_batches: 2  # æ¢¯åº¦ç´¯ç§¯å¢åŠ æœ‰æ•ˆæ‰¹æ¬¡å¤§å°
  gradient_clip_val: 1.0
  log_every_n_steps: 50
  enable_progress_bar: true
  benchmark: true
  deterministic: false

# ä¼˜åŒ–å™¨é…ç½®
lightning_module_config:
  learning_rate: 4.5e-6
  weight_decay: 0.0

# å›è°ƒé…ç½®
callbacks:
  checkpoint:
    target: pytorch_lightning.callbacks.ModelCheckpoint
    params:
      dirpath: "/kaggle/working/checkpoints"
      filename: "vqvae-p100-{epoch:02d}-{val_loss:.4f}"
      monitor: "val/rec_loss"
      mode: "min"
      save_top_k: 3
      save_last: true
      every_n_epochs: 5

# æ—¥å¿—é…ç½®
logger:
  target: pytorch_lightning.loggers.TensorBoardLogger
  params:
    save_dir: "/kaggle/working/logs"
    name: "vqvae_kaggle_p100"

# P100ç‰¹å®šä¼˜åŒ–
p100_optimizations:
  # å†…å­˜ä¼˜åŒ–å»ºè®®
  - "ä½¿ç”¨precision: 16 æ··åˆç²¾åº¦è®­ç»ƒ"
  - "batch_size: 12 æ˜¯P100çš„æœ€ä¼˜è®¾ç½®"
  - "accumulate_grad_batches: 2 å¢åŠ æœ‰æ•ˆæ‰¹æ¬¡å¤§å°"
  - "ch_mult: [1,1,2,4] å‡å°‘å†…å­˜ä½¿ç”¨"
  - "attn_resolutions: [32] ä»…åœ¨å¿…è¦åˆ†è¾¨ç‡ä½¿ç”¨æ³¨æ„åŠ›"
  
# é¢„æœŸæ€§èƒ½
expected_performance:
  training_time_per_epoch: "15-25åˆ†é’Ÿ"
  memory_usage: "~14GB"
  reconstruction_loss: "0.1-0.3"
  codebook_usage: "70-85%"
"""
    
    with open("/kaggle/working/configs/kaggle_p100_config.yaml", "w") as f:
        f.write(p100_config)
    
    print("âœ… P100ä¼˜åŒ–é…ç½®åˆ›å»ºå®Œæˆ")

def create_kaggle_training_script():
    """åˆ›å»ºKaggleè®­ç»ƒè„šæœ¬"""
    training_script = '''#!/usr/bin/env python3
"""
Kaggle VQ-VAEè®­ç»ƒè„šæœ¬
é’ˆå¯¹P100 16GB GPUä¼˜åŒ–
"""

import os
import sys
import torch
import pytorch_lightning as pl
from pytorch_lightning.callbacks import ModelCheckpoint
from pytorch_lightning.loggers import TensorBoardLogger
from omegaconf import OmegaConf

# æ·»åŠ taming-transformersåˆ°è·¯å¾„
sys.path.append("/kaggle/working/taming-transformers")

def main():
    print("ğŸš€ å¼€å§‹Kaggle VQ-VAEè®­ç»ƒ")
    print("=" * 50)
    
    # æ£€æŸ¥GPU
    if torch.cuda.is_available():
        print(f"ä½¿ç”¨GPU: {torch.cuda.get_device_name(0)}")
        print(f"GPUå†…å­˜: {torch.cuda.get_device_properties(0).total_memory / 1e9:.1f}GB")
    else:
        print("âŒ æœªæ£€æµ‹åˆ°GPU")
        return
    
    # åŠ è½½é…ç½®
    config_path = "/kaggle/working/configs/kaggle_p100_config.yaml"
    if not os.path.exists(config_path):
        print(f"âŒ é…ç½®æ–‡ä»¶ä¸å­˜åœ¨: {config_path}")
        return
        
    config = OmegaConf.load(config_path)
    print("âœ… é…ç½®åŠ è½½æˆåŠŸ")
    
    # å¯¼å…¥æ‰€éœ€æ¨¡å—
    try:
        from taming.models.vqgan import VQModel
        from kaggle_dataset import create_kaggle_dataloaders
        print("âœ… æ¨¡å—å¯¼å…¥æˆåŠŸ")
    except ImportError as e:
        print(f"âŒ æ¨¡å—å¯¼å…¥å¤±è´¥: {e}")
        return
    
    # åˆ›å»ºæ•°æ®åŠ è½½å™¨
    try:
        train_loader, val_loader, test_loader = create_kaggle_dataloaders(
            data_path="/kaggle/input/dataset",
            batch_size=config.data.params.batch_size
        )
        print("âœ… æ•°æ®åŠ è½½å™¨åˆ›å»ºæˆåŠŸ")
    except Exception as e:
        print(f"âŒ æ•°æ®åŠ è½½å¤±è´¥: {e}")
        return
    
    # åˆ›å»ºæ¨¡å‹
    try:
        model = VQModel(**config.model.params)
        print(f"âœ… æ¨¡å‹åˆ›å»ºæˆåŠŸ")
        print(f"æ¨¡å‹å‚æ•°: {sum(p.numel() for p in model.parameters()) / 1e6:.2f}M")
    except Exception as e:
        print(f"âŒ æ¨¡å‹åˆ›å»ºå¤±è´¥: {e}")
        return
    
    # åˆ›å»ºå›è°ƒ
    checkpoint_callback = ModelCheckpoint(
        dirpath="/kaggle/working/checkpoints",
        filename="vqvae-kaggle-{epoch:02d}-{val_loss:.4f}",
        monitor="val/rec_loss",
        mode="min",
        save_top_k=3,
        save_last=True,
        every_n_epochs=5
    )
    
    # åˆ›å»ºè®­ç»ƒå™¨
    trainer = pl.Trainer(
        accelerator="gpu",
        devices=1,
        precision=16,
        max_epochs=config.trainer.max_epochs,
        callbacks=[checkpoint_callback],
        logger=TensorBoardLogger("/kaggle/working/logs", name="vqvae_kaggle"),
        log_every_n_steps=50,
        accumulate_grad_batches=2,
        gradient_clip_val=1.0
    )
    
    print("âœ… è®­ç»ƒå™¨åˆ›å»ºæˆåŠŸ")
    
    # å¼€å§‹è®­ç»ƒ
    try:
        print("ğŸš€ å¼€å§‹è®­ç»ƒ...")
        trainer.fit(model, train_loader, val_loader)
        print("âœ… è®­ç»ƒå®Œæˆ!")
        
        # æµ‹è¯•æ¨¡å‹
        print("ğŸ“Š å¼€å§‹æµ‹è¯•...")
        trainer.test(model, test_loader, ckpt_path="best")
        print("âœ… æµ‹è¯•å®Œæˆ!")
        
    except Exception as e:
        print(f"âŒ è®­ç»ƒå¤±è´¥: {e}")
        import traceback
        traceback.print_exc()

if __name__ == "__main__":
    main()
'''
    
    with open("/kaggle/working/train_kaggle.py", "w") as f:
        f.write(training_script)
    
    os.chmod("/kaggle/working/train_kaggle.py", 0o755)
    print("âœ… Kaggleè®­ç»ƒè„šæœ¬åˆ›å»ºå®Œæˆ")

def main():
    """ä¸»å‡½æ•°"""
    print("ğŸ¯ Kaggle VQ-VAEç¯å¢ƒè®¾ç½®")
    
    # 1. ç¯å¢ƒè®¾ç½®
    if not setup_kaggle_environment():
        print("âŒ ç¯å¢ƒè®¾ç½®å¤±è´¥")
        return
    
    # 2. åˆ›å»ºæ•°æ®åŠ è½½å™¨
    create_kaggle_dataset_loader()
    
    # 3. åˆ›å»ºP100ä¼˜åŒ–é…ç½®
    create_p100_optimized_config()
    
    # 4. åˆ›å»ºè®­ç»ƒè„šæœ¬
    create_kaggle_training_script()
    
    print("\nğŸ‰ Kaggleç¯å¢ƒè®¾ç½®å®Œæˆ!")
    print("\nğŸ“‹ ä½¿ç”¨æ–¹æ³•:")
    print("1. åœ¨Kaggle Notebookä¸­è¿è¡Œ:")
    print("   !python /kaggle/working/kaggle_setup.py")
    print("2. å¼€å§‹è®­ç»ƒ:")
    print("   !python /kaggle/working/train_kaggle.py")
    print("\nğŸ’¡ P100 16GBä¼˜åŒ–ç‰¹æ€§:")
    print("- æ‰¹æ¬¡å¤§å°: 12 (æœ€ä¼˜è®¾ç½®)")
    print("- æ··åˆç²¾åº¦è®­ç»ƒèŠ‚çœå†…å­˜")
    print("- æ¢¯åº¦ç´¯ç§¯å¢åŠ æœ‰æ•ˆæ‰¹æ¬¡å¤§å°")
    print("- ç æœ¬å¤§å°: 8192 (å¹³è¡¡è´¨é‡å’Œå†…å­˜)")

if __name__ == "__main__":
    main() 
