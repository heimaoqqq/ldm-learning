"""
å½’ä¸€åŒ–VQ-VAEæ¨¡å—
è§£å†³æ½œåœ¨ç¼–ç æ•°å€¼èŒƒå›´è¿‡å¤§çš„é—®é¢˜
"""

import torch
import torch.nn as nn
import numpy as np

class NormalizedVQVAE(nn.Module):
    """
    VQ-VAEåŒ…è£…å™¨ï¼Œè‡ªåŠ¨å¤„ç†æ½œåœ¨ç¼–ç çš„å½’ä¸€åŒ–
    è§£å†³ç¼–ç å€¼è¿‡å¤§çš„é—®é¢˜ï¼Œä½¿å…¶é€‚åˆLDMè®­ç»ƒ
    """
    
    def __init__(self, vqvae_model, normalization_method='standardize', 
                 target_range=(-1.0, 1.0), eps=1e-5):
        """
        Args:
            vqvae_model: è®­ç»ƒå¥½çš„AdvVQVAEæ¨¡å‹
            normalization_method: 'standardize' (Z-score) æˆ– 'minmax' (Min-Max scaling)
            target_range: å½“ä½¿ç”¨minmaxæ—¶çš„ç›®æ ‡èŒƒå›´
            eps: é¿å…é™¤é›¶çš„å°å¸¸æ•°
        """
        super().__init__()
        self.vqvae = vqvae_model
        self.normalization_method = normalization_method
        self.target_range = target_range
        self.eps = eps
        
        # ç”¨äºå­˜å‚¨å½’ä¸€åŒ–ç»Ÿè®¡é‡
        self.register_buffer('is_fitted', torch.tensor(False))
        self.register_buffer('mean', torch.tensor(0.0))
        self.register_buffer('std', torch.tensor(1.0))
        self.register_buffer('min_val', torch.tensor(0.0))
        self.register_buffer('max_val', torch.tensor(1.0))
        
    def fit_normalization_stats(self, dataloader, max_samples=1000):
        """
        åœ¨æ•°æ®é›†ä¸Šè®¡ç®—å½’ä¸€åŒ–ç»Ÿè®¡é‡
        
        Args:
            dataloader: æ•°æ®åŠ è½½å™¨
            max_samples: æœ€å¤§é‡‡æ ·æ•°é‡
        """
        print("ğŸ” è®¡ç®—æ½œåœ¨ç¼–ç çš„å½’ä¸€åŒ–ç»Ÿè®¡é‡...")
        
        self.vqvae.eval()
        all_encodings = []
        sample_count = 0
        
        with torch.no_grad():
            for images, _ in dataloader:
                if sample_count >= max_samples:
                    break
                    
                images = images.to(next(self.vqvae.parameters()).device)
                
                # è·å–ç¼–ç å™¨è¾“å‡ºï¼ˆVQä¹‹å‰çš„è¿ç»­è¡¨ç¤ºï¼‰
                z = self.vqvae.encoder(images)
                all_encodings.append(z.cpu())
                sample_count += images.size(0)
        
        # åˆå¹¶æ‰€æœ‰ç¼–ç 
        all_encodings = torch.cat(all_encodings, dim=0)
        
        if self.normalization_method == 'standardize':
            # è®¡ç®—å…¨å±€å‡å€¼å’Œæ ‡å‡†å·®
            self.mean = all_encodings.mean()
            self.std = all_encodings.std()
            print(f"ğŸ“Š æ ‡å‡†åŒ–ç»Ÿè®¡é‡: å‡å€¼={self.mean:.4f}, æ ‡å‡†å·®={self.std:.4f}")
            
        elif self.normalization_method == 'minmax':
            # è®¡ç®—å…¨å±€æœ€å°å€¼å’Œæœ€å¤§å€¼
            self.min_val = all_encodings.min()
            self.max_val = all_encodings.max()
            print(f"ğŸ“Š Min-Maxç»Ÿè®¡é‡: æœ€å°å€¼={self.min_val:.4f}, æœ€å¤§å€¼={self.max_val:.4f}")
        
        self.is_fitted = torch.tensor(True)
        print("âœ… å½’ä¸€åŒ–ç»Ÿè®¡é‡è®¡ç®—å®Œæˆï¼")
    
    def normalize_encoding(self, z):
        """å½’ä¸€åŒ–ç¼–ç """
        if not self.is_fitted:
            raise RuntimeError("å¿…é¡»å…ˆè°ƒç”¨fit_normalization_stats()æ¥è®¡ç®—ç»Ÿè®¡é‡ï¼")
        
        if hasattr(self, '_debug') and self._debug:
            print(f"ğŸ” å½’ä¸€åŒ–å‰: è¾“å…¥èŒƒå›´[{z.min():.4f}, {z.max():.4f}], å‡å€¼={z.mean():.4f}, æ ‡å‡†å·®={z.std():.4f}")
            print(f"ğŸ” ç»Ÿè®¡é‡: mean={self.mean:.4f}, std={self.std:.4f}")
            
        if self.normalization_method == 'standardize':
            # Z-scoreæ ‡å‡†åŒ–
            z_normalized = (z - self.mean) / (self.std + self.eps)
            
        elif self.normalization_method == 'minmax':
            # Min-Maxç¼©æ”¾
            # å…ˆç¼©æ”¾åˆ°[0, 1]
            z_01 = (z - self.min_val) / (self.max_val - self.min_val + self.eps)
            # å†ç¼©æ”¾åˆ°ç›®æ ‡èŒƒå›´
            target_min, target_max = self.target_range
            z_normalized = z_01 * (target_max - target_min) + target_min
        
        if hasattr(self, '_debug') and self._debug:
            print(f"ğŸ” å½’ä¸€åŒ–å: è¾“å‡ºèŒƒå›´[{z_normalized.min():.4f}, {z_normalized.max():.4f}], å‡å€¼={z_normalized.mean():.4f}, æ ‡å‡†å·®={z_normalized.std():.4f}")
            # åªåœ¨ç¬¬ä¸€æ¬¡æ˜¾ç¤ºè°ƒè¯•ä¿¡æ¯åå…³é—­ï¼Œé¿å…åˆ·å±
            self._debug = False
            
        return z_normalized
    
    def denormalize_encoding(self, z_normalized):
        """åå½’ä¸€åŒ–ç¼–ç ï¼ˆç”¨äºè§£ç ï¼‰"""
        if not self.is_fitted:
            raise RuntimeError("å¿…é¡»å…ˆè°ƒç”¨fit_normalization_stats()æ¥è®¡ç®—ç»Ÿè®¡é‡ï¼")
            
        if self.normalization_method == 'standardize':
            # Z-scoreåæ ‡å‡†åŒ–
            z = z_normalized * (self.std + self.eps) + self.mean
            
        elif self.normalization_method == 'minmax':
            # Min-Maxåç¼©æ”¾
            target_min, target_max = self.target_range
            # å…ˆä»ç›®æ ‡èŒƒå›´ç¼©æ”¾å›[0, 1]
            z_01 = (z_normalized - target_min) / (target_max - target_min)
            # å†ç¼©æ”¾å›åŸå§‹èŒƒå›´
            z = z_01 * (self.max_val - self.min_val + self.eps) + self.min_val
            
        return z
    
    def encode(self, x):
        """ç¼–ç å¹¶å½’ä¸€åŒ–"""
        z = self.vqvae.encoder(x)
        z_normalized = self.normalize_encoding(z)
        z_q, _, _, _ = self.vqvae.vq(z_normalized)
        return z_q
    
    def decode(self, z_q):
        """åå½’ä¸€åŒ–å¹¶è§£ç """
        z_denormalized = self.denormalize_encoding(z_q)
        return self.vqvae.decoder(z_denormalized)
    
    def encode_without_vq(self, x):
        """åªè¿›è¡Œç¼–ç å’Œå½’ä¸€åŒ–ï¼Œä¸ç»è¿‡VQå±‚ï¼ˆç”¨äºLDMè®­ç»ƒï¼‰"""
        if not self.is_fitted:
            raise RuntimeError("å¿…é¡»å…ˆè°ƒç”¨fit_normalization_stats()æ¥è®¡ç®—ç»Ÿè®¡é‡ï¼")
            
        z = self.vqvae.encoder(x)
        z_normalized = self.normalize_encoding(z)
        
        # æ·»åŠ è°ƒè¯•ä¿¡æ¯ï¼ˆåªåœ¨éœ€è¦æ—¶ï¼‰
        if hasattr(self, '_debug') and self._debug:
            print(f"ğŸ” ç¼–ç è°ƒè¯•: åŸå§‹èŒƒå›´[{z.min():.4f}, {z.max():.4f}] -> å½’ä¸€åŒ–å[{z_normalized.min():.4f}, {z_normalized.max():.4f}]")
        
        return z_normalized
    
    def decode_from_normalized(self, z_normalized):
        """ä»å½’ä¸€åŒ–çš„ç¼–ç ç›´æ¥è§£ç ï¼ˆç”¨äºLDMé‡‡æ ·ï¼‰"""
        if not self.is_fitted:
            raise RuntimeError("å¿…é¡»å…ˆè°ƒç”¨fit_normalization_stats()æ¥è®¡ç®—ç»Ÿè®¡é‡ï¼")
            
        z_denormalized = self.denormalize_encoding(z_normalized)
        return self.vqvae.decoder(z_denormalized)
    
    def forward(self, x):
        """å®Œæ•´çš„å‰å‘ä¼ æ’­"""
        z = self.vqvae.encoder(x)
        z_normalized = self.normalize_encoding(z)
        z_q, commitment_loss, codebook_loss, usage_info = self.vqvae.vq(z_normalized)
        x_recon = self.decode(z_q)
        return x_recon, commitment_loss, codebook_loss, usage_info
    
    def get_stats_summary(self):
        """è·å–ç»Ÿè®¡é‡æ‘˜è¦"""
        if not self.is_fitted:
            return "æœªæ‹Ÿåˆå½’ä¸€åŒ–ç»Ÿè®¡é‡"
            
        if self.normalization_method == 'standardize':
            return f"æ ‡å‡†åŒ–: å‡å€¼={self.mean:.4f}, æ ‡å‡†å·®={self.std:.4f}"
        else:
            return f"Min-Max: èŒƒå›´=[{self.min_val:.4f}, {self.max_val:.4f}] -> {self.target_range}" 
