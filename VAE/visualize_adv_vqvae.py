import os
import torch
import matplotlib.pyplot as plt
import yaml
from adv_vq_vae import AdvVQVAE
from dataset import build_dataloader

# åŠ è½½é…ç½®
with open('config.yaml', 'r', encoding='utf-8') as f:
    config = yaml.safe_load(f)

# è®¾å¤‡é…ç½®
device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
print(f"ä½¿ç”¨è®¾å¤‡: {device}")

# åŠ è½½æ•°æ®
_, val_loader, _, val_dataset_len = build_dataloader(
    config['dataset']['root_dir'],
    batch_size=8,
    num_workers=0,
    shuffle_train=False,
    shuffle_val=False,
    val_split=0.3
)

print(f"ä½¿ç”¨éªŒè¯é›†è¿›è¡Œå¯è§†åŒ–ï¼ŒéªŒè¯é›†æ ·æœ¬æ•°: {val_dataset_len}")

# åˆ›å»ºä¿å­˜ç›®å½•è·¯å¾„
<<<<<<< HEAD
save_dir = config['training']['save_dir']
vis_dir = os.path.join("ae_debug", "adv_vqvae_vis")

# åˆå§‹åŒ–åŸºäºæŸå¤±çš„æ¨¡å‹
loss_model = AdvVQVAE(
    in_channels=config['model']['in_channels'],
    latent_dim=config['model']['latent_dim'],
    num_embeddings=config['model']['num_embeddings'],
    beta=config['model']['beta'],
    decay=config['model'].get('vq_ema_decay', 0.99),  # ä½¿ç”¨é…ç½®çš„ EMA è¡°å‡ç‡
    groups=config['model']['groups'],
    disc_ndf=64  # åˆ¤åˆ«å™¨ç‰¹å¾æ•°é‡
).to(device)

# åˆå§‹åŒ–åŸºäºFIDçš„æ¨¡å‹
fid_model = AdvVQVAE(
    in_channels=config['model']['in_channels'],
    latent_dim=config['model']['latent_dim'],
    num_embeddings=config['model']['num_embeddings'],
    beta=config['model']['beta'],
    decay=config['model'].get('vq_ema_decay', 0.99),  # ä½¿ç”¨é…ç½®çš„ EMA è¡°å‡ç‡
    groups=config['model']['groups'],
    disc_ndf=64  # åˆ¤åˆ«å™¨ç‰¹å¾æ•°é‡
).to(device)

# åŠ è½½åŸºäºæŸå¤±çš„æ¨¡å‹æƒé‡
loss_weights_path = os.path.join(save_dir, 'adv_vqvae_best_loss.pth')
if os.path.exists(loss_weights_path):
    loss_model.load_state_dict(torch.load(loss_weights_path, map_location=device))
    print(f"åŠ è½½åŸºäºæŸå¤±çš„æœ€ä½³æ¨¡å‹: {loss_weights_path}")
else:
    print(f"è­¦å‘Š: æ‰¾ä¸åˆ°åŸºäºæŸå¤±çš„æœ€ä½³æ¨¡å‹æƒé‡: {loss_weights_path}")
    print(f"å°è¯•åŠ è½½é»˜è®¤ä½ç½®çš„æƒé‡...")
    # å°è¯•åŠ è½½æ—§æ ¼å¼çš„æ¨¡å‹æƒé‡
    old_weights_path = os.path.join(save_dir, 'adv_vqvae_best.pth')
    if os.path.exists(old_weights_path):
        loss_model.load_state_dict(torch.load(old_weights_path, map_location=device))
        print(f"åŠ è½½æ—§æ ¼å¼æ¨¡å‹: {old_weights_path}")
    else:
        print(f"è­¦å‘Š: æ‰¾ä¸åˆ°æ—§æ ¼å¼æ¨¡å‹æƒé‡: {old_weights_path}")

# åŠ è½½åŸºäºFIDçš„æ¨¡å‹æƒé‡
fid_weights_path = os.path.join(save_dir, 'adv_vqvae_best_fid.pth')
has_fid_model = False
if os.path.exists(fid_weights_path):
    fid_model.load_state_dict(torch.load(fid_weights_path, map_location=device))
    print(f"åŠ è½½åŸºäºFIDçš„æœ€ä½³æ¨¡å‹: {fid_weights_path}")
    has_fid_model = True
else:
    print(f"è­¦å‘Š: æ‰¾ä¸åˆ°åŸºäºFIDçš„æœ€ä½³æ¨¡å‹æƒé‡: {fid_weights_path}")
    print(f"å¯è§†åŒ–å°†åªä½¿ç”¨åŸºäºæŸå¤±çš„æ¨¡å‹")

# è®¾ç½®è¯„ä¼°æ¨¡å¼
loss_model.eval()
if has_fid_model:
    fid_model.eval()
=======
# save_dir = config['training']['save_dir'] # ä¸å†ä½¿ç”¨é…ç½®æ–‡ä»¶ä¸­çš„save_dir
vis_dir = os.path.join("vqvae_vis")  # æ”¹ä¸ºç›¸å¯¹äºå½“å‰ç›®å½•çš„è·¯å¾„

# å®šä¹‰è¦å¯è§†åŒ–çš„æ¨¡å‹é…ç½®
model_configs = [
    {
        'name': 'é¢„è®­ç»ƒFIDæ¨¡å‹', # ä¿®æ”¹åç§°ä»¥åæ˜ å®é™…åŠ è½½çš„æ¨¡å‹
        'filename': '/kaggle/input/vae-best-fid2/adv_vqvae_best_fid2.pth', # ç›´æ¥ä½¿ç”¨ä½ çš„è·¯å¾„
        'short_name': 'pretrained_fid',
        'model': None,
        'available': False
    }
]

# åˆå§‹åŒ–å’ŒåŠ è½½æ¨¡å‹
for config_item in model_configs:
    # åˆ›å»ºæ¨¡å‹å®ä¾‹
    model = AdvVQVAE(
        in_channels=config['model']['in_channels'],
        latent_dim=config['model']['latent_dim'],
        num_embeddings=config['model']['num_embeddings'],
        beta=config['model']['beta'],
        decay=config['model'].get('vq_ema_decay', 0.99),
        groups=config['model']['groups'],
        disc_ndf=64
    ).to(device)
    
    # å°è¯•åŠ è½½æƒé‡
    weights_path = config_item['filename'] # ç›´æ¥ä½¿ç”¨filenameä½œä¸ºå®Œæ•´è·¯å¾„
    if os.path.exists(weights_path):
        model.load_state_dict(torch.load(weights_path, map_location=device))
        config_item['model'] = model
        config_item['available'] = True
        print(f"âœ… æˆåŠŸåŠ è½½{config_item['name']}: {weights_path}")
    else:
        print(f"âŒ æœªæ‰¾åˆ°{config_item['name']}: {weights_path}")

# æ£€æŸ¥è‡³å°‘æœ‰ä¸€ä¸ªæ¨¡å‹å¯ç”¨
available_models = [item for item in model_configs if item['available']]
if not available_models:
    print("âŒ æ²¡æœ‰æ‰¾åˆ°ä»»ä½•å¯ç”¨çš„æ¨¡å‹ï¼Œè¯·å…ˆè®­ç»ƒæ¨¡å‹")
    exit(1)

print(f"ğŸ“Š æ‰¾åˆ° {len(available_models)} ä¸ªå¯ç”¨æ¨¡å‹ï¼Œå°†è¿›è¡Œå¯¹æ¯”å¯è§†åŒ–")

# è®¾ç½®æ‰€æœ‰å¯ç”¨æ¨¡å‹ä¸ºè¯„ä¼°æ¨¡å¼
for config_item in available_models:
    config_item['model'].eval()
>>>>>>> 126d4ad24fc08805125e6779329dd8caece6ed5d

# åˆ›å»ºå¯è§†åŒ–è¾“å‡ºç›®å½•
os.makedirs(vis_dir, exist_ok=True)

# å¯è§†åŒ–å’Œæ¯”è¾ƒ
def denormalize(x):
    return (x * 0.5 + 0.5).clamp(0, 1)

<<<<<<< HEAD
# ç»˜å›¾å‡½æ•°ï¼Œæ ¹æ®ç»™å®šçš„åŸå§‹å›¾åƒå’Œé‡å»ºå›¾åƒç”Ÿæˆæ¯”è¾ƒå›¾
def create_comparison_plot(original_images, reconstructed_images, model_name, batch_idx, save_path):
    num_images = min(8, original_images.size(0))
    plt.figure(figsize=(16, 8))
    
    # ä¸Šæ’ï¼šæ˜¾ç¤ºåŸå§‹å›¾åƒ
    for j in range(num_images):
        plt.subplot(2, num_images, j+1)
=======
# ç»˜å›¾å‡½æ•°ï¼Œæ”¯æŒå¤šä¸ªæ¨¡å‹çš„å¯¹æ¯”
def create_multi_model_comparison_plot(original_images, model_results, batch_idx, save_path):
    """
    åˆ›å»ºå¤šæ¨¡å‹å¯¹æ¯”å›¾
    model_results: list of (reconstructed_images, model_name)
    """
    num_images = min(6, original_images.size(0))  # æ¯æ‰¹æœ€å¤šæ˜¾ç¤º6å¼ å›¾åƒ
    num_models = len(model_results)
    
    # è®¡ç®—å­å›¾å¸ƒå±€ï¼šåŸå§‹å›¾åƒ + å„æ¨¡å‹é‡å»º
    rows = num_models + 1
    cols = num_images
    
    plt.figure(figsize=(cols * 3, rows * 2.5))
    
    # ç¬¬ä¸€è¡Œï¼šæ˜¾ç¤ºåŸå§‹å›¾åƒ
    for j in range(num_images):
        plt.subplot(rows, cols, j + 1)
>>>>>>> 126d4ad24fc08805125e6779329dd8caece6ed5d
        plt.imshow(original_images[j].permute(1, 2, 0).cpu().numpy())
        plt.title(f"åŸå§‹å›¾åƒ #{j+1}", fontsize=10)
        plt.axis('off')
    
<<<<<<< HEAD
    # ä¸‹æ’ï¼šæ˜¾ç¤ºé‡å»ºå›¾åƒ
    for j in range(num_images):
        plt.subplot(2, num_images, num_images + j + 1)
        plt.imshow(reconstructed_images[j].permute(1, 2, 0).cpu().numpy())
        plt.title(f"{model_name}é‡å»º #{j+1}", fontsize=10)
        plt.axis('off')
    
    plt.tight_layout()
    plt.savefig(save_path, dpi=200)
=======
    # åç»­è¡Œï¼šæ˜¾ç¤ºå„æ¨¡å‹çš„é‡å»ºç»“æœ
    for model_idx, (recon_images, model_name) in enumerate(model_results):
        row_start = (model_idx + 1) * cols + 1
        for j in range(num_images):
            plt.subplot(rows, cols, row_start + j)
            plt.imshow(recon_images[j].permute(1, 2, 0).cpu().numpy())
            plt.title(f"{model_name} #{j+1}", fontsize=10)
            plt.axis('off')
    
    plt.tight_layout()
    plt.savefig(save_path, dpi=200, bbox_inches='tight')
>>>>>>> 126d4ad24fc08805125e6779329dd8caece6ed5d
    plt.close()
    
    return save_path

<<<<<<< HEAD
# å¯¹æŠ—è®­ç»ƒVQ-VAEçš„å¯è§†åŒ–ï¼šä¸ºæ¯ä¸ªæ¨¡å‹ç”Ÿæˆç‹¬ç«‹çš„æ¯”è¾ƒå›¾
=======
# è¿›è¡Œå¤šæ¨¡å‹å¯¹æ¯”å¯è§†åŒ–
print("\nå¼€å§‹ç”Ÿæˆå¤šæ¨¡å‹å¯¹æ¯”å¯è§†åŒ–...")
>>>>>>> 126d4ad24fc08805125e6779329dd8caece6ed5d
with torch.no_grad():
    for i, (images, _) in enumerate(val_loader):
        if i >= 5:  # åªæ˜¾ç¤ºå‰5æ‰¹æ¬¡
            break
            
        images = images.to(device)
<<<<<<< HEAD
        batch_size = images.size(0)
=======
>>>>>>> 126d4ad24fc08805125e6779329dd8caece6ed5d
        
        # åå½’ä¸€åŒ–åŸå§‹å›¾åƒ
        norm_images = denormalize(images)
        
<<<<<<< HEAD
        # åŸºäºæŸå¤±çš„æ¨¡å‹é‡å»ºå’Œå¯è§†åŒ–
        loss_recon, _, _ = loss_model(images)
        loss_recon = denormalize(loss_recon)
        loss_image_path = os.path.join(vis_dir, f"adv_vqvae_loss_batch_{i+1}.png")
        create_comparison_plot(
            norm_images, 
            loss_recon, 
            "åŸºäºæŸå¤±æ¨¡å‹", 
            i+1, 
            loss_image_path
        )
        print(f"å·²ä¿å­˜åŸºäºæŸå¤±æ¨¡å‹çš„é‡å»ºæ¯”è¾ƒ: {loss_image_path}")
        
        # å¦‚æœæœ‰åŸºäºFIDçš„æ¨¡å‹ï¼Œä¹Ÿç”Ÿæˆå…¶å¯¹åº”çš„æ¯”è¾ƒå›¾
        if has_fid_model:
            fid_recon, _, _ = fid_model(images)
            fid_recon = denormalize(fid_recon)
            fid_image_path = os.path.join(vis_dir, f"adv_vqvae_fid_batch_{i+1}.png")
            create_comparison_plot(
                norm_images, 
                fid_recon, 
                "åŸºäºFIDæ¨¡å‹", 
                i+1, 
                fid_image_path
            )
            print(f"å·²ä¿å­˜åŸºäºFIDæ¨¡å‹çš„é‡å»ºæ¯”è¾ƒ: {fid_image_path}")

print(f"å¯è§†åŒ–å®Œæˆï¼Œè¯·æŸ¥çœ‹ {vis_dir} ç›®å½•ä¸‹çš„å›¾åƒ") 
=======
        # æ”¶é›†æ‰€æœ‰å¯ç”¨æ¨¡å‹çš„é‡å»ºç»“æœ
        model_results = []
        for config_item in available_models:
            recon, _, _, _ = config_item['model'](images)  # æ¨¡å‹è¿”å›4ä¸ªå€¼ï¼šrecon, commitment_loss, codebook_loss, usage_info
            recon_norm = denormalize(recon)
            model_results.append((recon_norm, config_item['name']))
        
        # åˆ›å»ºå¤šæ¨¡å‹å¯¹æ¯”å›¾
        comparison_path = os.path.join(vis_dir, f"multi_model_comparison_batch_{i+1}.png")
        create_multi_model_comparison_plot(norm_images, model_results, i+1, comparison_path)
        print(f"âœ… å·²ä¿å­˜å¤šæ¨¡å‹å¯¹æ¯”å›¾: {comparison_path}")
        
        # åŒæ—¶ä¸ºæ¯ä¸ªæ¨¡å‹å•ç‹¬ä¿å­˜å›¾åƒï¼ˆä¿æŒå…¼å®¹æ€§ï¼‰
        for config_item in available_models:
            recon, _, _, _ = config_item['model'](images)  # ä¿®å¤è¿™é‡Œä¹Ÿéœ€è¦4ä¸ªå€¼
            recon_norm = denormalize(recon)
            single_path = os.path.join(vis_dir, f"{config_item['short_name']}_batch_{i+1}.png")
            
            # ä¸ºå•ä¸ªæ¨¡å‹åˆ›å»ºå¯¹æ¯”å›¾
            plt.figure(figsize=(16, 8))
            num_images = min(8, images.size(0))
            
            # ä¸Šæ’ï¼šåŸå§‹å›¾åƒ
            for j in range(num_images):
                plt.subplot(2, num_images, j+1)
                plt.imshow(norm_images[j].permute(1, 2, 0).cpu().numpy())
                plt.title(f"åŸå§‹ #{j+1}", fontsize=10)
                plt.axis('off')
            
            # ä¸‹æ’ï¼šé‡å»ºå›¾åƒ
            for j in range(num_images):
                plt.subplot(2, num_images, num_images + j + 1)
                plt.imshow(recon_norm[j].permute(1, 2, 0).cpu().numpy())
                plt.title(f"{config_item['name']} #{j+1}", fontsize=10)
                plt.axis('off')
            
            plt.tight_layout()
            plt.savefig(single_path, dpi=200)
            plt.close()
            print(f"âœ… å·²ä¿å­˜{config_item['name']}å•ç‹¬å¯¹æ¯”å›¾: {single_path}")

print(f"\nğŸ‰ å¯è§†åŒ–å®Œæˆï¼")
print(f"ğŸ“ å¤šæ¨¡å‹å¯¹æ¯”å›¾: {vis_dir}/multi_model_comparison_batch_*.png")
print(f"ğŸ“ å•æ¨¡å‹å¯¹æ¯”å›¾: {vis_dir}/*_batch_*.png")
print(f"ğŸ“ æ€»å…±ç”Ÿæˆäº† {len(available_models) * 5 + 5} å¼ å›¾åƒ") 
>>>>>>> 126d4ad24fc08805125e6779329dd8caece6ed5d
