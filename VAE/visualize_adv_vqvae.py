import os
import torch
import matplotlib.pyplot as plt
import yaml
from adv_vq_vae import AdvVQVAE
from dataset import build_dataloader

# åŠ è½½é…ç½®
with open('config.yaml', 'r', encoding='utf-8') as f:
    config = yaml.safe_load(f)

# è®¾å¤‡é…ç½®
device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
print(f"ä½¿ç”¨è®¾å¤‡: {device}")

# åŠ è½½æ•°æ®
_, val_loader, _, val_dataset_len = build_dataloader(
    config['dataset']['root_dir'],
    batch_size=8,
    num_workers=0,
    shuffle_train=False,
    shuffle_val=False,
    val_split=0.3
)

print(f"ä½¿ç”¨éªŒè¯é›†è¿›è¡Œå¯è§†åŒ–ï¼ŒéªŒè¯é›†æ ·æœ¬æ•°: {val_dataset_len}")

# åˆ›å»ºä¿å­˜ç›®å½•è·¯å¾„
# save_dir = config['training']['save_dir'] # ä¸å†ä½¿ç”¨é…ç½®æ–‡ä»¶ä¸­çš„save_dir
vis_dir = os.path.join("vqvae_vis")  # æ”¹ä¸ºç›¸å¯¹äºå½“å‰ç›®å½•çš„è·¯å¾„

# å®šä¹‰è¦å¯è§†åŒ–çš„æ¨¡å‹é…ç½®
model_configs = [
    {
        'name': 'é¢„è®­ç»ƒFIDæ¨¡å‹', # ä¿®æ”¹åç§°ä»¥åæ˜ å®é™…åŠ è½½çš„æ¨¡å‹
        'filename': '/kaggle/input/vae-best-fid2/adv_vqvae_best_fid2.pth', # ç›´æ¥ä½¿ç”¨ä½ çš„è·¯å¾„
        'short_name': 'pretrained_fid',
        'model': None,
        'available': False
    }
]

# åˆå§‹åŒ–å’ŒåŠ è½½æ¨¡å‹
for config_item in model_configs:
    # åˆ›å»ºæ¨¡å‹å®ä¾‹
    model = AdvVQVAE(
        in_channels=config['model']['in_channels'],
        latent_dim=config['model']['latent_dim'],
        num_embeddings=config['model']['num_embeddings'],
        beta=config['model']['beta'],
        decay=config['model'].get('vq_ema_decay', 0.99),
        groups=config['model']['groups'],
        disc_ndf=64
    ).to(device)
    
    # å°è¯•åŠ è½½æƒé‡
    weights_path = config_item['filename'] # ç›´æ¥ä½¿ç”¨filenameä½œä¸ºå®Œæ•´è·¯å¾„
    if os.path.exists(weights_path):
        model.load_state_dict(torch.load(weights_path, map_location=device))
        config_item['model'] = model
        config_item['available'] = True
        print(f"âœ… æˆåŠŸåŠ è½½{config_item['name']}: {weights_path}")
    else:
        print(f"âŒ æœªæ‰¾åˆ°{config_item['name']}: {weights_path}")

# æ£€æŸ¥è‡³å°‘æœ‰ä¸€ä¸ªæ¨¡å‹å¯ç”¨
available_models = [item for item in model_configs if item['available']]
if not available_models:
    print("âŒ æ²¡æœ‰æ‰¾åˆ°ä»»ä½•å¯ç”¨çš„æ¨¡å‹ï¼Œè¯·å…ˆè®­ç»ƒæ¨¡å‹")
    exit(1)

print(f"ğŸ“Š æ‰¾åˆ° {len(available_models)} ä¸ªå¯ç”¨æ¨¡å‹ï¼Œå°†è¿›è¡Œå¯¹æ¯”å¯è§†åŒ–")

# è®¾ç½®æ‰€æœ‰å¯ç”¨æ¨¡å‹ä¸ºè¯„ä¼°æ¨¡å¼
for config_item in available_models:
    config_item['model'].eval()

# åˆ›å»ºå¯è§†åŒ–è¾“å‡ºç›®å½•
os.makedirs(vis_dir, exist_ok=True)

# å¯è§†åŒ–å’Œæ¯”è¾ƒ
def denormalize(x):
    return (x * 0.5 + 0.5).clamp(0, 1)

# ç»˜å›¾å‡½æ•°ï¼Œæ”¯æŒå¤šä¸ªæ¨¡å‹çš„å¯¹æ¯”
def create_multi_model_comparison_plot(original_images, model_results, batch_idx, save_path):
    """
    åˆ›å»ºå¤šæ¨¡å‹å¯¹æ¯”å›¾
    model_results: list of (reconstructed_images, model_name)
    """
    num_images = min(6, original_images.size(0))  # æ¯æ‰¹æœ€å¤šæ˜¾ç¤º6å¼ å›¾åƒ
    num_models = len(model_results)
    
    # è®¡ç®—å­å›¾å¸ƒå±€ï¼šåŸå§‹å›¾åƒ + å„æ¨¡å‹é‡å»º
    rows = num_models + 1
    cols = num_images
    
    plt.figure(figsize=(cols * 3, rows * 2.5))
    
    # ç¬¬ä¸€è¡Œï¼šæ˜¾ç¤ºåŸå§‹å›¾åƒ
    for j in range(num_images):
        plt.subplot(rows, cols, j + 1)
        plt.imshow(original_images[j].permute(1, 2, 0).cpu().numpy())
        plt.title(f"åŸå§‹å›¾åƒ #{j+1}", fontsize=10)
        plt.axis('off')
    
    # åç»­è¡Œï¼šæ˜¾ç¤ºå„æ¨¡å‹çš„é‡å»ºç»“æœ
    for model_idx, (recon_images, model_name) in enumerate(model_results):
        row_start = (model_idx + 1) * cols + 1
        for j in range(num_images):
            plt.subplot(rows, cols, row_start + j)
            plt.imshow(recon_images[j].permute(1, 2, 0).cpu().numpy())
            plt.title(f"{model_name} #{j+1}", fontsize=10)
            plt.axis('off')
    
    plt.tight_layout()
    plt.savefig(save_path, dpi=200, bbox_inches='tight')
    plt.close()
    
    return save_path

# è¿›è¡Œå¤šæ¨¡å‹å¯¹æ¯”å¯è§†åŒ–
print("\nå¼€å§‹ç”Ÿæˆå¤šæ¨¡å‹å¯¹æ¯”å¯è§†åŒ–...")
with torch.no_grad():
    for i, (images, _) in enumerate(val_loader):
        if i >= 5:  # åªæ˜¾ç¤ºå‰5æ‰¹æ¬¡
            break
            
        images = images.to(device)
        
        # åå½’ä¸€åŒ–åŸå§‹å›¾åƒ
        norm_images = denormalize(images)
        
        # æ”¶é›†æ‰€æœ‰å¯ç”¨æ¨¡å‹çš„é‡å»ºç»“æœ
        model_results = []
        for config_item in available_models:
            recon, _, _ = config_item['model'](images)
            recon_norm = denormalize(recon)
            model_results.append((recon_norm, config_item['name']))
        
        # åˆ›å»ºå¤šæ¨¡å‹å¯¹æ¯”å›¾
        comparison_path = os.path.join(vis_dir, f"multi_model_comparison_batch_{i+1}.png")
        create_multi_model_comparison_plot(norm_images, model_results, i+1, comparison_path)
        print(f"âœ… å·²ä¿å­˜å¤šæ¨¡å‹å¯¹æ¯”å›¾: {comparison_path}")
        
        # åŒæ—¶ä¸ºæ¯ä¸ªæ¨¡å‹å•ç‹¬ä¿å­˜å›¾åƒï¼ˆä¿æŒå…¼å®¹æ€§ï¼‰
        for config_item in available_models:
            recon, _, _ = config_item['model'](images)
            recon_norm = denormalize(recon)
            single_path = os.path.join(vis_dir, f"{config_item['short_name']}_batch_{i+1}.png")
            
            # ä¸ºå•ä¸ªæ¨¡å‹åˆ›å»ºå¯¹æ¯”å›¾
            plt.figure(figsize=(16, 8))
            num_images = min(8, images.size(0))
            
            # ä¸Šæ’ï¼šåŸå§‹å›¾åƒ
            for j in range(num_images):
                plt.subplot(2, num_images, j+1)
                plt.imshow(norm_images[j].permute(1, 2, 0).cpu().numpy())
                plt.title(f"åŸå§‹ #{j+1}", fontsize=10)
                plt.axis('off')
            
            # ä¸‹æ’ï¼šé‡å»ºå›¾åƒ
            for j in range(num_images):
                plt.subplot(2, num_images, num_images + j + 1)
                plt.imshow(recon_norm[j].permute(1, 2, 0).cpu().numpy())
                plt.title(f"{config_item['name']} #{j+1}", fontsize=10)
                plt.axis('off')
            
            plt.tight_layout()
            plt.savefig(single_path, dpi=200)
            plt.close()
            print(f"âœ… å·²ä¿å­˜{config_item['name']}å•ç‹¬å¯¹æ¯”å›¾: {single_path}")

print(f"\nğŸ‰ å¯è§†åŒ–å®Œæˆï¼")
print(f"ğŸ“ å¤šæ¨¡å‹å¯¹æ¯”å›¾: {vis_dir}/multi_model_comparison_batch_*.png")
print(f"ğŸ“ å•æ¨¡å‹å¯¹æ¯”å›¾: {vis_dir}/*_batch_*.png")
print(f"ğŸ“ æ€»å…±ç”Ÿæˆäº† {len(available_models) * 5 + 5} å¼ å›¾åƒ") 
