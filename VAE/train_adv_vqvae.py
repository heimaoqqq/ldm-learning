import os
import yaml
import torch
import torch.nn as nn
import torch.optim as optim
import shutil
import time
from tqdm import tqdm
from adv_vq_vae import AdvVQVAE
from dataset import build_dataloader
from perceptual_loss import VGGPerceptualLoss
import torchvision.utils as vutils
import uuid
import math

# æ”¹è¿›çš„torch-fidelityå¯¼å…¥æ–¹å¼
HAS_FIDELITY = False
try:
    from torch_fidelity import calculate_metrics as original_calculate_metrics
    # åˆ›å»ºä¸€ä¸ªåŒ…è£…å‡½æ•°æ¥æ§åˆ¶è¾“å‡º
    def calculate_metrics(*args, **kwargs):
        """
        å¯¹torch_fidelity.calculate_metricsçš„åŒ…è£…ï¼Œç”¨äºæ§åˆ¶å…¶è¾“å‡ºå†—ä½™åº¦
        """
        # å¯¼å…¥å¿…è¦çš„æ¨¡å—
        import io
        import sys
        from contextlib import redirect_stdout
        
        # æ•è·åŸå§‹å‡½æ•°çš„æ‰€æœ‰è¾“å‡º
        f = io.StringIO()
        with redirect_stdout(f):
            # è°ƒç”¨åŸå§‹å‡½æ•°
            result = original_calculate_metrics(*args, **kwargs)
        
        # è¾“å‡ºåªåŒ…å«ç»“æœçš„ç®€åŒ–ä¿¡æ¯
        if result and 'frechet_inception_distance' in result:
            print(f"FIDåˆ†: {result['frechet_inception_distance']:.4f}")
        
        return result
    
    HAS_FIDELITY = True
    print("æˆåŠŸå¯¼å…¥torch-fidelityåº“ï¼Œå°†è®¡ç®—FIDæŒ‡æ ‡")
except ImportError as e:
    print(f"è­¦å‘Š: æ— æ³•å¯¼å…¥torch-fidelityåº“ï¼Œæ— æ³•è®¡ç®—FIDã€‚é”™è¯¯ä¿¡æ¯: {e}")
    print("è¯·è¿è¡Œ 'pip install torch-fidelity' å®‰è£…åé‡è¯•")
    print("ç»§ç»­è®­ç»ƒï¼Œä½†ä¸ä¼šè®¡ç®—FIDæŒ‡æ ‡")

# å¯ç”¨å¼‚å¸¸æ£€æµ‹ï¼Œå¸®åŠ©è¯†åˆ«æ¢¯åº¦é—®é¢˜
torch.autograd.set_detect_anomaly(True)

# åŠ è½½é…ç½®
with open('config.yaml', 'r', encoding='utf-8') as f:
    config = yaml.safe_load(f)

# æŒ‡å®šè®¾å¤‡
device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
print(f"ä½¿ç”¨è®¾å¤‡: {device}")

# FIDç›¸å…³è·¯å¾„å’Œè®¾ç½®
fid_eval_freq = config['training'].get('fid_eval_freq', 5)  # é»˜è®¤æ¯5ä¸ªepochè®¡ç®—ä¸€æ¬¡FID
fid_sample_size = config['training'].get('fid_sample_size', 1000)  # ç”¨äºè®¡ç®—FIDçš„æ ·æœ¬æ•°é‡
fid_batch_size = config['training'].get('fid_batch_size', 32)  # FIDè®¡ç®—çš„æ‰¹é‡å¤§å°

# FIDä¸´æ—¶å›¾åƒç›®å½•
temp_base_dir = os.path.join("temp_fid_images")  # åŸºç¡€ä¸´æ—¶ç›®å½•
os.makedirs(temp_base_dir, exist_ok=True)

# åœ¨æ¯æ¬¡FIDè®¡ç®—ä¸­ä½¿ç”¨å”¯ä¸€çš„å­ç›®å½•é¿å…å†²çª
def get_temp_fid_dirs():
    """åˆ›å»ºå¹¶è¿”å›ç”¨äºFIDè®¡ç®—çš„ä¸´æ—¶ç›®å½•"""
    # ä½¿ç”¨UUIDåˆ›å»ºå”¯ä¸€çš„ç›®å½•å
    unique_id = str(uuid.uuid4())[:8]
    temp_dir = os.path.join(temp_base_dir, f"run_{unique_id}")
    temp_real_dir = os.path.join(temp_dir, "real")
    temp_gen_dir = os.path.join(temp_dir, "generated")
    
    # åˆ›å»ºç›®å½•
    os.makedirs(temp_dir, exist_ok=True)
    os.makedirs(temp_real_dir, exist_ok=True)
    os.makedirs(temp_gen_dir, exist_ok=True)
    
    return temp_dir, temp_real_dir, temp_gen_dir

# æ„å»ºæ•°æ®åŠ è½½å™¨
train_loader, val_loader, train_dataset_len, val_dataset_len = build_dataloader(
    config['dataset']['root_dir'],
    batch_size=config['dataset']['batch_size'],
    num_workers=0, # å»ºè®®åœ¨Windowsä¸Šè°ƒè¯•æ—¶è®¾ä¸º0ï¼Œæˆ–è€…æ ¹æ®CPUæ ¸å¿ƒæ•°è°ƒæ•´
    shuffle_train=True,
    shuffle_val=False, # éªŒè¯é›†é€šå¸¸ä¸éœ€è¦æ‰“ä¹±
    val_split=0.3 # 30% ä½œä¸ºéªŒè¯é›†
)
dataset_len = train_dataset_len # ç”¨äºæ—§çš„å¹³å‡æŸå¤±è®¡ç®—åŸºæ•°ï¼Œç°åœ¨ä¸»è¦ç”¨ train_dataset_len

# åˆå§‹åŒ–æ¨¡å‹
model = AdvVQVAE(
    in_channels=config['model']['in_channels'],
    latent_dim=config['model']['latent_dim'],
    num_embeddings=config['model']['num_embeddings'],
    beta=config['model']['beta'],
    decay=config['model'].get('vq_ema_decay', 0.99),  # ä½¿ç”¨é…ç½®çš„ EMA è¡°å‡ç‡
    groups=config['model']['groups'],
    disc_ndf=64  # åˆ¤åˆ«å™¨ç‰¹å¾æ•°é‡
).to(device)

# åˆ›å»ºä¼˜åŒ–å™¨
gen_params = list(model.encoder.parameters()) + list(model.decoder.parameters()) + list(model.vq.parameters())
gen_optimizer = optim.Adam(
    gen_params,
    lr=config['training']['lr'],
    betas=(0.9, 0.99), # æ ¹æ®è®ºæ–‡æ›´æ–°
    weight_decay=config['training']['weight_decay']
)
disc_optimizer = optim.Adam(
    model.discriminator.parameters(),
    lr=config['training']['lr'] * 0.5,  # åˆ¤åˆ«å™¨å­¦ä¹ ç‡é€šå¸¸ç•¥å°
    betas=(0.5, 0.9), # æ ¹æ®è®ºæ–‡æ›´æ–°
    weight_decay=config['training']['weight_decay']
)

# æ„ŸçŸ¥æŸå¤±
perceptual_loss_fn = VGGPerceptualLoss().to(device) # é‡å‘½åä»¥åŒºåˆ†å˜é‡å’Œç±»å®ä¾‹
perceptual_weight = config['training'].get('perceptual_weight', 0.2) # ä»é…ç½®è¯»å–æˆ–é»˜è®¤

# ç”¨äºåå½’ä¸€åŒ–
def denorm(x):
    return (x * 0.5 + 0.5).clamp(0, 1)

# åˆ›å»ºä¿å­˜ç›®å½•
save_dir = config['training']['save_dir']
os.makedirs(save_dir, exist_ok=True)

# FIDè®¡ç®—å‡½æ•°
def calculate_fid(model, val_loader, temp_real_dir, temp_gen_dir, sample_size=1000):
    """è®¡ç®—FIDåˆ†æ•°"""
    if not HAS_FIDELITY:
        print("  æ— æ³•è®¡ç®—FID: torch-fidelityåº“æœªæˆåŠŸå¯¼å…¥")
        return float('inf')
    
    try:
        # ä¸´æ—¶ç›®å½•å·²ç”±è°ƒç”¨è€…åˆ›å»ºï¼Œè¿™é‡Œåªéœ€ç¡®è®¤ç›®å½•å­˜åœ¨
        for dir_path in [temp_real_dir, temp_gen_dir]:
            if not os.path.exists(dir_path):
                os.makedirs(dir_path, exist_ok=True)
                print(f"  åˆ›å»ºç¼ºå¤±ç›®å½•: {dir_path}")
        
        model.eval()
        with torch.no_grad():
            sample_count = 0
            for val_images, _ in tqdm(val_loader, desc="ç”ŸæˆFIDå›¾åƒæ ·æœ¬"):
                val_images = val_images.to(device)
                batch_size = val_images.size(0)
                
                # é€šè¿‡æ¨¡å‹è·å–é‡å»ºå›¾åƒ
                val_z = model.encoder(val_images)
<<<<<<< HEAD
                val_z_q, _, _ = model.vq(val_z)
=======
                val_z_q, _, _, _ = model.vq(val_z)  # æ–°å¢usage_infoè¿”å›å€¼
>>>>>>> 126d4ad24fc08805125e6779329dd8caece6ed5d
                val_recons = model.decoder(val_z_q)
                
                # åå½’ä¸€åŒ–
                real_images = denorm(val_images)
                gen_images = denorm(val_recons)
                
                # ä¿å­˜å›¾åƒ
                for i in range(batch_size):
                    if sample_count >= sample_size:
                        break
                    
                    # ä¿å­˜çœŸå®å›¾åƒ
                    vutils.save_image(
                        real_images[i], 
                        os.path.join(temp_real_dir, f"{sample_count}.png")
                    )
                    
                    # ä¿å­˜ç”Ÿæˆå›¾åƒ
                    vutils.save_image(
                        gen_images[i], 
                        os.path.join(temp_gen_dir, f"{sample_count}.png")
                    )
                    
                    sample_count += 1
                    
                if sample_count >= sample_size:
                    break
        
        print(f"  è®¡ç®—FIDä¸­ (åŸºäº{sample_count}ä¸ªå›¾åƒæ ·æœ¬)...")
        
        if sample_count < 10:
            print(f"  è­¦å‘Š: æ ·æœ¬æ•°é‡è¿‡å°‘ ({sample_count}), FIDè®¡ç®—å¯èƒ½ä¸å‡†ç¡®")
            return float('inf')
            
        # è®¡ç®—FID
        # ä½¿ç”¨io.StringIOæ•è·æ ‡å‡†è¾“å‡º
        import io
        import sys
        from contextlib import redirect_stdout

        # åˆ›å»ºStringIOå¯¹è±¡æ¥æ•è·è¾“å‡º
        f = io.StringIO()
        with redirect_stdout(f):
            metrics = calculate_metrics(
                input1=temp_real_dir, 
                input2=temp_gen_dir,
                cuda=torch.cuda.is_available(), 
                fid=True,
                verbose=True
            )
        
        # è·å–æ•è·çš„è¾“å‡º
        output = f.getvalue()
        print(output)  # ä»ç„¶æ‰“å°åŸå§‹è¾“å‡º
        
        # å°è¯•ä»è¾“å‡ºä¸­è§£æFIDå€¼
        import re
        fid_match = re.search(r'Frechet Inception Distance: (\d+\.\d+)', output)
        parsed_fid = None
        if fid_match:
            parsed_fid = float(fid_match.group(1))
            print(f"  ä»è¾“å‡ºè§£æçš„FIDå€¼: {parsed_fid:.4f}")
        
        # é¦–å…ˆå°è¯•ä»metricså­—å…¸è·å–
        if 'frechet_inception_distance' in metrics:
            fid_score = metrics['frechet_inception_distance']
            print(f"  ä»metricså­—å…¸è·å–çš„FID ('frechet_inception_distance'): {fid_score:.4f}")
        elif 'fid' in metrics:
            fid_score = metrics['fid']
            print(f"  ä»metricså­—å…¸è·å–çš„FID ('fid'): {fid_score:.4f}")
        else:
            # å¦‚æœmetricså­—å…¸ä¸­æ²¡æœ‰æ‰¾åˆ°ï¼Œä½¿ç”¨è§£æçš„å€¼
            print(f"  metricså­—å…¸ä¸­æ²¡æœ‰æ ‡å‡†FIDé”®ï¼Œå¯ç”¨é”®: {list(metrics.keys())}")
            if parsed_fid is not None:
                fid_score = parsed_fid
                print(f"  ä½¿ç”¨ä»è¾“å‡ºè§£æçš„FIDå€¼: {fid_score:.4f}")
            elif metrics:
                # å°è¯•ä½¿ç”¨å­—å…¸ä¸­çš„ç¬¬ä¸€ä¸ªå€¼
                fid_score = list(metrics.values())[0]
                print(f"  ä½¿ç”¨metricså­—å…¸ä¸­çš„ç¬¬ä¸€ä¸ªå€¼ä½œä¸ºFID: {fid_score:.4f}")
            else:
                print("  æœªæ‰¾åˆ°ä»»ä½•FIDå€¼ï¼Œè¿”å›æ— ç©·å¤§")
                fid_score = float('inf')

        print(f"  FIDè¯„åˆ†: {fid_score:.4f}")
        return fid_score
    except Exception as e:
        print(f"  è®¡ç®—FIDæ—¶å‡ºé”™: {str(e)}")
        print(f"  é”™è¯¯ç±»å‹: {type(e).__name__}")
        import traceback
        traceback.print_exc()  # æ‰“å°å®Œæ•´é”™è¯¯å †æ ˆ
        
        # å¦‚æœé”™è¯¯æ˜¯KeyErroræˆ–å…¶ä»–å·²çŸ¥é”™è¯¯ï¼Œå¹¶ä¸”æœ‰è¾“å‡ºä¾›è§£æ
        if isinstance(e, KeyError) and 'output' in locals():
            # å°è¯•ä»å·²æ•è·çš„è¾“å‡ºä¸­è§£æFIDå€¼
            fid_match = re.search(r'Frechet Inception Distance: (\d+\.\d+)', output)
            if fid_match:
                fid_score = float(fid_match.group(1))
                print(f"  å°½ç®¡å‘ç”Ÿé”™è¯¯ï¼Œä½†æˆåŠŸä»è¾“å‡ºè§£æFIDå€¼: {fid_score:.4f}")
                return fid_score
        
        print("  æ— æ³•æ¢å¤FIDå€¼ï¼Œè¿”å›æ— ç©·å¤§")
        return float('inf')

# ä¿®æ”¹FIDè®¡ç®—ç›¸å…³ä»£ç æ®µï¼Œä½¿ç”¨ç®€åŒ–ç‰ˆæœ¬
def calculate_fid_simple(model, val_loader, sample_size=1000):
    """ç®€åŒ–çš„FIDè®¡ç®—å‡½æ•°ï¼Œåªè¾“å‡ºå…³é”®ä¿¡æ¯"""
    if not HAS_FIDELITY:
        print("æ— æ³•è®¡ç®—FID: torch-fidelityåº“æœªæˆåŠŸå¯¼å…¥")
        return float('inf')
    
    try:
        # åˆ›å»ºä¸´æ—¶ç›®å½•
        temp_dir, temp_real_dir, temp_gen_dir = get_temp_fid_dirs()
        
        # ç”Ÿæˆæ ·æœ¬å’Œä¿å­˜å›¾åƒçš„ä»£ç ä¿æŒä¸å˜ï¼Œä½†ä¸è¾“å‡ºè¯¦ç»†è¿›åº¦
        sample_count = 0
        model.eval()
        with torch.no_grad():
            for val_images, _ in val_loader:
                val_images = val_images.to(device)
                
                # ä½¿ç”¨æ¨¡å‹ç”Ÿæˆé‡å»ºå›¾åƒ
                z = model.encoder(val_images)
<<<<<<< HEAD
                z_q, _, _ = model.vq(z)
=======
                z_q, _, _, _ = model.vq(z)  # æ–°å¢usage_infoè¿”å›å€¼
>>>>>>> 126d4ad24fc08805125e6779329dd8caece6ed5d
                recons = model.decoder(z_q)
                
                # ä¿å­˜çœŸå®å›¾åƒå’Œç”Ÿæˆå›¾åƒç”¨äºFIDè®¡ç®—
                for i in range(val_images.size(0)):
                    if sample_count >= sample_size:
                        break
                    
                    # ä¿å­˜çœŸå®å›¾åƒ
                    real_img = denorm(val_images[i])
                    real_path = os.path.join(temp_real_dir, f"real_{sample_count}.png")
                    vutils.save_image(real_img, real_path)
                    
                    # ä¿å­˜ç”Ÿæˆçš„å›¾åƒ
                    gen_img = denorm(recons[i])
                    gen_path = os.path.join(temp_gen_dir, f"gen_{sample_count}.png")
                    vutils.save_image(gen_img, gen_path)
                    
                    sample_count += 1
                    
                if sample_count >= sample_size:
                    break
        
        if sample_count < 10:
            print("è­¦å‘Š: æ ·æœ¬æ•°é‡è¿‡å°‘, FIDè®¡ç®—å¯èƒ½ä¸å‡†ç¡®")
            return float('inf')
        
        # è®¡ç®—FID - ä½¿ç”¨æˆ‘ä»¬çš„åŒ…è£…å‡½æ•°ä¼šè‡ªåŠ¨ç®€åŒ–è¾“å‡º
        metrics = calculate_metrics(
            input1=temp_real_dir, 
            input2=temp_gen_dir,
            cuda=torch.cuda.is_available(), 
            fid=True,
            verbose=False  # å…³é—­è¯¦ç»†è¾“å‡º
        )
        
        # ä»metricså­—å…¸è·å–FID
        if 'frechet_inception_distance' in metrics:
            fid_score = metrics['frechet_inception_distance']
        elif 'fid' in metrics:
            fid_score = metrics['fid']
        else:
            # å¦‚æœæ‰¾ä¸åˆ°FIDå€¼
            print("æœªæ‰¾åˆ°FIDå€¼ï¼Œè¿”å›æ— ç©·å¤§")
            return float('inf')
            
        # è®¡ç®—å®Œæˆååˆ é™¤ä¸´æ—¶ç›®å½•
        try:
            if os.path.exists(temp_dir):
                shutil.rmtree(temp_dir)
        except Exception:
            pass
            
        return fid_score
    except Exception as e:
        print(f"è®¡ç®—FIDæ—¶å‡ºé”™: {str(e)}")
        return float('inf')

# è®­ç»ƒå¾ªç¯
best_val_loss = float('inf') # ä½¿ç”¨éªŒè¯é›†æŸå¤±æ¥ä¿å­˜æœ€ä½³æ¨¡å‹
<<<<<<< HEAD
best_fid = float('inf')      # ä½¿ç”¨FIDè¯„åˆ†æ¥ä¿å­˜æœ€ä½³æ¨¡å‹
=======
best_val_rec_loss = float('inf') # æ–°å¢ï¼šä½¿ç”¨éªŒè¯é›†é‡å»ºæŸå¤±æ¥ä¿å­˜æœ€ä½³æ¨¡å‹
best_fid = float('inf') # åˆå§‹åŒ–æœ€ä½³FIDåˆ†æ•°
>>>>>>> 126d4ad24fc08805125e6779329dd8caece6ed5d
epochs = config['training']['epochs']
disc_train_interval = config['training'].get('disc_train_interval', 5) # åˆ¤åˆ«å™¨è®­ç»ƒé—´éš”

# æ·»åŠ å­¦ä¹ ç‡è°ƒåº¦å™¨ - çº¿æ€§é¢„çƒ­+ä½™å¼¦é€€ç«
use_scheduler = config['training'].get('use_scheduler', True)
warmup_epochs = config['training'].get('warmup_epochs', 10)  # é»˜è®¤ä¸ºè®­ç»ƒæ€»è½®æ•°çš„10%

if use_scheduler:
    # åˆ›å»ºåŸºäºepochçš„å­¦ä¹ ç‡è°ƒåº¦å™¨
    
    # åˆ›å»ºå­¦ä¹ ç‡è°ƒåº¦å™¨
    def lr_lambda(epoch):
        if epoch < warmup_epochs:
            # çº¿æ€§é¢„çƒ­
            return float(epoch) / float(max(1, warmup_epochs))
        else:
            # ä½™å¼¦é€€ç«
            progress = float(epoch - warmup_epochs) / float(max(1, epochs - warmup_epochs))
            return 0.5 * (1.0 + math.cos(math.pi * progress))
    
    gen_scheduler = torch.optim.lr_scheduler.LambdaLR(gen_optimizer, lr_lambda)
    disc_scheduler = torch.optim.lr_scheduler.LambdaLR(disc_optimizer, lr_lambda)
    print(f"å·²å¯ç”¨å­¦ä¹ ç‡è°ƒåº¦å™¨: çº¿æ€§é¢„çƒ­({warmup_epochs}è½®ï¼Œå æ€»è®­ç»ƒçš„{warmup_epochs/epochs*100:.1f}%) + ä½™å¼¦é€€ç« (epochçº§)")
else:
    gen_scheduler = None
    disc_scheduler = None
    print("ä¸ä½¿ç”¨å­¦ä¹ ç‡è°ƒåº¦å™¨")

print(f"å¼€å§‹è®­ç»ƒï¼Œæ€»å…±{epochs}è½®...")
print(f"è®­ç»ƒé›†æ ·æœ¬æ•°: {train_dataset_len}, éªŒè¯é›†æ ·æœ¬æ•°: {val_dataset_len}")
print(f"FIDè¯„ä¼°é¢‘ç‡: æ¯{fid_eval_freq}ä¸ªepochè®¡ç®—ä¸€æ¬¡")
print(f"FIDè®¡ç®—çŠ¶æ€: {'å¯ç”¨' if HAS_FIDELITY else 'ç¦ç”¨'}")

# ä» config ä¸­è·å–æƒé‡
rec_weight = config['training'].get('rec_weight', 1.0)
vq_commit_weight = config['training'].get('vq_commit_weight', 0.5) # beta in VQ
# perceptual_weight å·²ç»åœ¨ä¸Šé¢å®šä¹‰
gen_adv_weight = config['training'].get('gen_adv_weight', 0.2)

print(f"æŸå¤±æƒé‡: rec_weight={rec_weight}, vq_commit_weight(beta)={vq_commit_weight}, perceptual_weight={perceptual_weight}, gen_adv_weight={gen_adv_weight}")
print(f"æ³¨æ„: vq_commit_weight æ˜¯ VQ commitment loss ä¸­çš„ betaã€‚æ€»çš„ VQ regularization loss (codebook + commit) æƒé‡ä¸º 1.0")

for epoch in range(epochs):
    model.train() # è®¾ç½®ä¸ºè®­ç»ƒæ¨¡å¼
<<<<<<< HEAD
=======
    
    # åœ¨æ¯ä¸ªepochå¼€å§‹æ—¶é‡ç½®ç æœ¬ä½¿ç”¨ç»Ÿè®¡
    if hasattr(model.vq, 'reset_usage_stats'):
        model.vq.reset_usage_stats()
        print(f"  å·²é‡ç½®ç´¯ç§¯ç æœ¬ä½¿ç”¨è®¡æ•°å™¨ã€‚")
    
>>>>>>> 126d4ad24fc08805125e6779329dd8caece6ed5d
    running_rec_loss = 0.0
    running_vq_commit_loss = 0.0 # VQ commitment loss (beta * ||E(x) - sg(z_q)||^2)
    running_vq_codebook_loss = 0.0 # VQ codebook loss (||sg(E(x)) - z_q||^2)
    running_disc_loss = 0.0
    running_gen_adv_loss = 0.0 # ç”¨äºç”Ÿæˆå™¨çš„å¯¹æŠ—æŸå¤±
    running_perc_loss = 0.0
    
    disc_batches_trained = 0 # è®°å½•åˆ¤åˆ«å™¨è®­ç»ƒäº†å¤šå°‘ä¸ªæ‰¹æ¬¡

    for batch_idx, (images, _) in enumerate(tqdm(train_loader, desc=f"Epoch {epoch+1}/{epochs}")):
        images = images.to(device)
        batch_size = images.size(0)
        
        train_disc = (batch_idx % disc_train_interval == 0)

        #----------------------------------------------
        # 1. é¦–å…ˆè®­ç»ƒåˆ¤åˆ«å™¨ï¼ˆå¦‚æœéœ€è¦ï¼‰
        #----------------------------------------------
        if train_disc:
            model.discriminator.requires_grad_(True) # ç¡®ä¿åˆ¤åˆ«å™¨æ¢¯åº¦å¼€å¯
            disc_optimizer.zero_grad()
            
            with torch.no_grad(): # ç”Ÿæˆå™¨éƒ¨åˆ†ä¸è®¡ç®—æ¢¯åº¦
                z = model.encoder(images)
<<<<<<< HEAD
                z_q, _, _ = model.vq(z) 
=======
                z_q, _, _, _ = model.vq(z)  # æ–°å¢usage_infoè¿”å›å€¼
>>>>>>> 126d4ad24fc08805125e6779329dd8caece6ed5d
                fake_images = model.decoder(z_q)
            
            real_preds = model.discriminator(images)
            fake_preds = model.discriminator(fake_images.detach()) # .detach() å¾ˆé‡è¦
            
            d_real_loss = nn.BCEWithLogitsLoss()(real_preds, torch.ones_like(real_preds))
            d_fake_loss = nn.BCEWithLogitsLoss()(fake_preds, torch.zeros_like(fake_preds))
            d_loss = (d_real_loss + d_fake_loss) * 0.5 # è®ºæ–‡ä¸­å¸¸è§çš„åšæ³•æ˜¯ä¹˜ä»¥0.5
            
            d_loss.backward()
            disc_optimizer.step()
            running_disc_loss += d_loss.item() * batch_size # ä¹˜ä»¥ batch_size ä»¥ä¾¿åç»­æ­£ç¡®å¹³å‡
            disc_batches_trained += 1


        #----------------------------------------------
        # 2. ç„¶åè®­ç»ƒç”Ÿæˆå™¨ï¼ˆç¼–ç å™¨+è§£ç å™¨+VQå±‚ï¼‰
        #----------------------------------------------
        model.discriminator.requires_grad_(False) # è®­ç»ƒç”Ÿæˆå™¨æ—¶å†»ç»“åˆ¤åˆ«å™¨å‚æ•°
        gen_optimizer.zero_grad()
        
        # z æ˜¯ç¼–ç å™¨è¾“å‡º E(x)
        # z_q_straight_through æ˜¯ç›´é€šä¼°è®¡å™¨çš„è¾“å‡ºï¼Œç”¨äºè§£ç å™¨
        # vq_commit_loss_val æ˜¯ beta * ||E(x) - sg(z_q)||^2
        # vq_codebook_loss_val æ˜¯ ||sg(E(x)) - z_q||^2
<<<<<<< HEAD
        z = model.encoder(images)
        z_q_straight_through, vq_commit_loss_val, vq_codebook_loss_val = model.vq(z)
=======
        # usage_info æ˜¯ç æœ¬ä½¿ç”¨ä¿¡æ¯
        z = model.encoder(images)
        z_q_straight_through, vq_commit_loss_val, vq_codebook_loss_val, usage_info = model.vq(z)
>>>>>>> 126d4ad24fc08805125e6779329dd8caece6ed5d
        recons = model.decoder(z_q_straight_through)
        
        rec_loss = nn.MSELoss()(recons, images)
        p_loss = perceptual_loss_fn(denorm(recons), denorm(images)) # æ„ŸçŸ¥æŸå¤±çš„è¾“å…¥éœ€è¦denorm
        
        # å¯¹æŠ—æŸå¤±ï¼ˆè®©åˆ¤åˆ«å™¨è®¤ä¸ºç”Ÿæˆå›¾åƒæ˜¯çœŸå®çš„ï¼‰
        fake_preds_for_gen = model.discriminator(recons)
        g_adv_loss = nn.BCEWithLogitsLoss()(fake_preds_for_gen, torch.ones_like(fake_preds_for_gen))
        
        # VQ Regularization Loss (L_reg) = codebook_loss + commitment_loss
        # commitment_loss_val å·²ç»ä¹˜ä»¥ beta
        l_reg = vq_codebook_loss_val + vq_commit_loss_val

        # æ€»ç”Ÿæˆå™¨æŸå¤± (L_total) = L_rec + L_reg + lambda_perc * L_perc + lambda_adv_G * L_adv_G
        # rec_weight (æ¥è‡ªconfig) = 1.0
        # L_reg æƒé‡éšå¼ä¸º 1.0
        # perceptual_weight (æ¥è‡ªconfig) = 0.1
        # gen_adv_weight (æ¥è‡ªconfig) = 0.1
        g_total = (rec_weight * rec_loss + 
                   l_reg + 
                   perceptual_weight * p_loss + 
                   gen_adv_weight * g_adv_loss)
        
        g_total.backward()
        gen_optimizer.step()
        
        running_rec_loss += rec_loss.item() * batch_size
        running_vq_commit_loss += vq_commit_loss_val.item() * batch_size
        running_vq_codebook_loss += vq_codebook_loss_val.item() * batch_size
        running_gen_adv_loss += g_adv_loss.item() * batch_size
        running_perc_loss += p_loss.item() * batch_size
        
        # æ‰¹æ¬¡çº§å­¦ä¹ ç‡è°ƒåº¦å·²ç§»é™¤ï¼Œæ”¹ä¸ºepochçº§
    
    # è®¡ç®—è®­ç»ƒé›†ä¸Šçš„å¹³å‡æŸå¤±
    epoch_rec_loss = running_rec_loss / train_dataset_len
    epoch_vq_commit_loss = running_vq_commit_loss / train_dataset_len # è¿™æ˜¯ commitment loss
    epoch_vq_codebook_loss = running_vq_codebook_loss / train_dataset_len # è¿™æ˜¯ codebook loss
    epoch_gen_adv_loss = running_gen_adv_loss / train_dataset_len
    epoch_perc_loss = running_perc_loss / train_dataset_len
    
    if disc_batches_trained > 0:
        epoch_disc_loss = running_disc_loss / (disc_batches_trained * config['dataset']['batch_size'])
    else:
        epoch_disc_loss = 0.0

<<<<<<< HEAD
    print(f"Epoch {epoch+1} Training Losses:")
    print(f"  Rec Loss: {epoch_rec_loss:.6f}, VQ Commit Loss: {epoch_vq_commit_loss:.6f}, VQ Codebook Loss: {epoch_vq_codebook_loss:.6f}")
    print(f"  Gen Adversarial Loss: {epoch_gen_adv_loss:.6f}, Perceptual Loss: {epoch_perc_loss:.6f}")
    print(f"  Disc Loss: {epoch_disc_loss:.6f} (trained on {disc_batches_trained} batches)")

=======
    # è·å–ç æœ¬ä½¿ç”¨ç»Ÿè®¡
    if hasattr(model.vq, 'get_usage_stats'):
        usage_stats = model.vq.get_usage_stats()
        usage_rate = usage_stats['usage_rate']
        used_codes = usage_stats['used_codes']
        total_codes = usage_stats['total_codes']
    else:
        usage_rate = 0.0
        used_codes = 0
        total_codes = config['model']['num_embeddings']

    print(f"ğŸ“Š Epoch {epoch+1} Training Summary:")
    print(f"     Avg Gen Loss: {epoch_rec_loss + epoch_vq_commit_loss + epoch_vq_codebook_loss + epoch_gen_adv_loss + epoch_perc_loss:.4f}, Avg Disc Loss: {epoch_disc_loss:.4f}")
    print(f"     Avg Rec Loss: {epoch_rec_loss:.4f}, Avg Perceptual Loss: {epoch_perc_loss:.4f}")
    print(f"     Avg VQ Commit: {epoch_vq_commit_loss:.4f}, Avg VQ Codebook: {epoch_vq_codebook_loss:.4f}")
    print(f"     ğŸ“ˆ Cumulative Codebook Usage (end of epoch): {usage_rate:.2%}")
    
>>>>>>> 126d4ad24fc08805125e6779329dd8caece6ed5d
    # --- åœ¨éªŒè¯é›†ä¸Šè¯„ä¼° ---
    model.eval() # è®¾ç½®ä¸ºè¯„ä¼°æ¨¡å¼
    val_running_rec_loss = 0.0
    val_running_vq_commit_loss = 0.0
    val_running_vq_codebook_loss = 0.0
    val_running_perc_loss = 0.0
    
    with torch.no_grad():
        for val_images, _ in tqdm(val_loader, desc=f"Epoch {epoch+1} Validation", leave=False):
            val_images = val_images.to(device)
            
            val_z = model.encoder(val_images)
<<<<<<< HEAD
            val_z_q_st, val_vq_commit, val_vq_codebook = model.vq(val_z)
=======
            val_z_q_st, val_vq_commit, val_vq_codebook, val_usage_info = model.vq(val_z)  # æ–°å¢usage_infoè¿”å›å€¼
>>>>>>> 126d4ad24fc08805125e6779329dd8caece6ed5d
            val_recons = model.decoder(val_z_q_st)
            
            val_rec = nn.MSELoss()(val_recons, val_images)
            val_perceptual = perceptual_loss_fn(denorm(val_recons), denorm(val_images))
            
            val_running_rec_loss += val_rec.item() * val_images.size(0)
            val_running_vq_commit_loss += val_vq_commit.item() * val_images.size(0)
            val_running_vq_codebook_loss += val_vq_codebook.item() * val_images.size(0)
            val_running_perc_loss += val_perceptual.item() * val_images.size(0)
            
    epoch_val_rec_loss = val_running_rec_loss / val_dataset_len
    epoch_val_vq_commit_loss = val_running_vq_commit_loss / val_dataset_len
    epoch_val_vq_codebook_loss = val_running_vq_codebook_loss / val_dataset_len
    epoch_val_perc_loss = val_running_perc_loss / val_dataset_len
    
    # è®¡ç®—ç”¨äºæ¯”è¾ƒå’Œä¿å­˜æ¨¡å‹çš„éªŒè¯é›†æ€»æŸå¤±
    # è¿™ä¸ªç»„åˆå¯ä»¥æ ¹æ®å®é™…æ•ˆæœè°ƒæ•´ï¼Œè¿™é‡Œç®€å•åœ°å°†ä¸»è¦çš„ç”Ÿæˆå™¨ç›¸å…³æŸå¤±åŠ èµ·æ¥
    # æ ¹æ®è®ºæ–‡ L_total = L_rec + L_reg + 0.1 * L_perc (å¯¹æŠ—æŸå¤±ä¸ç”¨äºéªŒè¯)
    val_l_reg = epoch_val_vq_codebook_loss + epoch_val_vq_commit_loss
    current_val_loss = (rec_weight * epoch_val_rec_loss + 
                         val_l_reg + 
                         perceptual_weight * epoch_val_perc_loss)

<<<<<<< HEAD
    print(f"Epoch {epoch+1} Validation Losses:")
    print(f"  Val Rec Loss: {epoch_val_rec_loss:.6f}, Val VQ Commit: {epoch_val_vq_commit_loss:.6f}, Val VQ Codebook: {epoch_val_vq_codebook_loss:.6f}")
    print(f"  Val Perceptual Loss: {epoch_val_perc_loss:.6f}")
    print(f"  Current Combined Val Loss (for saving): {current_val_loss:.6f}")

    # ä¿å­˜åŸºäºéªŒè¯æŸå¤±çš„æœ€ä½³æ¨¡å‹
    if current_val_loss < best_val_loss:
        old_best = best_val_loss  # ä¿å­˜æ—§çš„æœ€ä½³å€¼ç”¨äºæ—¥å¿—
        best_val_loss = current_val_loss
        torch.save(model.state_dict(), os.path.join(save_dir, 'adv_vqvae_best_loss.pth'))
        print(f"  âœ“ å‘ç°æ›´å¥½çš„éªŒè¯æŸå¤±: {best_val_loss:.6f}ï¼Œå·²ä¿å­˜æ¨¡å‹")
        if epoch == 0:
            print(f"    â†’ åˆå§‹æ¨¡å‹ï¼Œè®¾ç½®ä¸ºåŸºå‡†å€¼")
        else:
            print(f"    â†’ ä¹‹å‰æœ€ä½³: {old_best:.6f} | æ”¹å–„: {old_best - current_val_loss:.6f}")
    else:
        print(f"  âœ— å½“å‰éªŒè¯æŸå¤± {current_val_loss:.6f} æœªæ”¹å–„ (å½“å‰æœ€ä½³: {best_val_loss:.6f})")
=======
    print(f"ğŸ“‰ Epoch {epoch+1} Validation Summary - Combined Loss: {current_val_loss:.4f}")
    print(f"     Avg Rec: {epoch_val_rec_loss:.4f}, Avg Perc: {epoch_val_perc_loss:.4f}")
    print(f"     Avg VQ Commit: {epoch_val_vq_commit_loss:.4f}, Avg VQ Codebook: {epoch_val_vq_codebook_loss:.4f}")
    print(f"     ğŸ“Š å½“å‰ç´¯ç§¯ç æœ¬ä½¿ç”¨ç‡: {usage_rate:.2%} ({used_codes}/{total_codes} ç å­—)")

    # ä¿å­˜åŸºäºéªŒè¯é‡å»ºæŸå¤±çš„æœ€ä½³æ¨¡å‹ï¼ˆä¸»è¦ç­–ç•¥ï¼‰
    if epoch_val_rec_loss < best_val_rec_loss:
        old_best = best_val_rec_loss  # ä¿å­˜æ—§çš„æœ€ä½³å€¼ç”¨äºæ—¥å¿—
        best_val_rec_loss = epoch_val_rec_loss
        
        # åˆ é™¤æ—§çš„æ¨¡å‹æ–‡ä»¶ï¼ˆå¦‚æœå­˜åœ¨ï¼‰
        best_rec_model_path = os.path.join(save_dir, 'adv_vqvae_best_loss.pth')
        if os.path.exists(best_rec_model_path):
            try:
                os.remove(best_rec_model_path)
                print(f"  ğŸ—‘ï¸ å·²åˆ é™¤æ—§çš„æœ€ä½³é‡å»ºæŸå¤±æ¨¡å‹")
            except Exception as e:
                print(f"  âš ï¸ åˆ é™¤æ—§æ¨¡å‹æ—¶å‡ºé”™: {e}")
        
        # ä¿å­˜æ–°çš„æœ€ä½³æ¨¡å‹
        torch.save(model.state_dict(), best_rec_model_path)
        print(f"  â­ å‘ç°æ›´å¥½çš„éªŒè¯é‡å»ºæŸå¤±: {best_val_rec_loss:.6f}ï¼Œå·²ä¿å­˜æ¨¡å‹")
        if epoch == 0:
            print(f"    â†’ åˆå§‹æ¨¡å‹ï¼Œè®¾ç½®ä¸ºåŸºå‡†å€¼")
        else:
            print(f"    â†’ ä¹‹å‰æœ€ä½³: {old_best:.6f} | æ”¹å–„: {old_best - epoch_val_rec_loss:.6f}")
    else:
        print(f"  âœ— å½“å‰éªŒè¯é‡å»ºæŸå¤± {epoch_val_rec_loss:.6f} æœªæ”¹å–„ (å½“å‰æœ€ä½³: {best_val_rec_loss:.6f})")
    
    # å¯é€‰ï¼šä¹Ÿä¿å­˜åŸºäºç»¼åˆæŸå¤±çš„æ¨¡å‹ï¼ˆç”¨äºå¯¹æ¯”ï¼‰
    if current_val_loss < best_val_loss:
        best_val_loss = current_val_loss
        
        # åˆ é™¤æ—§çš„ç»¼åˆæŸå¤±æ¨¡å‹æ–‡ä»¶ï¼ˆå¦‚æœå­˜åœ¨ï¼‰
        best_combined_model_path = os.path.join(save_dir, 'adv_vqvae_best_combined_loss.pth')
        if os.path.exists(best_combined_model_path):
            try:
                os.remove(best_combined_model_path)
                print(f"  ğŸ—‘ï¸ å·²åˆ é™¤æ—§çš„æœ€ä½³ç»¼åˆæŸå¤±æ¨¡å‹")
            except Exception as e:
                print(f"  âš ï¸ åˆ é™¤æ—§ç»¼åˆæŸå¤±æ¨¡å‹æ—¶å‡ºé”™: {e}")
        
        # ä¿å­˜æ–°çš„æœ€ä½³ç»¼åˆæŸå¤±æ¨¡å‹
        torch.save(model.state_dict(), best_combined_model_path)
        print(f"  ğŸ“Š ç»¼åˆæŸå¤±æœ€ä½³: {best_val_loss:.6f}ï¼Œå·²ä¿å­˜å¯¹æ¯”æ¨¡å‹")
>>>>>>> 126d4ad24fc08805125e6779329dd8caece6ed5d
    
    # æ›´æ–°å­¦ä¹ ç‡è°ƒåº¦å™¨ï¼ˆepochçº§ï¼‰
    if use_scheduler:
        gen_scheduler.step()
        disc_scheduler.step()
        current_gen_lr = gen_optimizer.param_groups[0]['lr']
        current_disc_lr = disc_optimizer.param_groups[0]['lr']
        print(f"  å­¦ä¹ ç‡æ›´æ–° - Gen: {current_gen_lr:.6f}, Disc: {current_disc_lr:.6f}")
    
    # æ¯fid_eval_freqä¸ªepochè®¡ç®—ä¸€æ¬¡FID
    if (epoch + 1) % fid_eval_freq == 0:
        print(f"\nEpoch {epoch+1}: æ­£åœ¨è®¡ç®—FIDè¯„åˆ†...")
        if HAS_FIDELITY:
            try:
                # è®°å½•å¼€å§‹æ—¶é—´
                start_time = time.time()
                fid_score = calculate_fid_simple(model, val_loader, sample_size=fid_sample_size)
                elapsed_time = time.time() - start_time
                print(f"FIDè¯„åˆ†: {fid_score:.4f}ï¼Œè€—æ—¶: {elapsed_time:.2f}ç§’")
                
                # ä¿å­˜åŸºäºFIDè¯„åˆ†çš„æœ€ä½³æ¨¡å‹
                if fid_score < best_fid:
                    old_best = best_fid  # ä¿å­˜æ—§çš„æœ€ä½³å€¼ç”¨äºæ—¥å¿—
                    best_fid = fid_score
<<<<<<< HEAD
=======
                    
                    # åˆ é™¤æ—§çš„FIDæ¨¡å‹æ–‡ä»¶ï¼ˆå¦‚æœå­˜åœ¨ï¼‰
                    best_fid_model_path = os.path.join(save_dir, 'adv_vqvae_best_fid.pth')
                    if os.path.exists(best_fid_model_path):
                        try:
                            os.remove(best_fid_model_path)
                            print(f"  ğŸ—‘ï¸ å·²åˆ é™¤æ—§çš„æœ€ä½³FIDæ¨¡å‹")
                        except Exception as e:
                            print(f"  âš ï¸ åˆ é™¤æ—§FIDæ¨¡å‹æ—¶å‡ºé”™: {e}")
                    
                    # ä¿å­˜æ–°çš„æœ€ä½³FIDæ¨¡å‹
                    torch.save(model.state_dict(), best_fid_model_path)
>>>>>>> 126d4ad24fc08805125e6779329dd8caece6ed5d
                    print(f"  âœ“ å‘ç°æ›´å¥½çš„FIDè¯„åˆ†: {best_fid:.4f}ï¼Œå·²ä¿å­˜æ¨¡å‹")
                    if epoch == 0:
                        print(f"    â†’ åˆå§‹FIDè¯„ä¼°ï¼Œè®¾ç½®ä¸ºåŸºå‡†å€¼")
                    else:
                        print(f"    â†’ ä¹‹å‰æœ€ä½³: {old_best:.4f} | æ”¹å–„: {old_best - fid_score:.4f}")
<<<<<<< HEAD
                    torch.save(model.state_dict(), os.path.join(save_dir, 'adv_vqvae_best_fid.pth'))
=======
>>>>>>> 126d4ad24fc08805125e6779329dd8caece6ed5d
                else:
                    print(f"  âœ— å½“å‰FIDè¯„åˆ† {fid_score:.4f} æœªæ”¹å–„ (å½“å‰æœ€ä½³: {best_fid:.4f})")
            except Exception as e:
                print(f"FIDè®¡ç®—è¿‡ç¨‹ä¸­å‡ºç°é”™è¯¯: {str(e)}")
        else:
            print("è·³è¿‡FIDè®¡ç®—ï¼štorch-fidelityåº“æœªæˆåŠŸå¯¼å…¥")
    
    # æ¯20è½®ä¿å­˜ä¸€æ¬¡checkpoint
    if (epoch + 1) % config['training'].get('save_interval', 20) == 0:
        torch.save({
            'epoch': epoch + 1,
            'model_state_dict': model.state_dict(),
            'gen_optimizer_state_dict': gen_optimizer.state_dict(),
            'disc_optimizer_state_dict': disc_optimizer.state_dict(),
            'best_val_loss': best_val_loss,
<<<<<<< HEAD
=======
            'best_val_rec_loss': best_val_rec_loss,  # æ–°å¢
>>>>>>> 126d4ad24fc08805125e6779329dd8caece6ed5d
            'best_fid': best_fid if 'best_fid' in locals() else float('inf'),
        }, os.path.join(save_dir, f'adv_vqvae_epoch_{epoch+1}.pth'))
        print(f"  ä¿å­˜checkpoint: adv_vqvae_epoch_{epoch+1}.pth")

print("è®­ç»ƒå®Œæˆï¼")
# åˆ é™¤ä¸´æ—¶æ–‡ä»¶ç›®å½•
if os.path.exists(temp_base_dir):
<<<<<<< HEAD
    shutil.rmtree(temp_base_dir) 
=======
    shutil.rmtree(temp_base_dir) 
>>>>>>> 126d4ad24fc08805125e6779329dd8caece6ed5d
